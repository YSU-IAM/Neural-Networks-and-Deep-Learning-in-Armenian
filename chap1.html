<!DOCTYPE html>
<html lang="en">
<!-- Produced from a LaTeX source file.  Note that the production is done -->
<!-- by a very rough-and-ready (and buggy) script, so the HTML and other  -->
<!-- code is quite ugly!  Later versions should be better.                -->
    <meta charset="utf-8">
    <meta name="citation_title" content="Neural Networks and Deep Learning">
    <meta name="citation_author" content="Nielsen, Michael A.">
    <meta name="citation_publication_date" content="2015">
    <meta name="citation_fulltext_html_url" content="http://neuralnetworksanddeeplearning.com">
    <meta name="citation_publisher" content="Determination Press">
    <link rel="icon" href="nnadl_favicon.ICO" />
    <title>Նեյրոնային ցանցեր և խորը ուսուցում: Մայքլ Նիլսենի գրքի թարգմանությունը հայերեն</title>
    <script src="assets/jquery.min.js"></script>
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {inlineMath: [['$','$']]},
        "HTML-CSS":
          {scale: 92},
        TeX: { equationNumbers: { autoNumber: "AMS" }}});
    </script>
    <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>


    <link href="assets/style.css" rel="stylesheet">
    <link href="assets/pygments.css" rel="stylesheet">
    <link rel="stylesheet" href="https://code.jquery.com/ui/1.11.2/themes/smoothness/jquery-ui.css">

<style>
/* Adapted from */
/* https://groups.google.com/d/msg/mathjax-users/jqQxrmeG48o/oAaivLgLN90J, */
/* by David Cervone */

@font-face {
    font-family: 'MJX_Math';
    src: url('https://cdn.mathjax.org/mathjax/latest/fonts/HTML-CSS/TeX/eot/MathJax_Math-Italic.eot'); /* IE9 Compat Modes */
    src: url('https://cdn.mathjax.org/mathjax/latest/fonts/HTML-CSS/TeX/eot/MathJax_Math-Italic.eot?iefix') format('eot'),
    url('https://cdn.mathjax.org/mathjax/latest/fonts/HTML-CSS/TeX/woff/MathJax_Math-Italic.woff')  format('woff'),
    url('https://cdn.mathjax.org/mathjax/latest/fonts/HTML-CSS/TeX/otf/MathJax_Math-Italic.otf')  format('opentype'),
    url('https://cdn.mathjax.org/mathjax/latest/fonts/HTML-CSS/TeX/svg/MathJax_Math-Italic.svg#MathJax_Math-Italic') format('svg');
}

@font-face {
    font-family: 'MJX_Main';
    src: url('https://cdn.mathjax.org/mathjax/latest/fonts/HTML-CSS/TeX/eot/MathJax_Main-Regular.eot'); /* IE9 Compat Modes */
    src: url('https://cdn.mathjax.org/mathjax/latest/fonts/HTML-CSS/TeX/eot/MathJax_Main-Regular.eot?iefix') format('eot'),
    url('https://cdn.mathjax.org/mathjax/latest/fonts/HTML-CSS/TeX/woff/MathJax_Main-Regular.woff')  format('woff'),
    url('https://cdn.mathjax.org/mathjax/latest/fonts/HTML-CSS/TeX/otf/MathJax_Main-Regular.otf')  format('opentype'),
    url('https://cdn.mathjax.org/mathjax/latest/fonts/HTML-CSS/TeX/svg/MathJax_Main-Regular.svg#MathJax_Main-Regular') format('svg');
}
</style>

  </head>
  <body><div class="nonumber_header"><h2><a href="index.html">Նեյրոնային ցանցեր և խորը ուսուցում</a></h2></div><div class="section"><div id="toc">
<p class="toc_title"><a href="index.html">Նեյրոնային ցանցեր և խորը ուսուցում</a></p><p class="toc_not_mainchapter"><a href="about.html">Ինչի՞ մասին է գիրքը</a></p><p class="toc_not_mainchapter"><a href="exercises_and_problems.html">Խնդիրների և վարժությունների մասին</a></p><p class='toc_mainchapter'><a id="toc_using_neural_nets_to_recognize_handwritten_digits_reveal" class="toc_reveal" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';"><img id="toc_img_using_neural_nets_to_recognize_handwritten_digits" src="images/arrow.png" width="15px"></a><a href="chap1.html">Ձեռագիր թվերի ճանաչում օգտագործելով նեյրոնային ցանծեր</a><div id="toc_using_neural_nets_to_recognize_handwritten_digits" style="display: none;"><p class="toc_section"><ul><a href="chap1.html#perceptrons"><li>Պերսեպտրոններ</li></a><a href="chap1.html#sigmoid_neurons"><li>Սիգմոիդ նեյրոններ</li></a><a href="chap1.html#the_architecture_of_neural_networks"><li>Նեյրոնային ցանցերի կառուցվածքը</li></a><a href="chap1.html#a_simple_network_to_classify_handwritten_digits"><li>Պարզ ցանց ձեռագիր թվերի դասակարգման համար</li></a><a href="chap1.html#learning_with_gradient_descent"><li>Սովորում գրադիենտային իջեցման միջոցով</li></a><a href="chap1.html#implementing_our_network_to_classify_digits"><li>Թվերի դասակարգման համար նախատեսված ցանցի իրականացումը</li></a><a href="chap1.html#toward_deep_learning"><li>Խորը ուսուցմանն ընդառաջ</li></a></ul></p></div>
<script>
$('#toc_using_neural_nets_to_recognize_handwritten_digits_reveal').click(function() {
   var src = $('#toc_img_using_neural_nets_to_recognize_handwritten_digits').attr('src');
   if(src == 'images/arrow.png') {
     $("#toc_img_using_neural_nets_to_recognize_handwritten_digits").attr('src', 'images/arrow_down.png');
   } else {
     $("#toc_img_using_neural_nets_to_recognize_handwritten_digits").attr('src', 'images/arrow.png');
   };
   $('#toc_using_neural_nets_to_recognize_handwritten_digits').toggle('fast', function() {});
});</script><p class='toc_mainchapter'><a id="toc_how_the_backpropagation_algorithm_works_reveal" class="toc_reveal" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';"><img id="toc_img_how_the_backpropagation_algorithm_works" src="images/arrow.png" width="15px"></a><a href="chap2.html">How the backpropagation algorithm works</a><div id="toc_how_the_backpropagation_algorithm_works" style="display: none;"><p class="toc_section"><ul><a href="chap2.html#warm_up_a_fast_matrix-based_approach_to_computing_the_output
_from_a_neural_network"><li>Warm up: a fast matrix-based approach to computing the output
  from a neural network</li></a><a href="chap2.html#the_two_assumptions_we_need_about_the_cost_function"><li>The two assumptions we need about the cost function</li></a><a href="chap2.html#the_hadamard_product_$s_\odot_t$"><li>The Hadamard product, $s \odot t$</li></a><a href="chap2.html#the_four_fundamental_equations_behind_backpropagation"><li>The four fundamental equations behind backpropagation</li></a><a href="chap2.html#proof_of_the_four_fundamental_equations_(optional)"><li>Proof of the four fundamental equations (optional)</li></a><a href="chap2.html#the_backpropagation_algorithm"><li>The backpropagation algorithm</li></a><a href="chap2.html#the_code_for_backpropagation"><li>The code for backpropagation</li></a><a href="chap2.html#in_what_sense_is_backpropagation_a_fast_algorithm"><li>In what sense is backpropagation a fast algorithm?</li></a><a href="chap2.html#backpropagation_the_big_picture"><li>Backpropagation: the big picture</li></a></ul></p></div>
<script>
$('#toc_how_the_backpropagation_algorithm_works_reveal').click(function() {
   var src = $('#toc_img_how_the_backpropagation_algorithm_works').attr('src');
   if(src == 'images/arrow.png') {
     $("#toc_img_how_the_backpropagation_algorithm_works").attr('src', 'images/arrow_down.png');
   } else {
     $("#toc_img_how_the_backpropagation_algorithm_works").attr('src', 'images/arrow.png');
   };
   $('#toc_how_the_backpropagation_algorithm_works').toggle('fast', function() {});
});</script><p class='toc_mainchapter'><a id="toc_improving_the_way_neural_networks_learn_reveal" class="toc_reveal" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';"><img id="toc_img_improving_the_way_neural_networks_learn" src="images/arrow.png" width="15px"></a><a href="chap3.html">Improving the way neural networks learn</a><div id="toc_improving_the_way_neural_networks_learn" style="display: none;"><p class="toc_section"><ul><a href="chap3.html#the_cross-entropy_cost_function"><li>The cross-entropy cost function</li></a><a href="chap3.html#overfitting_and_regularization"><li>Overfitting and regularization</li></a><a href="chap3.html#weight_initialization"><li>Weight initialization</li></a><a href="chap3.html#handwriting_recognition_revisited_the_code"><li>Handwriting recognition revisited: the code</li></a><a href="chap3.html#how_to_choose_a_neural_network's_hyper-parameters"><li>How to choose a neural network's hyper-parameters?</li></a><a href="chap3.html#other_techniques"><li>Other techniques</li></a></ul></p></div>
<script>
$('#toc_improving_the_way_neural_networks_learn_reveal').click(function() {
   var src = $('#toc_img_improving_the_way_neural_networks_learn').attr('src');
   if(src == 'images/arrow.png') {
     $("#toc_img_improving_the_way_neural_networks_learn").attr('src', 'images/arrow_down.png');
   } else {
     $("#toc_img_improving_the_way_neural_networks_learn").attr('src', 'images/arrow.png');
   };
   $('#toc_improving_the_way_neural_networks_learn').toggle('fast', function() {});
});</script><p class='toc_mainchapter'><a id="toc_a_visual_proof_that_neural_nets_can_compute_any_function_reveal" class="toc_reveal" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';"><img id="toc_img_a_visual_proof_that_neural_nets_can_compute_any_function" src="images/arrow.png" width="15px"></a><a href="chap4.html">A visual proof that neural nets can compute any function</a><div id="toc_a_visual_proof_that_neural_nets_can_compute_any_function" style="display: none;"><p class="toc_section"><ul><a href="chap4.html#two_caveats"><li>Two caveats</li></a><a href="chap4.html#universality_with_one_input_and_one_output"><li>Universality with one input and one output</li></a><a href="chap4.html#many_input_variables"><li>Many input variables</li></a><a href="chap4.html#extension_beyond_sigmoid_neurons"><li>Extension beyond sigmoid neurons</li></a><a href="chap4.html#fixing_up_the_step_functions"><li>Fixing up the step functions</li></a><a href="chap4.html#conclusion"><li>Conclusion</li></a></ul></p></div>
<script>
$('#toc_a_visual_proof_that_neural_nets_can_compute_any_function_reveal').click(function() {
   var src = $('#toc_img_a_visual_proof_that_neural_nets_can_compute_any_function').attr('src');
   if(src == 'images/arrow.png') {
     $("#toc_img_a_visual_proof_that_neural_nets_can_compute_any_function").attr('src', 'images/arrow_down.png');
   } else {
     $("#toc_img_a_visual_proof_that_neural_nets_can_compute_any_function").attr('src', 'images/arrow.png');
   };
   $('#toc_a_visual_proof_that_neural_nets_can_compute_any_function').toggle('fast', function() {});
});</script><p class='toc_mainchapter'><a id="toc_why_are_deep_neural_networks_hard_to_train_reveal" class="toc_reveal" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';"><img id="toc_img_why_are_deep_neural_networks_hard_to_train" src="images/arrow.png" width="15px"></a><a href="chap5.html">Why are deep neural networks hard to train?</a><div id="toc_why_are_deep_neural_networks_hard_to_train" style="display: none;"><p class="toc_section"><ul><a href="chap5.html#the_vanishing_gradient_problem"><li>The vanishing gradient problem</li></a><a href="chap5.html#what's_causing_the_vanishing_gradient_problem_unstable_gradients_in_deep_neural_nets"><li>What's causing the vanishing gradient problem?  Unstable gradients in deep neural nets</li></a><a href="chap5.html#unstable_gradients_in_more_complex_networks"><li>Unstable gradients in more complex networks</li></a><a href="chap5.html#other_obstacles_to_deep_learning"><li>Other obstacles to deep learning</li></a></ul></p></div>
<script>
$('#toc_why_are_deep_neural_networks_hard_to_train_reveal').click(function() {
   var src = $('#toc_img_why_are_deep_neural_networks_hard_to_train').attr('src');
   if(src == 'images/arrow.png') {
     $("#toc_img_why_are_deep_neural_networks_hard_to_train").attr('src', 'images/arrow_down.png');
   } else {
     $("#toc_img_why_are_deep_neural_networks_hard_to_train").attr('src', 'images/arrow.png');
   };
   $('#toc_why_are_deep_neural_networks_hard_to_train').toggle('fast', function() {});
});</script><p class='toc_mainchapter'><a id="toc_deep_learning_reveal" class="toc_reveal" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';"><img id="toc_img_deep_learning" src="images/arrow.png" width="15px"></a><a href="chap6.html">Deep learning</a><div id="toc_deep_learning" style="display: none;"><p class="toc_section"><ul><a href="chap6.html#introducing_convolutional_networks"><li>Introducing convolutional networks</li></a><a href="chap6.html#convolutional_neural_networks_in_practice"><li>Convolutional neural networks in practice</li></a><a href="chap6.html#the_code_for_our_convolutional_networks"><li>The code for our convolutional networks</li></a><a href="chap6.html#recent_progress_in_image_recognition"><li>Recent progress in image recognition</li></a><a href="chap6.html#other_approaches_to_deep_neural_nets"><li>Other approaches to deep neural nets</li></a><a href="chap6.html#on_the_future_of_neural_networks"><li>On the future of neural networks</li></a></ul></p></div>
<script>
$('#toc_deep_learning_reveal').click(function() {
   var src = $('#toc_img_deep_learning').attr('src');
   if(src == 'images/arrow.png') {
     $("#toc_img_deep_learning").attr('src', 'images/arrow_down.png');
   } else {
     $("#toc_img_deep_learning").attr('src', 'images/arrow.png');
   };
   $('#toc_deep_learning').toggle('fast', function() {});
});</script><p class="toc_not_mainchapter"><a href="sai.html">Appendix: Is there a <em>simple</em> algorithm for intelligence?</a></p><p class="toc_not_mainchapter"><a href="acknowledgements.html">Acknowledgements</a></p><p class="toc_not_mainchapter"><a href="faq.html">Frequently Asked Questions</a></p>
</div>



<p>
Մարդկային տեսողական համակարգը աշխարհի հրաշալիքներից է: Դիտարկենք ձեռագիր թվանշանների հետևյալ հերթականությունը: <a name="complete_zero"></a></p>

<p><center><img src="images/digits.png" width="160px"></center> </p>

<p>
  Մարդկանց մեծամասնությունը առանց ջանք գործադրելու կարող է ճանաչել 504192 թվերը: Այդ դյուրինությունը խաբուսիկ է սակայն: Մարդկային ուղեղի կիսագնդերում պարունակվում է հիմնական տեսողական կորտեքսը, որը հայտնի է որպես V1: Այն պարունակում է 140 միլիոն նեյրոններ, որոնք իրար հետ կապված են տասնյակ միլիարդավոր կապերով: Ընդ որում, մարդկային տեսողությունը բաղկացած չէ միայն V1-ից, այլ V2, V3, V4, և V5 տեսողական կորտեքսներից, որոնք իրականացնում են բազմաթիվ նկարների մշակում:
  Մեր գլուխներն ըստ էության պարունակում են սուպեր համակարգիչներ` էվոլյուցիայի միջոցով կատարելագործված միլիոնավոր տարիների ընթացքում և հրաշալիորեն հարմարված տեսանելի աշխարհը հասկանալու համար: Ձեռագիր թվանշանները հասկանալը հեշտ չէ, այնուամենայնիվ, մարկանց մոտ լավ է ստացվում հասկանալ այն ինչ իրենց աչքերն են ընկալում: Սակայն գրեթե ամբողջ այդ աշխատանքը կատարվում է ենթագիտակցորեն, հետևաբար մենք ըստ արժանվույն չենք գնահատում թե ինչպիսի դժվար խնդիր է լուծում տեսողական համակարգը:
</p>

<p>
  Տեսողական օրինաչափությունը հասկանալու դժվարությունը երևան է գալիս այն ժամանակ երբ փորձ է
  արվում ստեղծելու ծրագիր ձեռագիր թվանշաններ ճանաչելու համար: Մեզ հեշտ թվացող այդ երևույթը
  պարզվում է, որ բավականին բարդ է: Պատկերներ ճանաչելու պարզ ինտուիցիան (9 թվանշանը վերևում
  շրջանաձև է, որը կապվում է նրեքևի հետ կոր ուղղաձիգով) պարզվում է որ այնքան էլ պարզ չէ նկարագրել
  ալգորիթմորեն: Երբ փորձ է կատարվում նպանատիպ կանոնները հստակեցնել, միանգամից խճճվում ենք բացառությունների
  կամ հատուկ դեպքերի կծիկի մեջ: Խնդիրը լուծելը արագորեն դառնում է անհույս:
</p>

<p></p>

<p>
  Նեյրոնային ցանցերը խնդրին մոտենում են այլ կերպ: Միտքը կայանում է նրանում, որ
  պետք է վերցնել մեծ քանակությամբ ձեռագիր թվանշաններ, որոնց անվանենք ուսուցման օրինակներ,
</p>

<p>
  <center><img src="images/mnist_100_digits.png" width="440px"></center>
</p>

<p>
  և կառուցել համակարգ որը կարող է սովորել այդ օրինակներից: Այլ կերպ ասած, նեյրոնային
  ցանցը օգտագործում է օրինակները ձեռագիր թվանշանների կառուցվածքն ինքնաբերաբար
  հասկանալու համար: Ավելին, շատացնելով օրինակների քանակը, ցանցը կարող է ավելի շատ
  սովորել ձեռագրերի մասին, այսպիսով բարելավելով ճշգրտությունը: Օրինակ, ցանցը ավելի ճշգրիտ
  կարող է գուշակել սովորելով 1000 օրինակի վրա քան 100 օրինակի:
</p>

<p>
  Այս գլխում կկառուցենք համակարգչային ծրագիր, որը իրականացնում է նեյրոնային ցանց,
  որը իր հերթին սովորում է ճանաչել ձեռագիր թվանշաններ: Ծրագիրը ունի 74 տող երկարություն
  և չի օգտագործում ոչ մի նեյրոնային ցանցերի գրադարան: Սակայն այն կարող է թվանշանները
  ճանաչել 96 տոկոս ճշտությամբ առանց մարդկային միջամտության: Այնուհետև հետագա
  գլուխներում կկառուցենք գաղափարներ, որոնք կօգնեն ճանաչման ճշտությունը հասցնել
  99 տոկոսից ավելի: Փաստացիորեն, լավագույն կոմերցիոն նեյրոնային ցանցերն այնքան
  հուսալի են, որ օգտագործվում են բանկերի կողմից չեկերի մշակման համար, փոստատների
  կողմից հասցեների ճանաչման համար:
</p>

<p>
  Մենք կենտրոնանում ենք ձեռագիր թվանշանների ճանաչման վրա, քանի որ այն ընդհանուր
  առմամբ գերազանց նախատիպային խնդիր է նեյրոնային ցանցերի մասին սովորելու համար:
  Որպես նախատիպային խնդիր ըստ երևույթին այն հեշտ չէ, սակայն այնքան բարդ չէ որ կարիք զգացվի
  չափազանց բարդ լուծման տեխնիկաների կամ համակարգչային հզորության (computational power) օգտագործման:
  Հետևաբար սա հրաշալի մոտեցում է ավելի առաջադեմ տեխնիկաների հմտություններ յուրացնելու համար, օրինակ խորը
  ուսուցումը: Այսպիսով, գրքում պարբերաբար վերադառնալու ենք ձեռագիր թվանշանների
  ճանաչման խնդրին: Ավելի ուշ նաև կքննարկենք թե ինչպես կարելի է օգտագործել այս
  գաղափարները այլ խնդիրների լուծման համար, օրինակ` համակարգչային տեսողության (computer vision),
  բնական լեզվի ճանաչում (speech, natural language processing) և այլն:
</p>

<p>
  Իհարկե, եթե այս գլխի նպատակը լիներ միայն կառուցել ծրագիր, որը ճանաչում է ձեռագիր թվանշանները,
  ապա գլուխը կարճ կլիներ: Մենք խոսելու ենք նաև նեյրոնային ցանցերի մասին այլ կարեևոր գաղափարներից,
  հատկապես երկու կարևոր արհեստական նեյրոնի տեսակների մասին (պերսեպտրոն և սիգմոիդ նեյրոն) և նեյրոնային
  ցանցերի ստանդարտ ուսուցման ալգորիթմի մասին, որը հայտնի ե որպես ստոկաստիկ գրադիենտային իջեցում (stochastic
  gradient descent): Ավելի խորը հասկանալու համար առկան են քննարկումներ թե ինչպես կարելի է կառուցել ինտուցիա
  և կարողանալ հասկանալ թե որ մասը ինչպես է մտածված և կառուցված նեյրոնային ցանցերում և դրանծ ուսուցման մեջ:
</p>

<p>
  <h3><a name="perceptrons"></a><a href="#perceptrons">Պերսեպտրոններ</a></h3>
</p>

<p>Ի՞նչ է նեյրոնային ցանցը: Սկզբում կներկայացնեմ արհեստական նեյրոնի մի տարատեսակ, որ կոչվում է <em>պերսեպտրոն</em>:
Պերսեպտրոնները <a href="http://books.google.ca/books/about/Principles_of_neurodynamics.html?id=7FhRAAAAMAAJ">ստեղծվել են</a> 1950-1960-ականներին <a href="http://en.wikipedia.org/wiki/Frank_Rosenblatt">Ֆրանկ Ռոզեսբլատի կողմից</a>, ոգեշնչված <a href="http://en.wikipedia.org/wiki/Warren_McCulloch">Ուորեն ՄակԿուլոքի</a> և <a href="http://en.wikipedia.org/wiki/Walter_Pitts">Վալտեր Փիթսի</a> ավելի վաղ կատարված <a href="http://scholar.google.ca/scholar?cluster=4035975255085082870">աշխատանքով</a>: Այսօր ավելի հաճախ օգտագործում են արհեստական նեյրոնների այլ մոդելներ․ այս գրքում և նեյրոնային ցանցերի վերաբերյալ ժամանակակից աշխատանքների մեծամասնության մեջ օգտագործվող նեյրոնների հիմնական մոդելը կոչվում է <em>սիգմոիդ նեյրոն</em>: Մենք շուտով կանդրադառնանք սիգմոիդ նեյրոններին: Բայց որպեսզի հասկանանք, թե ինչու են սիգմոիդ նեյրոնները սահմանվում այնպես, ինչպես սահմանվում են, արժե նախ ժամանակ ծախսել պերսեպտրոնները հասկանալու համար:</p><p>Ինչպե՞ս են աշխատում պերսեպտրոնները:  Պերսեպտրոնը մուտքում ստանում է մի քանի երկուական արժեքներ,
$x_1, x_2, \ldots$, և ելքում ստանում է մեկ երկուական արժեք (որպես ելք նշանակենք output, այսուհետ այս երկու տերմինները կօգտագործվեն փոխարինաբար)․
<center>
<img src="images/tikz0.png"/>
</center>
Այս օրինակում պերսեպտրոնը ունի երեք մուտքեր, $x_1, x_2, x_3$:
Ընդհանուր դեպքում այն կարող է ունենալ ավելի շատ կամ ավելի քիչ մուտքեր: Ռոզենբլատը առաջարկել է ելքում ստացվող արժեքը հաշվարկելու պարզ կանոն: Նա ներմուծեց <em>կշիռներ</em>, $w_1,w_2,\ldots$, իրական թվեր, որոնք արտահայտում են համապատասխան մուտքերի կարևորությունը ելքի համար: Նեյրոնի ելքը, $0$ կամ $1$, որոշվում է կախված այն բանից, թե $\sum_j w_j x_j$ կշռված գումարը փոքր է, թե մեծ է որոշակի <em>շեմային արժեքից</em>: Շեմը, ինչպես կշիռները, իրական թիվ է, որը հանդիսանում է նեյրոնի պարամետր:  Ավելի ճշգրիտ հանրահաշվական տերմիններով`
<a class="displaced_anchor" name="eqtn1"></a>\begin{eqnarray}
\mbox{ելք} & = & \left\{ \begin{array}{ll}
0 & \mbox{if } \sum_j w_j x_j \leq \mbox{ շեմ} \\
1 & \mbox{if } \sum_j w_j x_j > \mbox{ շեմ}
\end{array} \right.
\tag{1}\end{eqnarray}

Այսքանն է պերսեպտրոնի աշխատանքի նկարագրությունը:</p>

<p>Սա պարզագույն մաթեմատիկական մոդելն է: Դուք կարող եք պերսեպտրոնը հասկանալ որպես մի սարք, որը փաստերը կշռելով կայացնում է որոշումներ: Քննարկենք մի օրինակ: Օրինակը այնքան էլ իրատեսական չէ, սակայն հեշտ է հասկանալը, և մենք շուտով կդիտարկենք ավելի իրատեսական օրինակներ: Ենթադրենք մոտենում են հանգստյան օրերը և դուք լսել եք, որ ձեր քաղաքում պանրի փառատոն է կայանալու: Դուք պանիր սիրում եք և ուզում եք որոշել արդյոք արժի գնալ փառատոնին: Դուք կայացնում եք որոշում հիմնվելով երեք գործոնների վրա․

<ol>
  <li> Եղանակը լա՞վն է,
  <li> Ձեր ընկերը կամ ընկերուհին ցանկություն ունե՞ն միանալ ձեզ,
  <li> Փառատոնին հնարավո՞ր է մոտենալ հասարակական տրանսպորտով (դուք չունեք ավտոմեքենա):
</ol>

Մենք կարող ենք այս երեք գործոնները ներկայացնել երկուական փոփոխականներով՝
$x_1, x_2$ և $x_3$: Օրինակ, եթե եղանակը լավն է, ապա ունենք $x_1 = 1$, իսկ եթե եղանակը բարենպաստ չէ, ապա $x_1 = 0$: Նմանապես, $x_2 = 1$ եթե ձեր ընկերը կամ ընկերուհին ցանկություն ունեն գնալու, և $x_2 = 0$ հակառակ դեպքում: Եվ նորից նման ձևով $x_3$-ը հասարակական տրանսպորտի հետ կապված:
</p>

<p>Այժմ ենթադրենք որ դուք շատ եք սիրում պանիր, այնքան շատ, որ պարաստ եք գնալ փառատոնին նույնիսկ եթե ձեր ընկերը կամ ընկերուհին հետաքրքրված չեն և փառատոնին հասնելը դժվար է: Բայց գուցե դուք տանել չեք կարողանում վատ եղանակը և հաստատ չեք մասնակցի փառատոնին, եթե եղանակը անբարենպաստ եղավ: Այս բնույթի որոշման կայացումը մոդելավորելու համար կարող եք օգտագործել պերսեպտրոն: Օրինակ, կարելի է եղանակի համար կշիռը վերցնել $w_1 = 6$, իսկ մյուս պայմանների համար՝ $w_2 = 2$ և $w_3 = 2$: $w_1$-ի մեծ արժեքը ցույց է տալիս, որ եղանակը շատ կարևոր է ձեզ համար, շատ ավելի կարևոր է, քան արդյոք ձեր ընկերը կամ ընկերուհին կմիանան ձեզ, կամ հասարակական տրանսպորտի հարմարությունը: Վերջապես, ենթադրենք պերսեպտրոնի շեմը դուք ընտրում եք հավասար 5-ի: Այսպիսի ընտրության դեպքում պերսեպտրոնը իրականացնում է մեր ցանկացած որոշում կայացնող մոդելը, ելքում տալով 1, եթե եղանակը լավն է, և 0, եթե եղանակը բարենպաստ չէ: Ելքի վրա ընդհանրապես չեն ազդի ձեր ընկերոջ կամ ընկերուհու մասնակցելու ցանկությունը կամ հասարակական տրանսպորտի հարմարությունը:</p>

<p>Կշիռները և շեմը փոփոխելով մենք կստանանք որոշման կայացման տարբեր մոդելներ: Օրինակ, որպես շեմ ընտրենք $3$: Այդ դեպքում պերսեպտրոնը կորոշի որ դուք փառատոնին գնաք այն ժամանակ երբ եղանակը բարենպաստ է <em>կամ</em> երբ փառատոնը մոտ է հասարակական տրանսպորտին <em>և</em> ձեր ընկերը կամ ընկերուհին պատրաստ են միանալ ձեզ: Մի խոսքով դա կդառնա որոշում կայացնելու ուրիշ մոդել: Շեմն իջեցնելը նշանակում է որ դուք հակված եք փառատոնին մասնակցելուն:</p>

<p>Պարզ է որ պերսեպտրոնը մարդկային որոշում կայացնելու ամբողջական մոդել չէ: Սակայն օրինակը ցույց տվեց թե ինչպես այն կարող է համեմատել տարատեսակ գործոնները որոշում կայացնելու նպատակով: Ավելին, կարծես իրականալի է թվում այն որ պերսեպտրոնների բարդ կառուցվածքը կարող է անգամ իրականացնել ոչ պարզ որոշումներ:
<center>
  <img src="images/tikz1.png"/>
</center>
Հետևյալ ցանցում պերսեպտրոնների առաջին սյունակը, որին կանվանենք պերսեպտրոնների առաջին <em>շերտ</em>, իրականացնում է 3 պարզ որոշումներ` համեմատելով տրված գործոնները: Իսկ ի՞նչ կարելի է ասել 2-րդ շերտի պերսեպտրոնների մասին: Այդ պերսեպտրոններից յուդաքանչյուրը որոշում է կայացնում համեմատելով առաջին շերտի կայացրած որոշումների արդյունքները: Այդ կերպ երկրորդ շերտի պերսեպտրոնը կարող է կայացնել ավելի բարդ և աբստրակտ մակարդակի որոշում քան առաջին շերտի պերսեպտրոնները: Երրորդ շերտի պերսեպտրոնները կարող են կայացնել անգամ ավելի բարդ որոշումներ: Այս ձևով բազմաշերտ պերսեպտրոնների ցանցը կարող է կայացնել բավականին բարդ որոշումներ:</p>

<p>
  Ի դեպ, պերսեպտրոնի սահմանման մեջ ես նշել էի, որ նրաք ունեն մեկ
  ելքային արժեք: Տպավորություն կարող է ստեղծվել, որ վերևում նկարված ցանցում պերսեպտրոններն
  ունեն մեկից ավել ելքեր: Սակայն դա այդպես չէ, քանի որ մեկից ավել նկարված ելքային սլաքներն ուղղակի
  նշանակում են, որ տվյալ պերսեպտրոնի ելքը հանդիսանում է մուտք բազմաթիվ այլ պերսեպտրոնների:
  Այսպիսի նշանակումն ավելի հարմար է դարձնում ցանց նկարելն ու պատկերացնելը:
</p>

<p>
  Պարզեցնենք պերսեպտրոնի նկարագրությունը: $\sum_j w_j x_j > \mbox{շեմ}$ պայմանը
  կարելի է պարզեցնել երկու փոփոխություններով: Առաջին փոփոխությունն է` գրենք $\sum_j w_j x_j$ գումարը որպես
  $w \cdot x \equiv \sum_j w_j x_j$ սկալյար արտադրյալ, որտեղ $w$-ն կշիռների վեկտորն է,
  $x$-ը` մուտքային: Երկրորդ փոփոխությունն է` տանել ելքը անհավասարման մյուս մասը և վերանվանել այն
  որպես պերսեպտրոնի <em>շեղում</em>` $b \equiv -\mbox{շեմ}$: Օգտագործելով շեղումը շեմի փոխարեն,
  պերսեպտրոնը կգրենք.

  <a class="displaced_anchor" name="eqtn2"></a>
  \begin{eqnarray}
    \mbox{ելք} = \left\{
      \begin{array}{ll}
        0 & \mbox{if } w\cdot x + b \leq 0 \\
        1 & \mbox{if } w\cdot x + b > 0
      \end{array}
    \right.
  \tag{2}\end{eqnarray}

  Շեղումը կարելի է ընկալել որպես մի մեծություն, որը ցույց է տալիս, թե ինչքան հեշտությամբ կարելի է այնպես անել,
  որ պերսեպտրոնը ելքում ստանա $1$ արժեքը կամ կենսաբանական տերմիններով ասած, շեղումը ցույց է
  տալիս թե որքան հեշտությամբ կարելի ա այնպես անել, որ պերսեպտրոնը <em>հրահանգի(fire - ԿՏ)</em>:
  Մեծ շեղումով պերսեպտրոններն ավելի դյուրին է ելքում $1$ ստանում համեմատած փոքր շեղումների, որոնց դեպքում
  շեղման փոքրանալով, պերսեպտրոնի $1$ ելքային արժեք ունենալը դժվարանում է: Պարզ է, որ շեղումը չնչին
  փոփոխություն է պերսեպտրոնների նկարագրության մեջ, սակայն ավելի ուշ կհամոզվենք որ դա կբերի էական պարզեցումների:
  Այդ իսկ պատճառով, այսուհետ կօգտագործենք շեղում տերմինը շեմի փոխարեն:
</p>


<p>
  Ես նկարագրել եմ պերսեպտրոնները որպես վկայությունների կշռման մեթոդ, որի միջոցով
  կարելի է կատարել որոշումներ: Պերսեպտրոնի կարելի է օգտագործել
  պարզագույն հաշվողական այնպիսի միավորների կառուցման համար, ինչպիսիք են <CODE>AND</CODE>, <CODE>OR</CODE>
  և <CODE>NAND</CODE> գործողությունները: Օրինակ, ենթադրենք, որ ունենք պերսեպտրոն երկու
  մուտքերով, ամենքի արժեքը` $-2$, իսկ շեղումը $3$ է: Ահա մեր պերսեպրտոնը.
  <center>
    <img src="images/tikz2.png"/>
  </center>
  Հեշտ է նկատել, որ $00$ մուտքից ստացվում է $1$ ելք, քանի որ $(-2)*0+(-2)*0+3 = 3$
  դրական է: $*$ սիմվոլի օգտագործումը նախատեսված է բազմապատկումն ավելի ակնառու դարձնելու համար:
  Նույն ձևով հեշտ է համոզվել, որ $01$ և $10$ մուտքերի դեպքում արժեքը $1$ է: Սակայն
  $11$ մուտքի դեպքում արժեքը $0$ է, քանի որ $(-2)*1+(-2)*1+3 = -1$ բացասական է: Այսպիսով,
  նկատենք, որ մեր պերսեպտրոնը իրականացնում է <CODE>NAND</CODE> գործողությունը:
</p>

<p>
<a name="universality"></a>
</p>

<p>
  <CODE>NAND</CODE>-ի օրինակը ցույց է տալիս, որ կարող ենք հասշվել պարզ տրամաբանական
  ֆունկցիաներ: Իրականում պերսեպտրոնների ցանցի միջոցով կարելի է հաշվել <em>կամայական</em> տրամաբանական
  ֆունկցիա, քանի որ <CODE>NAND</CODE>-ը ունիվերսալ հաշվողական միավոր է, որով կարելի է կառուցել մնացած
  գործողությունները: Օրինակ, <CODE>NAND</CODE>-ը կարող ենք օգտագործել գումարման սխեմա կառուցելու համար,
  որը գումարում է $x_1$ և $x_2$ բիթերը: Սա նշանակում է հաշվել $x_1 \oplus x_2$ բիթ առ բիթ գումարումը և
  մնացորդային բիթը, որը $1$ է, երբ $x_1$ և $x_2$ բիթերը $1$ են, 0 մնացած դեպքերում:

  <center>
   <img src="images/tikz3.png"/>
  </center>

  Համարժեք պերսեպտրոնների ցանց ստանալու համար, բոլոր <CODE>NAND</CODE>-երը
  փոխարինենք երկումուտքանի պերսեպտրոններով, յուրաքանչյուրը $-2$ կշռով և $3$ շեղումով:
  Ահա թե ինչ ցանց է ստացվում: Նկատենք, որ աջ ներքևի <CODE>NAND</CODE> գործողությանը
  համապատասխանող գագաթը տեղաշարժված է նկարելն ավելի հեշտացնելու նպատակով:

  <center>
    <img src="images/tikz4.png"/>
  </center>

  Նկատենք, որ ամենաձախում գտնվող պերսեպտրոնի ելքերը հանդիսանում են մուտքեր
  ամենաներքևում գտնվող պերսեպտրոնի համար: Պերսեպտրոնի սահմանման մեջ նշված չէր,
  որ այսպիսի նկարագրություն թույլատրելի է, սակայն դա ոչ մի նշանակություն չունի: Եթե
  որոշում ենք թույլ չտալ նմանատիպ նշանակումներ, ապա կարող ենք միացնել երկու գծերը
  և դարձնել այն մեկ կապ -4 կշռով երկու -2 կշռով կապերի փոխարեն: (Եթե այս մասը ակնհայտ չեք
  համարում, ապա խորհուրդ եմ տալիս կանգ առնել և համոզվել որ սա էկվիվալենտ է): Այդ
  փոփոխությունից հետո ցանցի տեսքը կլինի այսպիսի (բոլոր չնշված կշիռները -2, բոլոր շեղումները
  3 և վերոնշյալ կապը -4 կշռով, ինչպես նշված է)

  <center>
   <img src="images/tikz5.png"/>
  </center>

  Նպատակահարմար է նաև վերցնել $x_1$ և $x_2$ մուտքային արժեքները որպես մուտքային պերսեպտրոնների
  <em>շերտ</em>.

  <center>
   <img src="images/tikz6.png"/>
  </center>

  Օգտագործենք հետևյալ նշանակումն այն պերսեպտրոնների համար, ովքեր ունեն ելք բայց
  չունեն մուտք.

  <center>
    <img src="images/tikz7.png"/>
  </center>
</p>

<p>
  Գումարման գործողության իրականացումը ցույց է տալիս, թե ինչպես կարելի է օգտագործել
  պերսեպտրոնները բազմաթիվ <CODE>NAND</CODE> գործողություններ պարունակող սխեմա
  սիմուլացնել: Եվ քանի որ <CODE>NAND</CODE>-երը ունիվերսալ հաշվարկային () միավորներ են,
  ապա հետևում է, որ նույնը ճիշտ է նաև պերսեպտրոնների համար:
</p>

<p>
  Պերսեպտրոնների ունիվրսալ հաշվողունակությունը միժամանակ և՛ հուսադրող է, և՛ հիասթափեցնող:
  Այն հուսադրող է, քանի որ այն ցույց է տալիս, որ պերսեպտրոնների ցանցը կարող է կամայակն այլ
  հաշվողական սարքին հավասար հզոր լինել: Սակայն դա նույնքան հիասթափեցնող է, քանի որ մյուս
  կողմից էլ ստացվում է, որ պերսեպտրոնները պարզապես <CODE>NAND</CODE>-ի նոր տեսակ են: Դա
  այդքան էլ մեծ նորություն չէ:
</p>

<p>
  Այնուամենայնիվ, իրավիճակը շատ ավելի բարվոք է: Պարզվում է, որ հնարավոր է դուրս բերել
  <em>սովորող ալգորիթմներ</em>, որը ինքնաբերաբար կարող է ձևափոխել արհեստական նեյրոնների
  կշիռներն ու շեղումները: Այսպիսի ձևափոխումը տեղի է ունենում ի պատասխան արտաքին գործոնների,
  այլ ոչ ծրագրավորողի: Սովորող ալգորիթմները թույլ են տալիս մեզ արհեստական նեյրոնները օգտագործել
  էապես տարբեր ձևով, համեմատած արդեն ընդունված տրամաբանական գործողությունների: Ուղղակիորեն
  <CODE>NAND</CODE> գործողությունների հերթականություն մշակելու փոխարեն, նեյրոնային ցանցը պարզապես
  սովորում է լուծել խնդիրներ, երբեմն խնդիրներ, որոնց լուծելու համար ավանդական սխեմա կառուցելը շատ
  բարդ կլիներ:
</p>

<p>
  <h3>
    <a name="sigmoid_neurons"></a>
    <a href="#sigmoid_neurons">Սիգմոիդ Նեյրոններ</a>
  </h3>
</p>

<p>
  Սովորող ալգորիթմները հրաշալի է հնչում: Բայց ինչպե՞ս կարող ենք դուրս
  բերել նմանատիպ ալգորիթմներ նեյրոնային ցանցերի համար: Ենթադրենք պերսեպտրոնների
  ցանց ունենք, որը կուզենայինք օգտագործել որոշակի խնդիր լուծելու նպատակով: Օրինակ,
  որպես մուտքային տվյալներ կարող են հանդիսանալ ձեռագիր թվանշանի թվային նկարի պիքսելները:
  Եվ մենք կնախընտրեինք, որ ցանցը սովորեր կշիռներն ու շեղումները այնպես, որ ցանցի ելքում
  կստանայինք թվանշանների դասակարգումը: Որպեսզի հասկանանք, թե ինչպես ուսուցումը կարող է
  աշխատել, ենթադրենք ցանցում` կշռի կամ շեղման մեջ կատարել ենք փոքրիկ փոփոխություն:
  Մեզ համար նախընտրելի արդյունքը կլիներ տեսնել, որ այդ փոքր փոփոխությունը առաջացներ
  փոկր փոփոխություն ցանցի ելքում: Ինչպես շուտով կհամոզվենք, այս հատկությունը ուսուցումը
  հնարավոր է դարձնում: Սխեմատիկորեն սա այն է, ինչ մեզ պետք է (ակնհայտ է, որ այս ցանցը
  չափազանց պարզ է ձեռագիր թվանշաններ ճանաչելու համար).
</p>

<p>
  <center>
    <img src="images/tikz8.png"/>
  </center>
</p>

<p>
  Եթե կշռի կամ շեղման փոքր փոփոխության հետևանքով առաջանար փոքր փոփոխություն
  ելքում, ապա մենք կկարողանայինք օգտագործել այդ փաստը կշիռներն ու շեղումները
  փոփոխելու համար այնպես, որ ցանցը ստանաս մեզ համար ցանկալի վարքագիծ: Օրինակ,
  ենթադրենք ցանցը սխալմամբ "9" թվանշանը ճանաչում է որպես "8": Մենք կարող ենք
  գտնել մի այնպիսի փոփոխություն շեղման և կշիռների համար, որ ցանցը փոքր ինչ ավելի
  մոտենա թվանշանը որպես "9" ճանաչելուն: Այնուհետև կարող ենք կրկնել այս քայլը այնքան
  մինչև ստանանք ավելի և ավելի լավ ելքեր: Ցանցը կասենք, որ սովորում է
</p>

<p>
  Խնդիրը կայանում է նրանում, որ սա այն չէ ինչ պատահում է պերսեպտրոնների դեպքում:
  Իրականում երբեմն մեկ պերսեպտրոնի կշիռների և շեղման չնչին փոփոխությունը կարող է
  հանգեցնել ելքի կտրուկ փոփոխության, օրինակ $0$-ից $1$: Այս փոփոխությունը կարող է
  հանգեցնել ցանցի մնացած հատվածներում բավականին կոմպլեքս փոփոխություններ: Այսպիսով,
  անգամ եթե 9-ը ճանաչվի ճիշտ, վարքագիծը այլ մուտքերի դեպքում կարող է անկառավարելիորեն
  փոխվել: Սա կշիռների և շեղման փոքրիկ փոփոխությամբ ցանցի վարքագիծը փոխելու հետևանքով
  նպատակին մոտենալը դարձնում է դժվարին: Կարող է պատահի այս խնդիրը շրջանցելու
  խելացի միջոց գոյություն ունի, սակայն միանգամից ակնհայտ չէ, թե ինչպես կարող ենք սովորեցնել
  պերսեպտրոնների ցանցին:
</p>

<p>
  Մենք կարող ենք շրջանցել այս խնդիրը ներմուծելով նոր տեսակի արհեստական նեյրոն,
  որը կոչվում է <em>սիգմոիդ</em> նեյրոն: Սիգմոիդ նեյրոնները նման են պերսոտրոններին,
  սակայն փոփոխված են այնպես, որ կշռի կամ շեղման փոքր փոփոխություններիը առաջացնում են
  փոքր փոփոխություններ ելքում: Սա է այն պայմանը, որի դեպքում սիգմոիդ նեյրոնների ցանցը կկարողանա
  սովորել:
</p>

<p>
  Նկարագրենք սիգմոիդ նեյրոնը: Կնկարենք այն այնպես ինչպես նկարել էինք պերսեպտրոնը.
  <center>
    <img src="images/tikz9.png"/>
  </center>
  Պերսեպտրոնի նման, սիգմոիդն ունի $x_1, x_2, \ldots$. մուտքեր: Սակայն $0$ կամ $1$-ի
  փոխարեն նրանք կարող են ընդունել կամայական արժեք $0$-ի և $1$-ի միջև: Օրինակ, $0.638\ldots$-ը
  ընդունելի աժեք է մուտքի համար: Ինչպես պերսեպտրոնը, սիգմոիդ նեյրոններն ունեն կշիռներ $w_1, w_2, \ldots$
  և շեղում $b$: Սակայն ելքը $0$ կամ $1$-ի փոխարեն $\sigma(w \cdot x+b)$ է, որտեղ $\sigma$ ֆունկցիան կոչվում է
  <em>սիգմոիդ</em>*
    <span class="marginnote">
      *Ի դեպ, $\sigma$-ն երբեմն կոչվում է <em>լոգիստիկ ֆունկցիա(logistic function)</em>, և հետևաբար,
      նեյրոնների այս նոր տիպը` <em>լոգիստիկ նեյրոններ(logistic neurons)</em>: Հետևյալ տերմինները նույնպես
      հաճախ օգտագործվող են, հետևաբար արժե տեղյակ լինել, սակայն այս գրքում մենք կօգտագործենք սիգմոիդ անվանումը:
    </span>:
  և սահմանվում է.

  <a class="displaced_anchor" name="eqtn3"></a>
  \begin{eqnarray}
    \sigma(z) \equiv \frac{1}{1+e^{-z}}.
    \tag{3}
  \end{eqnarray}

  Այսպիսով, սիգմոիդ նեյրոնի ելքը $x_1,x_2,\ldots$ մուտքերի, $w_1,w_2,\ldots$ կշիռների
  և $b$ շեղման դեպքում.

  <a class="displaced_anchor" name="eqtn4"></a>
  \begin{eqnarray}
    \frac{1}{1+\exp(-\sum_j w_j x_j-b)}.
    \tag{4}
  \end{eqnarray}
</p>

<p>
  Առաջին հայացքից սիգմոիդ նեյրոնները կարող են պերսեպտրոններից տարբեր թվալ:
  Սիգմոիդի տեսքը կարող է ոչ ակնհայտ լինել ետե ծանոթ չեք ֆունկցիայի հետ: Իրականում
  պերսեպտրոնների և սիգմոիդ նեյրոնների միջև կան բազմաթիվ նմանություններ:
</p>

<p>
  Որպեսզի հասկանանք այդ նմանությունները, ենթադրենք $z$-ը մեծ դրական թիվ է ներկայացված հետևյալ տեսքով`
  $z \equiv w \cdot x + b$: Հետևաբար, $e^{-z} \approx 0$ և $\sigma(z) \approx 1$:
  Այլ կերպ ասած, $z = w \cdot x+b$ մեծ և դրական է, սիգմոիդ նեյրոնի արժեքը մոտավորապես $1$ է
  (այնպես, ինչպես կլիներ պերսեպտրոնի համար): Մյուս կողմից ենթադրենք, որ $z = w \cdot x+b$ շատ փոքր
  բացասական թիվ է, ապա $e^{-z} \rightarrow \infty$ և $\sigma(z) \approx 0$, հետևաբար, եթե
  $z = w \cdot x +b$ շատ փոքր բացասական թիվ է, ապա սիգմոիդի արժեքը ձգտում է պերսեպտրոնի արժեքին:
  Միայն $w \cdot x+b$-ի ոչ մեծ բացարձակ արժեքների դեպքում է, որ սիգմոիդի ու պերսեպտրոնի մոդելները տարբերվում են:
</p>

<p>
  Իսկ ի՞նչ տեսք ունի $\sigma$-ն: Ինչպե՞ս հասկանանք այն: Իրականում $\sigma$-ի ճշգրիտ արժեքն էական չէ, էական է
  այն, թե ինչ տեսք ունի ֆունկցիայի գրաֆիկը: Ահա այն.
</p>

<p>
  <div id="sigmoid_graph"><a name="sigmoid_graph"></a></div>
  <script src="https://d3js.org/d3.v3.min.js"></script>
  <script>
    function s(x) {return 1/(1+Math.exp(-x));}
    var m = [40, 120, 50, 120];
    var height = 290 - m[0] - m[2];
    var width = 600 - m[1] - m[3];
    var xmin = -5;
    var xmax = 5;
    var sample = 400;
    var x1 = d3.scale.linear().domain([0, sample]).range([xmin, xmax]);
    var data = d3.range(sample).map(function(d){ return {
            x: x1(d),
            y: s(x1(d))};
        });
    var x = d3.scale.linear().domain([xmin, xmax]).range([0, width]);
    var y = d3.scale.linear()
                    .domain([0, 1])
                    .range([height, 0]);
    var line = d3.svg.line()
        .x(function(d) { return x(d.x); })
        .y(function(d) { return y(d.y); })
    var graph = d3.select("#sigmoid_graph")
        .append("svg")
        .attr("width", width + m[1] + m[3])
        .attr("height", height + m[0] + m[2])
        .append("g")
        .attr("transform", "translate(" + m[3] + "," + m[0] + ")");
    var xAxis = d3.svg.axis()
                      .scale(x)
                      .tickValues(d3.range(-4, 5, 1))
                      .orient("bottom")
    graph.append("g")
        .attr("class", "x axis")
        .attr("transform", "translate(0, " + height + ")")
        .call(xAxis);
    var yAxis = d3.svg.axis()
                      .scale(y)
                      .tickValues(d3.range(0, 1.01, 0.2))
                      .orient("left")
                      .ticks(5)
    graph.append("g")
        .attr("class", "y axis")
        .call(yAxis);
    graph.append("path").attr("d", line(data));
    graph.append("text")
         .attr("class", "x label")
         .attr("text-anchor", "end")
         .attr("x", width/2)
         .attr("y", height+35)
         .text("z");
    graph.append("text")
            .attr("x", (width / 2))
            .attr("y", -10)
            .attr("text-anchor", "middle")
            .style("font-size", "16px")
            .text("sigmoid function");
  </script>
</p>

<p>
  Սա քայլ ֆունկցիայի (step function) "հարթեցված" տարբերակն է:
</p>

<p>
  <div id="step_graph"></div>
  <script>
  function s(x) {return x < 0 ? 0 : 1;}
  var m = [40, 120, 50, 120];
  var height = 290 - m[0] - m[2];
  var width = 600 - m[1] - m[3];
  var xmin = -5;
  var xmax = 5;
  var sample = 400;
  var x1 = d3.scale.linear().domain([0, sample]).range([xmin, xmax]);
  var data = d3.range(sample).map(function(d){ return {
          x: x1(d),
          y: s(x1(d))};
      });
  var x = d3.scale.linear().domain([xmin, xmax]).range([0, width]);
  var y = d3.scale.linear()
                  .domain([0,1])
                  .range([height, 0]);
  var line = d3.svg.line()
      .x(function(d) { return x(d.x); })
      .y(function(d) { return y(d.y); })
  var graph = d3.select("#step_graph")
      .append("svg")
      .attr("width", width + m[1] + m[3])
      .attr("height", height + m[0] + m[2])
      .append("g")
      .attr("transform", "translate(" + m[3] + "," + m[0] + ")");
  var xAxis = d3.svg.axis()
                    .scale(x)
                    .tickValues(d3.range(-4, 5, 1))
                    .orient("bottom")
  graph.append("g")
      .attr("class", "x axis")
      .attr("transform", "translate(0, " + height + ")")
      .call(xAxis);
  var yAxis = d3.svg.axis()
                    .scale(y)
                    .tickValues(d3.range(0, 1.01, 0.2))
                    .orient("left")
                    .ticks(5)
  graph.append("g")
      .attr("class", "y axis")
      .call(yAxis);
  graph.append("path").attr("d", line(data));
  graph.append("text")
       .attr("class", "x label")
       .attr("text-anchor", "end")
       .attr("x", width/2)
       .attr("y", height+35)
       .text("z");
  graph.append("text")
          .attr("x", (width / 2))
          .attr("y", -10)
          .attr("text-anchor", "middle")
          .style("font-size", "16px")
          .text("step function");
  </script>
</p>

<p>
  Եթե $\sigma$-ն լիներ քայլ ֆունկցիան, ապա սիգմոիդ նեյրոնը կլիներ պերսեպտրոնը,
  քանի որ ելքում կստացվեին $1$ կամ $0$ արժեքները կախված նրանից, թե $w\cdot x+b$
  դրական է, թե բացասական*:

  <span class="marginnote">
    *Իրականում, $w \cdot x +b = 0$ պերսեպտրոնի արժեքը $0$ է, երբ քայլ ֆունկցիայի
    արժեքը $1$ է: Այսպիսով, ճշգրիտության համար նշեմ, որ կարիք կլինի փոխել քայլ ֆունկցիայի
    արժեքը այդ կետում: Սակայն պարզ է ընդհանուր գաղափարը:
  </span>

  Օգտագործելով $\sigma$ ֆունկցիան, մենք ստանում ենք պերսեպտրոնի փոքր-ինչ հարթեցված
  տարբերակը, ինչը ամենակարևորն է, քանի որ դա նշանակում է՝ որ կշռի $\Delta w_j$ և շեղման
  $\Delta b$ փոքր փոփոխությունների արդյունքում վերջնական արժեքի փոփոխությունը $\Delta \mbox{output}$
  կլինի նույնպես փոքր: Ըստ էության, $\Delta \mbox{output}$ կարելի է մոտարկել

  <a class="displaced_anchor" name="eqtn5"></a>
  \begin{eqnarray}
    \Delta \mbox{ելք} \approx \sum_j \frac{\partial \, \mbox{ելք}}{\partial w_j}
    \Delta w_j + \frac{\partial \, \mbox{ելք}}{\partial b} \Delta b,
    \tag{5}
  \end{eqnarray}

  որտեղ գումարն ըստ բոլոր $w_j$ կշիռների է, իսկ $\partial \,
  \mbox{ելք} / \partial w_j$ և $\partial \, \mbox{ելք} /\partial
  b$ $\mbox{ելք}$-ի  մասնակի ածանցյալներն են ըստ $w_j$ և $b$ փոփոխականների
  համապատասխանաբար: Խուճապի մի մատնվեք, եթե հարմարավետ չեն մասնակի ածանցյալները
  ձեզ համար: Կարող է թվալ, որ վերևի արտահայտությունը բարդ է, սակայն այն ուղղակի նշանակում է,
  որ  $\Delta \mbox{ելք}$-ը գծային ֆունկցիա է $\Delta w_j$ և $\Delta b$ կշիռների և շեղման
  փոփոխություններից կախված: Գծայնությունը թույլ է տալիս հեշտությամբ ընտրել փոքր փոփոխություն
  կշիռների և շեղումների համար, որը կհանգեցնի փոքր փոփոխություն ելքում: Այսպիսով, սիգմոիդները
  ունենալով պերսեպտրոններին նման որակական հատկանիշներ, միաժամանակ թույլ են տալիս հեշտությամբ
  հասկանալ, թե ինչպես կազդի կշիռների և շեղման փոփոխությունը նեյրոնի ելքում:
</p>

<p>
  Քանի որ $\sigma$ ֆունկցիայի գրաֆիկի տեսքն է ավելի կարևոր, քան ֆունկցիան ինքնին, ապա ինչու՞
  օգտագոեծենք $\sigma$-ի
  <span id="margin_850263336921_reveal" class="equation_link">(3)</span>
  <span id="margin_850263336921" class="marginequation" style="display: none;">
    <a href="chap1.html#eqtn3" style="padding-bottom: 5px;" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';">
      \begin{eqnarray}
        \sigma(z) \equiv \frac{1}{1+e^{-z}} \nonumber
      \end{eqnarray}
    </a>
  </span>
  <script>
    $('#margin_850263336921_reveal').click(function() {$('#margin_850263336921').toggle('slow', function() {});});
  </script>
  -ում տրված տեսքը: Ըստ էության ավելի ուշ մենք կտեսնենք նեյրոններ, որոնց աեժեքը $f(w \cdot x + b)$ է
  որևիցէ այլ $f(\cdot)$ <em>ակտիվացման ֆունկցիայի</em> դեպքում: Ակտիվացման ֆունկցիայի փոփոխության
  հետևանքով կարող են փոխվել միայն մասնակի ածանցյալների արժեքները

  <span id="margin_444952422305_reveal" class="equation_link">(5)</span>
  <span id="margin_444952422305" class="marginequation" style="display: none;">
    <a href="chap1.html#eqtn5" style="padding-bottom: 5px;" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';">
      \begin{eqnarray}
      \Delta \mbox{ելք} \approx \sum_j \frac{\partial \, \mbox{ելք}}{\partial w_j}
      \Delta w_j + \frac{\partial \, \mbox{ելք}}{\partial b}
      \Delta b \nonumber\end{eqnarray}
    </a>
  </span>
  <script>
    $('#margin_444952422305_reveal').click(function() {$('#margin_444952422305').toggle('slow', function() {});});
  </script>

  հավասարման մեջ: Հեշտ է նկատել նաև, որ վերոնշյալ մասնակի ածանցյալներ հաշվելիս $\sigma$ ֆունկցիան
  կհեշտացնի հաշվելու գործընթացը, քանի որ էքսպոնենցիալ ֆունկցիաները դիֆերենցելիս ունեն հրաշալի հատկություններ:
  Այնուամենայնիվ, $\sigma$-ն բավականին տարածված է նեյրոնային ցանցերում որպես ակտիվացման ֆունկցիա, և մենք
  այն կօգտագործենք բավականին հաճախ այս գրքում:
</p>

<p>
  Իսկ ինչպես պետք է մեկնաբանել սիգմոիդ նեյրոնի ելքը (արժեքը): Հեշտ է նկատել, որ
  պերսեպտրոնին համեմատ, սիգմոիդ նեյրոնի ելքում միայն $0$ կամ $1$ չէ, այլ արժեքներ
  $0$-ից $1$-ի միջև (օրինակ $0.173\ldots$ կամ $0.689\ldots$ և այլն): Այդ հատկությունը
  կարելի է օգտագործել բազմաթիվ ձևերով: Օրինակ, այն կարելի է օգտագործել ելքային արժեքը
  որպես նկարի (որպես մուտք նեյրոնային ցանցին) պիքսելների միջին ինտենսիվություն ներկայացնելու համար:
  Սակայն երբ նպատակը ելքում բինար արժեք ներկայացնելն է (օրինակ մուտքային նկարը "9" է կամ "9" չէ),
  ապա այդ դեպքում կարելի է օգտագործել այլ ստրատեգիա` եթե արժեքը $0.5$-ից փոքր է, ապա "9" է և
  համապատասխանաբար "9" չէ երբ ելքի արժեքը $0.5$-ից փոքր չէ: Նմանատիպ պայմանավորվածությունները
  միշտ հստակ կնշվեն գրքի հետագա քննարկումներում, որպեսզի շփոթություն չառաջանա:
</p>

<p>
  <h4>
    <a name="exercises_191892"></a>
    <a href="#exercises_191892">Վարժություններ</a>
  </h4>
  <ul>
    <li>
    <strong>Պերսեպտրոն սիմուլացնող սիգմոիդ նեյրոններ, մաս I</strong>
    $\mbox{}$ <br/>
    Ենթադրենք պերսեպտրոնների ցանցի բոլոր շեղումները և կշիռները բազմապատկում ենք
    $c > 0$ դրական հաստատունով: Ցույց տվեք, որ ցանցի վարքագիծը դրանից չի փոխվում:
    </p><p>
    <li>
      <strong>Պերսեպտրոն սիմուլացնող սիգմոիդ նեյրոններ, մաս II</strong>
      $\mbox{}$ <br/>
      Դիտարկենք պերսեպտրոնների ցանց: Ենթադրենք ցանցի մուտքն արդեն ընտրված է:
      Մուտքային արժեքը էական չէ, էական է այն, որ այն ֆիքսված է:
      Ենթադրենք կշիռներն ու շեղումները բավարարում են $w \cdot x + b \neq 0$ պայմանին
      $x$ մուտքի և ցանցի կամայական պերսեպտրոնի համար: Այժմ փոխարինենք ցանցի բոլոր պերսեպտրոնները
      սիգմոիդ նեյրոններով և բազմապատկենք կշիռներն ու շեղումները $c > 0$ հաստատունով:
      Ցույց տվեք, որ երբ $c \rightarrow \infty$, ապա սիգմոիդ նեյրոնների ցանցի վարքագիծը
      նույնն է, ինչ պերսեպտրոնների ցանցինը: Ինչպե՞ս վերոնշյալ հատկությունը կարող է տեղի չունենալ
      գոնե մեկ պերսպտրոնի համար, որը չի բավարարում $w \cdot x + b = 0$ պայմանին:
</ul>
</p>

<p>
  <h3>
    <a name="the_architecture_of_neural_networks"></a>
    <a href="#the_architecture_of_neural_networks">
      Նեյրոնային ցանցերի կառուցվածքը
    </a>
  </h3>
</p>


<p>
  Հաջորդ բաժնում կներկայացնենք նեյրոնային ցանց, որը բավականին հաջողությամբ կարողանում է
  դասակարգել ձեռագիր թվանշանները: Որպես նախապատրաստական աշխատանք, նպատակահարմար է
  բացատրել որոշ տերմիններ, որը մեզ թույլ կտա անվանումներ տալ ցանցի բաղադրիչներին: Ենթադրենք, որ
  ունենք որևէ ցանց.
  <center>
    <img src="images/tikz10.png"/>
  </center>
  Հայտնի է արդեն, որ ամենից ձախ գտնվող շերտը կոչվում է մուտքային շերտ, որին պատկանող
  նեյրոնները համապատասխանաբար կոչվում են <em>մուտքային նեյրոններ</em>: Աջակողմյան շետը
  կոչվում է <em>ելքային</em> (վերը նշված դեպքում միակ ելքային նեյրոն): Միջին շերտերը կոչվում են
  <em>թաքնված շերտեր</em>, քանի որ այս շերտի նեյրոնները ոչ մուտքային են, ոչ ելքային: Չնայած նրան,
  որ թաքնված տերմինը միստիկ հնըչողություն ունի, սակայն այն ոչ մի խորը մաթեմատիկական կամ փիլիսոփայական
  նշանակություն չունի, այն պարզապես նշանակում ո՛չ մուտքային, ո՛չ ելքային: Վերևում նկարված ցանցը
  ունի միայն մեկ թաքնված շերտ, սակայն որոշ ցանցեր ունենբազմաթիվ թաքնված շերտեր: Օրինակ, հետևյալ
  չորս շերտանոց ցանցն ունի երկու թաքնված շերտ.
  <center>
    <img src="images/tikz11.png"/>
  </center>
  Նշենք, որ պատմականորեն, այդպիսի բազմաշերտ ցանցերը ինչ-ինչ պատճառով կոչվում են
  <em>բազմաշերտ պերսեպտրոններ</em>` չնայած անյն փաստին, որ իրենք կառուցված են սիգմոիդներից
  այլ ոչ պերսեպտրոններից: Մենք չենք օգտագործի այդպիսի տերմինաբանություն, քանի-որ այն
  շփոթոյթյան մեջ կարող է գցել ընթերցողին:
</p>

<p>
  Մուտքային և ելքային շերտերի կառուցվածքները հիմնականում ակնհայտ են լինում:
  Օրինակ, ենթադրենք ցանկանում ենք պարզել արդյոք ձեռագիր թվանշանը
  ցույց է տալիս "9" թիվը: Ցանցը կառուցելու բնական մեթոդը կլինի նկարի պիքսելների
  խտության արտապատկերումը մուտքային նեյրոններին: Եթե նկարը $64$-ը $64$-ի վրա
  անգույն նկար է, այդ դեպքում կունենանճ $4,096 = 64 \times 64$ մուտքային նեյրոններ,
  որտեղ խտությունները նորմավորված են $0$-ից $1$ միջակայքում: Ելքային շերտը կպարունակի
  միայն մեկ նեյրոն, որի արժեքի $0.5$-ից մեծ լինելը կնշանակի նկարը 9 է, իսկ փոքր լինեու դեպքպւմ` ոչ:
</p>

<p></p><p></p>

<p>
  Մինչդեռ նեյրոնային ցանցի մուտքային և ելքային շերտերի կառուցվածքը հիմնականում ակնհայտ է, սակայն
  թաքնված շերտերի կառուցվածքը կարող է էապես բարդ լինել: Բավականին դժվար է ընդհանուր բնութագրել
  թաքնված շերտերի կառուցման պրոցեսը մի քանի ընդհանուր պնդումներով: Փոխարենը նեյրոնային ցանցեր
  հետազոտողները ստեղծել են բազմաթիվ կառուցվածքներ, մոտեցումներ, որոնք օգնում են ստանալ նպատակային
  արդյունքը` օգտագործելով նեյրոնային ցանցեր: Մենք կհանդիպենք այդպիսի կառուցվածքներից մի քանիսին
  ավելի ուշ գրքում:
</p>

<p>
  Մինչ այժմ մենք քննարկում էինք այնպիսի նեյրոնային ցանցեր, որոնցում մի շերտի ելքն
  օգտագործվում է որպես մուտք հաջորդ շերտի համար: Այդպիսի ցանցերը կոչվում են
  <em>առաջաբեր(feedforward)</em> նեյրոնային ցանցեր: Սա նշանակում է, որ ցանցում
  չկան ցիկլեր. ինֆորմացիան միշտ առաջ է բերվում և ոչ մի դեպքում ետ: Եթե թույլ տայինք ցիկլեր,
  ապա կստացվեր, որ $\sigma$-ի մուտքը կախված կլիներ ելքից, այդ պատճառով մենք թույլ չենք տալիս
  այդպիսի ցիկլեր:
</p>

<p>
  Սակայն գոյություն ունեն այնպիսի նեյրոնային ցանցեր, որոնց մեջ ցիկլերը հնարավոր են:
  Այդպիսի մոդելները կոչվում են <a href="http://en.wikipedia.org/wiki/Recurrent_neural_network">ռեկուրենտ նեյրոնային ցանցեր</a>: Գաղափարը կայանում է նրանում, որ այդպիսի մոդելներում նեյրոնը
  աշխատի ինչ-որ սահմանափակ ժամանակ մինչև պասիվանալը: Այդ աշխատանքը կարող է խթանել
  այլ նեյրոններին, որպեսզի նրանք էլ սկսեն աշխատել ինչ-որ ժամանակ անց ինչ-որ չափավոր ժամանակով:
  Այդ իր հերթին հանգեցնում է նոր նեյրոնների աշխատանքին, այսպիսով հանգեցնելպվ նեյրոններ կասկադային
  աշխատանքին: Ցիկլերն այս դեպքում ոչնչի վրա չեն ազդում, քանի որ նեյրոնի ելքը ազդեցություն ունի
  մուտքի վրա ինչ-որ ժամանակ անց, այլ ոչ անմիջապես:
</p>

<p></p>

<p>
  Ռեկուրենտ նեյրոնային ցանցերում հետազոտությունները ժամանակի ընթացքում ավելանում են,
  հետևաբար նաև կիրառությունները: Այս տեսակի ցանցերը ըստ էության, ավելի մոտիկ են ուղեղի
  աշխատանքի մոդելին, քան առաջաբեր ցանցերը: Ռեկուրենտ ցանցերն ունակ են լուծելու այնպիսի
  խնդիրներ, որոնք առաջաբեր ցանցերի համար մեծ դժվարություն են ներկայացնում: Այնուամենայնիվ,
  սահմանափակելով մեր շրջանակը, այս գրքում կկենտրոնանք ավելի լայնորեն կիրառվող առաջաբեր
  ցանցերի վրա:
</p>

<p>
  <h3>
    <a name="a_simple_network_to_classify_handwritten_digits"></a>
    <a href="#a_simple_network_to_classify_handwritten_digits">
      Պարզ ցանց ձեռագիր թվանշանները ճանաչելու համար
    </a>
  </h3>
</p>

<p>
  Վերադառնանք ձեռագիր թվերի ճանաչման խնդրին: Մենք կարող ենք խնդիրը բաժանել
  երկու ենթախնդիրների: Առաջինը` բաժանենք բազմաթիվ նկարներ պարունակող նկարը
  մի թվանշան պարունակող նկարների հերթականության: Օրինակ, մենք նպատակադրված ենք
  բաժանել հետևյալ նկարը.
</p>

<p><center><img src="images/digits.png" width="300px"></center></p>

<p>
  6 առանձին նկարների,
</p>

<p><center><img src="images/digits_separate.png" width="440px"></center></p>

<p>
  Մենք` մարդիկս այս <em>սեգմենտացիայի խնդիրը</em> հեշտությամբ ենք լուծում, սակայն
  համակարգչային ծրագրի համար հեշտ խնդիր չէ նկարը ճշգրիտ բաժանելը: Նկարը մասնատելուց հետո
  ծրագիրը պետք է տարբերակի յուրաքանչյուր առանձին թվանշան: Օրինակ, մենք կուզենայինք, որ մեր
  ծրագիրը վերևի թվերից առաջինը ճանաչեր որպես 5.
</p>

<p><center><img src="images/mnist_first_digit.png" width="64px"></center></p>

<p>
  Կենտրոնանք վերը նշված խնդիրներից երկրորդի վրա, այն է` ինդիվիդուալ թվանշանների տարբերակման
  խնդիրը: Ընտրում ենք այս ուղղությունը, քանի որ պարզվում է, որ բաժանման խնդիրն այդքան էլ դժվար չէ լուծելը,
  եթե ունես թվանշանները տարբերակելու լավ լուծում: Բաժանման խնդիրը լուծելու բազմաթիվ
  մոտեցումներ կան: Մոտեցումներից մեկն է` փորձել տարբեր ձևերով բաժանել և թույլ տալ, որպեսզի թվանշաններ
  ճանաչող ծրագիրը գնահատականներ տա բաժանումներին: Բաժանումը գնահատվում է կախված նրանից թե ինդիվիդուալ
  թվանշան տարբերակող ծրագիրն ինչքան "վստահ" բաժանվածի բոլոր մասերում տարբերակված թվանշանների
  հարցում, ընդ որում` որքան շատ են այն բաժինները, որում տարբերակումը վստահ չէ, այնքան ավելի ցածր է գնահատականը:
  Իդեան կայանում է նրանում, որ եթե տարբերակող ծրագիրը դժվարանում է տարբերակել գոնե մի բաժնում, ապա դրա
  պատճառն  ամենայն հավանականությամբ սխալ բաժանման մեջ է կայանում: Ընդ որում սա օրինակներից մեկն է, թե ինչպես կարելի
  է լուծել բաժանման խնդիրը: Այդ իսկ պատճառով, բաժանման խնդրի փոխարեն մենք կկենտրոնանանք թվանշաններ
  ճանաչելու համար նախատեսված նեյրոնային ցանց նախագծելու վրա:
</p>

<p>
  Ինդիվիդուալ թվանշան ճանաչելու նպատակով մենք կկառուցենք եռաշերտ նեյրոնային ցանց.
</p>

<p>
  <center><img src="images/tikz12.png"/></center>
</p>

<p>
  Ցանցի մուտքային շերտը պարունակում է կոդավորված մուտքային պիքսելները: Ինչպես քննարկվում է
  հաջորդ բաժնում, ուսուցման տվյալները իրենցից ներկայացնում են $28$ պիքսել երկարությամբ և լայնությամբ
  ձեռագիր թվանշանների նկարներ, հետևաբար մուտքային շերտը պարունակում է $784 = 28 \times 28$
  նեյրոններ: Պարզության համար, վեևրևի գծանկարում $784$ նեյրոններից շատերը բաց են թողնված: Մուտքային
  պիքսելները մոխրագույն են, այնպես, որ $0.0$-ն ներկայացնում է սպիտակը իսկ $1.0$-ը` սևը, իսկ այդ միջակայքում
  գտնվող արժեքները ներկայացնում են մոխրագույնի աստիճանաբար մգացող երանգները:
</p>

<p>
  Ցանցի երկրորդ շերտը թաքնված է: Երկրորդ շերտի նեյրոնների քանակը նշանակենք $n$, որի
  արժեքի շուրջ կկատարենք բազմաթիվ փորձեր: Օրինակը ներկայացնում է համեմատաբար
  փոքր թաքնված շերտ, որը պարունակում է $n = 15$ նեյրոններ:
</p>

<p>
  Ցանցի ելքային շերտը պարունակում է 10 նեյրոններ: Եթե առաջին նեյրոնի արժեքը, օրինակ
  $\approx 1$ (մոտ է 1-ին), ապա դա նշանակում է, որ ցանցը կարծում է, որ թվանշանը $0$ է:
  Երբ երկրորդ նեյրոնն ունի այդ հատկությունը, ապա դա կնշանակի, որ ցանցը կարծում է՝, որ
  թվանշանը $1$ է և այդպես շարունակ: Այսպիսով, մենք ելքային նեյրոնները համարակալում ենք
  $0$-ից $9$ և պարզում, թե որ նեյրոնն ունի մեծագույն ակտիվացիայի արժեքը: Եթե այդ նեյրոնը,
  ենթադրենք, $6$-ն է, ապա ցանցը ցույց է տալիս, որ թվանշանը $6$-ն է և այդպես շարունակ:
</p>

<p>
  Հարց է առաջանում, թե ինչու ենք օգտագործում $10$ ելքային նայրոններ: Վերջիվերջո
  ցանցի նպատակն է ցույց տալ, թե ($0, 1, 2, \ldots, 9$) թվանշաններից որին է
  համապատասխանում մուտքային նկարը: թվում է բնական է օգտագործել ելքային $4$ նեյրոն,
  որոնցից յուրաքանչյուրը կունենա բինար արժեք` կախված նրանից, թե $0$-ից $1$ միջակայքի
  որ մասում է արժեքը: Չորս նեյրոնները բավարար են պատասխանը կոդավորելու հանար,
  քանի որ $2^4 = 16$, որը մեծ է 10 հնարավոր արժեքների քանակից: Ինչու՞ մեր ցանցը $10$
  նեյրոն օգտագործի փոխարենը: Միթե դա ոչ էֆֆեկտիվ չէ: Պատասխանը էմպիրիկ է. իրականում կարելի
  է փորձել երկու ձևերով էլ: Պարզվում է, որ հենց այս խնդիրը $10$ ելքային նեյրոններով ավելի լավ
  է սովորում թվանշանները ճանաչել, քան $4$ ելքային նեյրոններով: Այնումամենայնիվ, մեզ հետաքրքիր է,
  թե <em>ինչու</em> է $10$ ելքերով ցանցն աշխատում ավելի լավ: Հնարավո՞ր է արդյոք նախորոք
  որոշել, թե $10$ կամ $4¢ է պետք օգտագործել:
</p>

<p>
  Որպեսզի պարզենք, թե ինչու ենք այդպես վարվում, փորձենք հասկանալ, թե ինչպես է աշխատում
  նեյրոնային ցանցը: Ենթադրենք օգտագործում ենք $10$ ելքային նեյրոններ: Դիտարկենք
  առաջին ելքային նեյրոնը, որը պատասխանատու է որոշելու համար արդյոք մոտքային նկարը $0$ է:
  Դա տեղի է ունենում թաքնված շերտերից ստացված "վկայությունները" "համեմատելով": Ի՞նչպես են աշխատում
  թաքնված շերտերը: Ենթադրենք թաքնված շերտի առաջին նեյրոնը որոշում է արդյոք ներքևում նշված նկարն
  առկա է, թե ոչ:
</p>

<p><center><img src="images/mnist_top_left_feature.png" width="130px"></center></p>

<p>
  Դա կարելի է անել մուտքային պիքսելներին, որոնք հատվում են նկարին համապատասխանող պիքսելների
  ծանր կշիռներ տալով և համեմատաբար թեթև կշիռներ տալով մնացած մոտքային պիքսելներին: Նույն ձևով,
  ենթադրենք, որ երկրորդ, երրորդ և չորրորդ նեյրոնները թաքնված շերտում որոշում են արդյոք հետևյալ նկարները
  ազատ են:
</p>

<p><center><img src="images/mnist_other_features.png" width="424px"></center></p>

<p>
  Ակնհայտ է, որ այդ չորս նկարները միասին կազմում են $0$ նկարը:
  <a href="#complete_zero">earlier</a>:
</p>

  <p><center><img src="images/mnist_complete_zero.png" width="130px"></center></p>

<p>
  Այսպիսով, եթե թաքնված նեյրոնների բոլոր 4 նեյրոնները աշխատում են, ապա
  եզրակացնում ենք, որ թվանշանը մոտ է $0$-ին: Իհարկե դա <em>միակ</em>
  միակ վկայությունը չէ, որից կարող ենք եզրալացնել, որ թվանշանը $0$-ն է: Մենք
  կարող ենք օրինականորեն ստանալ $0$ բազմաթիվ այլ ձևերով (օրինակ վերևի նկարների
  նկատմամբ փոփոխություններ կատարելով):
</p>

<p></p><p></p><p></p>

<p>
  Ենթադրելով, որ նեյրոնային ցանցն աշխատում է այսպես, կարող ենք տալ խելամիտ
  բացատրություն, թե ինչու է նպատակահարմար օգտագործել $10$ ելք $4$-ի փոխարեն:
  Եթե ունենայինք $4$ ելքեր, ապա առաջին ելքային նեյրոնը փորձելու էր որոշելու թվանշանի
  առաջին բիթը: Եվ հեշտ ձև չկա առաջին բիթը կապելու վերևում տրված պարզ նկարի հետ:
</p>

<p>
  Այսպիսով, այս ամենը ոչ ճշգրիտ է: Ոչնչից չի հետևում, որ պարզ եռաշերտ նեյրոնային
  ցանցը պարտավոր է աշխատել նկարագրված ձևով` թաքնված շերտերը գուշակելով պարզ
  կոմպոնենտների տեսքերը: Հնարավոր է, որ խելոք սովորող ալգորիթմը գտնի կշիռների
  այնպիսի դասավորվածություն, որը թույլ տա օգտագործել $4$ ելքային նեյրոններ:
</p>

<p>
  <h4>
    <a name="exercise_513527"></a>
    <a href="#exercise_513527">Վարժություն</a>
  </h4>
  <ul>
    <li>
      Գոյություւն ունի մոտեցում, որը հնարավորություն է տալիս գտնել թվի երկակի(բիթային) ներկայացումը
      վերևում նշված ցանցին ևս մեկ շերտ ավելացնելով: Նոր շերտը նախորդ շերտի շերտի արժեքը փոխակերպում է
      բինար ներկայացման ինչպես ներկայացված է ներքևում: Գտնել նոր ելքային շերտի կշիռներն ու շեղումները:
      Կարող եք ենթադրել, որ նեյրոնների առաջին $3$ շերտերն այնպիսին են, որ երրորդ շերտից ճիշտ արժէքը
      ունի ամենաքիչը $0.99$ հավանականություն և ոչ ճշգրիտ արժեքներն ունեն $0.01$-ից փոքր արժեք:
  </ul>
</p>

<p>
  <center><img src="images/tikz13.png"/></center>
</p>

<p></p><p></p><p></p>

<p>
  <h3>
    <a name="learning_with_gradient_descent"></a>
    <a href="#learning_with_gradient_descent">Գրադիենտային իջեցմամբ ուսուցում</a>
  </h3>
</p>

<p></p>

<p>
  Այժմ, երբ մենք ունենք նեյրոնային ցանցի կառուցվածք, ինչպես այն կարող է սովորել ճանաչել
  թվանշաններ: Առաջինն ինչ մեզ պետք է, դա ուսուցման համար նախատեսված տվյալների բազմությունն է
  (ուսուցման տվյալների բազմություն): Մենք կօգտագործենք
  <a href="http://yann.lecun.com/exdb/mnist/">MNIST տվյալների բազմությունը</a>,
  որը պարունակում է տաս հազարավոր ձեռագիր թվանշանների նկարներ իրենց ճշգրիտ թվային արժեքներով:
  MNIST անունը գալիս է նրանից, որ այն Միացյալ Նահանգների
  <a href="http://en.wikipedia.org/wiki/National_Institute_of_Standards_and_Technology">NIST</a>-ի
  (National Institute of Standards and Technology) կողմից հավաքագրված երկու տվյալների
  բազմությունների փոփոխության ենթարկված տարբերակն է: Ահա մի քանի նկարներ MNIST-ից:
</p>

<p>
  <center><img src="images/digits_separate.png" width="420px"></center>
</p>

<p>
  Ինչպես տեսնում եք այս թվանշաններն ըստ էության նույնն են ինչ ցույց էր տրված
  <a href="#complete_zero">գլխի սկզբում</a> որպես ճանաչման խնդիր: Իհարկե
  ցանցը սովորեցնելուց կփորձարկենք նկարների վրա, որոնք ուսուցման տվյալների բազմությունում
  չկան:
</p>

<p>
  MNIST-ի տվյալները բաղկացած են երկու մասից: Առաջին մասը պարունակում է 60,000
  նկարներ, որոնք կօգտագործվեն որպես ուսուցման տվյալներ: Այդ նկարները 250 մարդկանց
  սկանավորված ձեռագիր թվանշաններ են այնպես, որ մարդկանցից կեսը Միացյալ Նահանգների
  մարդահամարի բյուրոյի աշխատակիցներն են, մյուս կեսը ավագ դպրոցի աշակերտներ: Նկարները
  մոխրագույն են և 28-ը 28-ի վրա: MNIST տվյալների բազմության երկրորդ մասը 10,000 նկարներից
  է բաղկացած, որը կօգտագործվի որպես թեստային տվյալներ: Կրկին նկարները մոխրագույն են և 28-ը
  28-ի վրա: Մենք կօգտագործենք թեստային տվյալները որոշելու համար, թե ինչքան լավ է մեր նեյրոնային
  ցանցը սովորել թվանշանների ճանաչումը: Որպեսզի թեստավորումը լավը լինի, թեստային տվյալների բազմությունը
  վերցված է 250 <em>ուրիշ</em> մարդկանց բազմությունից: Սա մեզ վստահություն է տալիս, որ համակարգը
  կարող է ճանաչել այն մարդկանց ձեռագրերը, ոնը նախկինում չի հանդիպել ուսուցման ժամանակ:
</p>

<p>
  Ուսուցման մուտքը նշանակենք $x$-ով: Ընդ որում մուտքային $x$ վեկտորը $28 \times 28 =
  784$ չափանի վեկտոր է,որի ամեն անդամը ներկայացնում է մեկ պիքսելի մոխրագույն արժեքը:
  Նշանակենք համապատասխան ելքային արժեքը $y = y(x)$, որտեղ $y$-ը $10$ չափանի վեկտոր է:
  Օրինակ, եթե որոշակի ուսուցման վեկտորը ներկայացնում է 6 թվանշանը, ապա
  $y(x) = (0, 0, 0, 0, 0, 0, 1, 0, 0, 0)^T$ ցանցի ցանկալի ելքային վեկտորն է, որտեղ $T$-ն
  տրանսպոնացման գործողությունն է (որը տողային վեկտորը վերածում է սյունակային վեկտորի և հակառակը):
</p>

<p>
  Մեր նպատակն է գտնել մի այլպիսի ալգորիթմ, որը հնարավորություն է տալիս
  հաշվել այնպիսի կշիռներ և շեղումներ, որ ցանցի ելքային արժեքը մոտարկի $y(x)$-ը
  բոլոր $x$ մուտքային արժեքների դեպքում: Որպեսզի հաշվարկենք, թե ինչ հաջողություններ
  կան նպատակին հասնելու առումով, սահմանենք <em>արժեքի ֆունկցիա(cost function)</em>*
  <span class="marginnote">
    *Երբեմն հղվում են որպես <em>կորստի (loss)</em> կամ <em>նպատակային (objective)</em>
    ֆունկցիա: Մենք օգտագործում ենք արժեքի ֆունկցիա տերմինը գրքում, սակայն խորհուրդ է տրվում
    հաշվի առնել, որ նշված ալտերնատիվ տերմինները նույնպես լայն օգտագործում ունեն, հատկապես
    գիտական հոդվածներում:
  </span>:
  <a class="displaced_anchor" name="eqtn6"></a>
  \begin{eqnarray}  C(w,b) \equiv
    \frac{1}{2n} \sum_x \| y(x) - a\|^2.
  \tag{6}\end{eqnarray}

  Որտեղ $w$-ով նշանակված է ցանցում բոլոր կշիռների բազմությունը, $b$-ով նշանակված
  են բոլոր շեղումները, $n$-ը ուսուցման մուտքերի քանակն է, $a$-ն ցանցի ելքային վեկտորն է
  $x$ մուտքի դեպքում և գումարը բոլոր մուտքային $x$-երով է: Իհարկե, $a$ ելքային արժեքը
  կախված է $x$-ի, $w$-ի and $b$-ի արժեքներից, սակայն պարզությունը պահելու համար, այդ
  կախվածությունը նշված չէ բանաձևում: $\| v \|$ նշանակումը ցույց է տալիս $v$-ի երկարության
  ֆունկցիան: Կոչենք $C$-ն <em>քառակուսային</em> արժեքի ֆունկցիա. այն հայտնի է նաև որպես
  <em>Միջին Քառակուսային Սխալ</em>: Դիտարկելով քառակուսային արժեքի ֆունկցիան, եզրակացնում
  ենք, որ $C(w,b)$-ն ոչ բացասական է, քանի որ յուրաքանչյուր անդամը ոչ բացասական է: Ավելին,
  $C(w,b)$ արժեքը փոքրանում է (օրինակ $C(w,b) \approx 0$), երբ $y(x)$-ի արժեքը
  մոտենում է ելքային $a$ արժեքին բոլոր $x$ ուսուցման մուտքերի համար: Այսպիսով, կարելի է ասել,
  որ ալգորիթմը լավ է աշխատում, երբ այն կարողանում է գտնել կշիռների և շեղումների այնպիսի արժեքներ,
  որ $C(w,b) \approx 0$: Նմանապես, այն լավ չի աշխատում, երբ $C(w,b)$ մեծ արժեք ունի,
  ինչը նշանակում է $y(x)$ մոտիկ չէ $a$  ելքերին, մեծ քանակությամբ արժեքների դեպքում: Այսպիսով,
  մեր ուսուցման ալգորիթմի նպատակն է լինելւ մինիմիզացնել $C(w,b)$ արժեքը որպես ֆունկցիա կշիռներից
  և շեղումներից: Այսպիսով, մենք ուզում ենք գտնել այնպիսի կշիռների և շեղումների բազմություն, որը
  արժեքը դարձնում է ինչքան հնարավոր է փոքր: Մենք դա կանենք օտգագործելով
  <em>գրադիենտային իջեցման (gradient descent)</em> ալգորիթմը:
</p>

<p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p>

<p>
  Ինչու՞ դիտարկել քառակուսային արժեքը, չէ՞ որ մեր վերջնական նպատակն է
  ունենալ մեծ քանակությամբ նկարներ ճիշտ տարբերակված ցանցի կողմից:
  Ինչու՞ չմաքսիմիզացնել ճիշտ գուշակված նկարների քանակը, փոխարենը դիտարկելու
  այնպիսի մի միջանկյալ մեծություն ինչպիսին է քառակուսային արժեքը: Խնդիրը կայանում
  է նրանում, որ ճիշտ տարբերակված նկարների քանակի ֆունկցիան կախված ցանցի
  կշիռներից և շեղումից այնքան էլ հարմար չէ օպտիմիզացիայի խնդիր լուծելու համար:
  Այն է` կշիռների և շեղման փոքր փոփոխությունը չի հանգեցնի ոչ մի փոփոխության
  ճիշտ տարբերակված նկարների քանակի մեջ: Այդ իսկ պատճառով դժվար է հասկանալ,
  թե ինչպես փոփոխել կշիռներն ու շեղումները, որպեսզի բարելավվի ալգորիթմի կատարողականությունը:
  Պարզվում է, որ եթե փոխարենը վերցնենք այնպիսի արժեքի ֆունկցիա, ինչպիսին է քառակուսային
  արժեքի ֆունկցիան, կշիռների և սեղումների փոքր փոփոխությունները կհանգեցնեն արժեքի
  բարելավման: Այդ իսկ պատճառով, մենք սկզբում կկենտրոնանք արժեքի ֆունկցիան
  մինիմզացնելու վրա, այնուհետև կդիտարկենք տարբերակման ճշտությունը:
</p>

<p></p>

<p>
  Անգամ եթե հայտնի է, որ մենք ուզում ենք այնպիսի ֆունկցիա, որի հետ հեշտ լինի
  աշխատել օպտիմիզացիայի առումով, մեկ է հարց է առաջանում, թե ինչու ենք ընտրում
  հենց քառակուսային ֆունկցիան օգտագործված հավասարում

  <span id="margin_432054929623_reveal" class="equation_link">(6)</span>
  <span id="margin_432054929623" class="marginequation" style="display: none;">
    <a href="chap1.html#eqtn6" style="padding-bottom: 5px;" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';">\begin{eqnarray}  C(w,b) \equiv
    \frac{1}{2n} \sum_x \| y(x) - a\|^2 \nonumber\end{eqnarray}</a>
  </span>
  <script>
    $('#margin_432054929623_reveal').click(function() {$('#margin_432054929623').toggle('slow', function() {});});
  </script>-ում.

  Մի գուցե, եթե ընտրեինք այլ ֆունկցիա, կստանայինք մինիմիզացնող կշիռների և շեղումների այլ
  բազմություն: Սա արդարացված անհանգստություն է, և այդ պատճառով ավելի ուշ ետ
  կվերադառնանք արժեքի ֆունկցիային և կկատարենք որոշ փոփոխություններ: Այնուամենայնիվ,
  հավասարում

  <span id="margin_488284336334_reveal" class="equation_link">(6)</span>
  <span id="margin_488284336334" class="marginequation" style="display: none;">
    <a href="chap1.html#eqtn6" style="padding-bottom: 5px;" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';">\begin{eqnarray}  C(w,b) \equiv
  \frac{1}{2n} \sum_x \| y(x) - a\|^2 \nonumber\end{eqnarray}</a>
  </span>
  <script>
    $('#margin_488284336334_reveal').click(function() {$('#margin_488284336334').toggle('slow', function() {});});
  </script>-ի
  արժեքի ֆունկցիան հարմար է և բավարար նեյրոնային ցանցերի հիմնական կոնցեպտները
  սովորելու համար, հետևաբար, մենք կօգտագործենք դա:
</p>

<p>
  Ընդհանրացնելով, մեր նեյրոնային ցանցի ուսուցուման նպատակը կշիռների և շեղումների
  որոշումն է, որը մինիմիզացնում է $C(w, b)$ քառակուսային ֆունկցիայի արժեքը:
  Սա բավականին հստակ դրված խնդիր է, սակայն այն պարունակում է բազմաթիվ
  շեղող մասեր, օրինակ կշիռները, շեղումները, նեյրոնային ցանցի կառուցվածքը և այլն:
  Պարզվում է, որ մենք կարող ենք բավականին առաջընթաց ունենալ եթե արհամարհենք
  "արժեքի ֆունկցիայի ծագման պատմությունը" և կենտրոնանանք միայն մինիմիզացիայի
  վրա: Ենթադրենք, որ ունենք մեկից ավել փոփոխականներից ֆունկցիա և մեր նպատակն
  է մինիմիզացնել այդ ֆունկցիան: Մենք կկառուցենք <em>գրադիենտային իջեցման(gradient
  descent)</em> մոտեցումը, որը կօգտագործենք մինիմիզացիայի խնդիրը լուծելու համար:
  Այնուհերև կվերադառնանք նեյրոնային ցանցերի այն արժեքի ֆունկցիային, որը մենք ուզում
  ենք մինիմիզացնել:
</p>

<p>
  Այսպիսով, դիտարկենք $C(v)$ ֆունկցիան: Մեր նպատակն է այդ ֆունկցիայի մինիմիզացիան:
  Սա կարող է լինել կամայական $v = v_1, v_2, \ldots$ իրական փոփոխականների
  ֆունկցիա: Նկատենք, որ $w$ և $b$-ն փոխարինվել էին $v$-ով, որպեսզի ցույց տրվի,
  որ $C$-ն կարող է լինել կամայական ֆունկցիա. մենք նեյրոնային ցանցերի կոնտեքստով
  այլևս չենք մտածում: $C(v)$-ն մինիմզացնելու համար, ենթադրենք այն երկու
  փոփոխականի ֆունկցիա է` $C(v_1, v_2)$:
</p>

<p>
  <center><img src="images/valley.png" width="542px"></center>
</p>

<p>
  Մեր նպատակն է գտնել $C$-ի մինիմումի կետ(եր)ը: Իհարկե, եթե դիտարկենք
  վերևում պատկերված ֆունկցիայի գրաֆիկը, ապա կարող ենք տեսնել մինիմումի
  կետը: Սակայն դա բավականին պարզ ֆունկցիա է, համեմատած իրականության
  մեջ հանդիպող $C$-ի ավելի բարդ կառուցվածքներին (մեկից ավել փոփոխականի
  ֆունկցիաներ, որոնց գրաֆիկից ակնհայտ չէ մինիմումի կետերը):
</p>

<p>
  Ուրիշ հնարավոր լուծում է օգտագործել մաթեմատիկական անալիզի գործիքները
  և գտնել մինիմումը անալիտիկորեն: Մենք կարող ենք հաշվել ածանցյալները և
  փորձել գտնել $C$-ի էքստրեմումի կետերը: Սա հնարավոր է, որ աշխատի, եթե
  $C$-ն մեկ կամ երկու փոփոխականների ֆունկցիա է, սակայն խնդիրը էապես
  կբարդանա, եթե մենք ունենանք շատ ավելի մեծ քանակությամբ փոփոխականներ:
  Նեյրոնային ցանցերի համար հատկապես փոփոխականների քանակը շատ ավելի շատ է:
  Մեծ ցանցերում արժեքի ֆունկցիաները կարող են կաված լինել միլլիոնավոր կշիռներից
  և շեղումներից (ընդ որում, լիելով բավականին բարդ կառուցվածքով ֆունկցիա):
  Այսպիսով, օգտագործելով մաթեմատիկական անալիզը, պրակտիկորեն հնարավոր չէ
  գտնել մինիմումի կետերը անալիտիկորեն:
</p>

<p><a name="gradient_descent"></a></p>

<p>
  Բարեբախտաբար, հայտնի է ալգորիթմ, որը օգտագործելով կարող ենք լուծել խնդիրը:
  Դիտարկենք հետևայլ անալոգիան: Մտածենք մեր ֆոունկցիայի մասին որպես հովիտ:
  Պատկերացնենք, որ գնդակը գլորվում է հովիտով դեպի ներքև: Ելնելով ամենօրյա մեր
  փոձից, կարող ենք ասել, որ գնդակը վերջիվերջո կհասնի հովիտի ստորոտին: Փոսձենք
  օգտագործել այս գաղափարը որպես մինիմումի կետը գտնելու մեթոդ: Մենք կընտրենք
  պատահական կետ որպես գնդակի սկզբնակետ և կսիմուլացնենք գնդակի ներքև գլորվելը
  ամեն քայլում որոշելով, թե որն է լինելու գնդակի գլորման ուղղությունը (կամ հաջորդ
  կետը, որով անցնելու է գնդակը): Մենք դա կարող ենք իրականացնել հաշվելով $C$-ի
  ածանցյալները (երբեմն նաև երկրորդ կարգի): Այդ ածանցյալները մեզ ցուցյց կտան, թե
  ինչպիսի "տեսք" ունի հովիտը և, հետևաբար, թե ինչպես մեր գնդակը պետք է գլորվի:
</p>

<p>
  Տպավորություն կարող է ստեղծվել, որ մենք սկսելու ենք օգտագործել Նյուտոնյան
  շարժման հավասարումները գնդակի համար` հաշվի առնելով գրավիտացիան, արագացումը
  և այլն: Իրականում մենք գլորվող գնդակի անալոգիային այդպես լրջորեն չենք վերաբերվելու.
  մենք դուրս ենք բերում $C$-ի մինիմիզացնելու ալգորիթմ, այլ ոչ ֆիզիկայի օրենքների
  ճշգրիտ սիմուլյացիա: Գնդակի օրինակն ուղղակի նախատեսված է պատկերացում կազմելու
  համար, թե ինչ ալգորիթմ ենք պատրաստվում կառուցել: Այսպիսով, եթե մենք ունենայինք
  սուպեր կարողություններ և կարողանայինք պարտադրել սեփական ֆիզիկայի կանոնները` գնդակին
  թելադրելով, թե ինչպես այն պետք է շարժվի, ապա ի՞նչ օրենքներով կորոշեինք գնդակի
  շարժումն այնպես որ այն միշտ գլորվեր դեպի ստորոտը:
</p>

<p>
  Որպեսզի ճշգրտենք այս հարցը, ապա դիտարկենք, թե ինչ կպատահի, եթե
  գնդակը շարժենք $\Delta v_1$-ով $v_1$ ուղղությամբ և $\Delta v_2$-ով
  $v_2$-ի ուղղությամբ: Այսպիսով, $C$-ի փոփոխությունը կարելի է հաշվել հետևյալ
  բանաձևով.

  <a class="displaced_anchor" name="eqtn7"></a>
  \begin{eqnarray}
    \Delta C \approx \frac{\partial C}{\partial v_1} \Delta v_1 +
    \frac{\partial C}{\partial v_2} \Delta v_2.
  \tag{7}\end{eqnarray}

  Եթե $\Delta C$-ն բացասական է, դա կնշանակի, որ $C$-ն նվազում է, այսինքն,
  ըստ մեր անալոգիայի, գնդակը գլորվում է դեպի ստորոտ: Հետևաբար, պետք է ընտրենք
  $\Delta v_1$-ի և $\Delta v_2$-ի այնպիսի արժեքներ, որպեսզի $C$-ն նվազի ամեն
  քայլից հետո: Փորձենք գտնել այդպիսի փոփոխություններ: Նշանակենք
  $\Delta v \equiv (\Delta v_1, \Delta v_2)^T$, որտեղ $T$-ն տրանսպոնացման
  գործողությունն է: Նշանակենք որպես $C$-ի <em>գրադիենտ</em> մասնակի ածանցյալների
  վեկտորը` $\left(\frac{\partial C}{\partial v_1}, \frac{\partial C}{\partial
  v_2}\right)^T$. Նշանակենք գրադիենտային վեկտորը հունական նաբլա տառով` $\nabla C$.

  <a class="displaced_anchor" name="eqtn8"></a>
  \begin{eqnarray}
  \nabla C \equiv \left( \frac{\partial C}{\partial v_1},
  \frac{\partial C}{\partial v_2} \right)^T.
  \tag{8}\end{eqnarray}

  Հարկ է նշել, որ $\nabla C$ նշանակումը հնարավոր է ինտերպրետացնել ոչ միանշանակ:
  Այն կարելի է դիտարկել որպես մաթեմատիկական օբյեկտ կախված երկու մասից, որոնցից
  $\nabla$-ն ուղղակի նշանակում է, որ գրվածը գրադիենտ վեկտոր է: Սակայն կարելի է
  $\nabla$-ն դիտարկել որպես անկախ մաթեմատիկական ոբյեկտ, որտեղ այն հանդես է գալիս,
  օիրնակ որպես դիֆերենցման օպերատոր: Պայմանավորվենք դիտարկել $\nabla C$-ն առաջին
  նկարագրված (ավելի պարզեցված) ձևով:
</p>

<p>

  Արտագրենք
  <span id="margin_659965637148_reveal" class="equation_link">(7)</span>
  <span id="margin_659965637148" class="marginequation" style="display: none;">
    <a href="chap1.html#eqtn7" style="padding-bottom: 5px;" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';">
    \begin{eqnarray}
      \Delta C \approx \frac{\partial C}{\partial v_1} \Delta v_1 +
    \frac{\partial C}{\partial v_2} \Delta v_2 \nonumber\end{eqnarray}
    </a>
  </span>
  <script>
    $('#margin_659965637148_reveal').click(function() {$('#margin_659965637148').toggle('slow', function() {});});
  </script>
  արտահայտությունը որպես

  <a class="displaced_anchor" name="eqtn9"></a>
  \begin{eqnarray}
    \Delta C \approx \nabla C \cdot \Delta v.
  \tag{9}\end{eqnarray}

  Այս հավասարումն օգնում է բացատրել, թե ինչու է $\nabla C$-ն կոչվում
  գրադիենտ: Այն ցույց է տալիս, թե ինչպես է $C$-ի փոփոխությունը կախված
  $v$-ի փոփոխությունից: Հետևաբար, այն հնարավորություն է տալիս $\Delta v$-ն
  այնպես ընտրել, որ $\Delta C$-ն ստանա բացասական արժեք: Ենթադրենք, որ
  ընտրում ենք

  <a class="displaced_anchor" name="eqtn10"></a>
  \begin{eqnarray}
  \Delta v = -\eta \nabla C,
  \tag{10}\end{eqnarray}

  որտեղ $\eta$-ն բավականաչափ փոքր դրական թիվ է (հայտնի որպես
  <em>ուսուցման գործակից (learning rate)</em>).

  Հավասարում
  <span id="margin_859162866010_reveal" class="equation_link">(9)</span>-ը
  <span id="margin_859162866010" class="marginequation" style="display: none;">
    <a href="chap1.html#eqtn9" style="padding-bottom: 5px;" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';">
      \begin{eqnarray}
      \Delta C \approx \nabla C \cdot \Delta v \nonumber\end{eqnarray}
    </a>
  </span>

  <script>
    $('#margin_859162866010_reveal').click(function() {$('#margin_859162866010').toggle('slow', function() {});});
  </script>

  ցույց է տալիս, որ
  $\Delta C \approx -\eta \nabla C \cdot \nabla C = -\eta \|\nabla C\|^2$.
  Քանի որ $\| \nabla C \|^2 \geq 0$, ապա $\Delta C \leq 0$, հետևաբար $C$-ն միշտ կնվազի,
  եթե $v$-ն ընտրենք հաշվի առնելով հավասարում

  <span id="margin_116668158518_reveal" class="equation_link">(10)</span>-ը
  <span id="margin_116668158518" class="marginequation" style="display: none;">
    <a href="chap1.html#eqtn10" style="padding-bottom: 5px;" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';">
      \begin{eqnarray}
      \Delta v = -\eta \nabla C \nonumber\end{eqnarray}
    </a>
  </span>
  <script>
    $('#margin_116668158518_reveal').click(function() {$('#margin_116668158518').toggle('slow', function() {});});
  </script>.

  (Իհարկե, այնպես, որ չխախտվի մոտավոր հավասարում
  <span id="margin_780815505894_reveal" class="equation_link">(9)</span>-ը
  <span id="margin_780815505894" class="marginequation" style="display: none;">
    <a href="chap1.html#eqtn9" style="padding-bottom: 5px;" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';">
      \begin{eqnarray}
      \Delta C \approx \nabla C \cdot \Delta v \nonumber\end{eqnarray}
    </a>
  </span>
  <script>
    $('#margin_780815505894_reveal').click(function() {$('#margin_780815505894').toggle('slow', function() {});});
  </script>).

  Սա ըստ էության այն է, ինչ մենք փնտրում էինք, հետևաբար, մենք կվերցնենք հավասարում

  <span id="margin_11850183887_reveal" class="equation_link">(10)</span>-ը
  <span id="margin_11850183887" class="marginequation" style="display: none;">
    <a href="chap1.html#eqtn10" style="padding-bottom: 5px;" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';">
      \begin{eqnarray}
      \Delta v = -\eta \nabla C \nonumber\end{eqnarray}
    </a>
  </span>
  <script>
    $('#margin_11850183887_reveal').click(function() {$('#margin_11850183887').toggle('slow', function() {});});
  </script>

  որպես "շարժման հավասարում" գնդակի համար: Դա էլ ըստ էության հիմքն է
  գրադիենտային իջեցման ալգորիթմ կառուցելու համար: Այսպիսով, օգտագործելով հավասարում

  <span id="margin_838405111504_reveal" class="equation_link">(10)</span>-ը
  <span id="margin_838405111504" class="marginequation" style="display: none;">
    <a href="chap1.html#eqtn10" style="padding-bottom: 5px;" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';">
      \begin{eqnarray}
      \Delta v = -\eta \nabla C \nonumber\end{eqnarray}
    </a>
  </span>
  <script>
    $('#margin_838405111504_reveal').click(function() {$('#margin_838405111504').toggle('slow', function() {});});
  </script>

  և հաշվենք $\Delta v$-ի արժեքը, այնուհետև շարժենք գնդակը
  $v$ կետից $\Delta v$-ով.

  <a class="displaced_anchor" name="eqtn11"></a>
  \begin{eqnarray}
  v \rightarrow v' = v -\eta \nabla C.
  \tag{11}\end{eqnarray}

  Այնուհետև կօգտագործենք այս օրենքը ևս մեկ անգամ, շարժելով գնդակը ևս մեկ
  քայլով: Շարունակելով այսպես, $C$-ն կնվազի այնքան մինչև ամենայն հավանականությամբ
  հասնի գլոբալ մինիմումին (կախված ֆունկցիայի հատկություններից իհարկե):
</p>


<p>
  Ընդհանրացնելով, գրադիենտային իջեցման աշխատանքը կայանում է հետևյալում.
  հաշվել $\nabla C$ գրադիենտային վեկտորը, այնուհետև շարժվել <em>հակառակ</em>
  ուղղությամբ (գլորվելով դեպի հովիտի ստորոտը): Մենք կարող ենք դա պատկերել
  հետևյալ կերպ.
</p>

<p>
  <center><img src="images/valley_with_ball.png" width="542px"></center>
</p>

<p>
  Որպեսզի գրադիենտային ուսուցումը ճիշտ աշխատի, պետք է $\eta$-ի արժեքը
  վերցնել բավարար չափով փոքր, որ

  <span id="margin_261741104421_reveal" class="equation_link">(9)</span>
  <span id="margin_261741104421" class="marginequation" style="display: none;">
    <a href="chap1.html#eqtn9" style="padding-bottom: 5px;" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';">
      \begin{eqnarray}
      \Delta C \approx \nabla C \cdot \Delta v \nonumber\end{eqnarray}
    </a>
  </span>
  <script>
    $('#margin_261741104421_reveal').click(function() {$('#margin_261741104421').toggle('slow', function() {});});
  </script>

  հավասարումը դառնա լավ մոտարկում: Հակառակ դեպքում կարող ենք ստանալ
  $\Delta C > 0$, ինչը հակասում է մեր նպատակներին: Միևնույն ժամանակ,
  եթե $\eta$-ի արժեքը լինի շատ փոքր, ապա $\Delta v$-ի փոփոխությունները
  նույնպես կլինի փոքր, հետևաբար գրադիենտային իջեցումը կաշխատի դանդաղ:
  Ալգորիթմի պտակտիկ իրականացումներում, $\eta$-ի արժեքը փոխվում է այնպես, որ

  <span id="margin_89917482490_reveal" class="equation_link">(9)</span><span id="margin_89917482490" class="marginequation" style="display: none;"><a href="chap1.html#eqtn9" style="padding-bottom: 5px;" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';">\begin{eqnarray}
    \Delta C \approx \nabla C \cdot \Delta v \nonumber\end{eqnarray}</a></span><script>$('#margin_89917482490_reveal').click(function() {$('#margin_89917482490').toggle('slow', function() {});});</script>

  հավասարումը լինում է լավ մոտարկում և ալգորիթմը շատ դանդաղ չի լինում:
  Հետագայում ավելի մանրամասն կտեսնենք, թե ինչպես է դա տեղի ունենում:
</p>

<p>
  Մենք գրադիենտային իջեցմանը ծանոթացանք, ենթադրելով, որ $C$-ն երկու
  փոփոխականի ֆունկցիա է: Ըստ էության, ալգորիթմը աշխատում է ճիշտ նույն
  ձևով, անգամ եթե $C$-ն երկուսից ավելի փոփոխականի ֆունկցիա է: Ենթադրենք
  $C$-ն $v_1,\ldots,v_m$-ից կախված $m$ փոփոխականի ֆունկցիա է: Ապա
  $C$-ի $\Delta C$ փոփոխությունը, որն արդյունք է $\Delta v = (\Delta v_1,
  \ldots, \Delta v_m)^T$ փոփոխության, կարելի է հաշվել արտահայտել հետևյալ
  հավասարումով.

  <a class="displaced_anchor" name="eqtn12"></a>\begin{eqnarray}
    \Delta C \approx \nabla C \cdot \Delta v,
  \tag{12}\end{eqnarray}

  որտեղ գրադիենտ $\nabla C$-ն հետևյալ վեկտորն է.

  <a class="displaced_anchor" name="eqtn13"></a>\begin{eqnarray}
    \nabla C \equiv \left(\frac{\partial C}{\partial v_1}, \ldots,
    \frac{\partial C}{\partial v_m}\right)^T.
  \tag{13}\end{eqnarray}


  Ինչպես երկու փոփոխականի դեպքում, կարող ենք որոշել
  <a class="displaced_anchor" name="eqtn14"></a>\begin{eqnarray}
    \Delta v = -\eta \nabla C,
  \tag{14}\end{eqnarray}

  և

  <span id="margin_737008049048_reveal" class="equation_link">(12)</span><span id="margin_737008049048" class="marginequation" style="display: none;"><a href="chap1.html#eqtn12" style="padding-bottom: 5px;" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';">\begin{eqnarray}
    \Delta C \approx \nabla C \cdot \Delta v \nonumber\end{eqnarray}</a></span><script>$('#margin_737008049048_reveal').click(function() {$('#margin_737008049048').toggle('slow', function() {});});</script>

  $\Delta C$-ի արտահայտությունը կլինի բացասական: Դա հնարավորություն է
  տալիս մեզ գրադիենտը ձգտեցնել մինիմումի պարբերաբար կիրառելով

  <a class="displaced_anchor" name="eqtn15"></a>\begin{eqnarray}
    v \rightarrow v' = v-\eta \nabla C.
  \tag{15}\end{eqnarray}

  օրենքը, անգամ եթե $C$-ն երկուսից ավել փոփոխականներից հավասարում է:
  Հենց այս թարմացման օրենքն էլ <em>սահմանում</em> է գրադիենտային իջեցման
  ալգորիթմը: Այն հնարավորություն է տալիս շարունակաբար փոխելով $v$-ի դիրքը
  գտնել $C$-ի մինիմում արժեք: Հարկ է նշել, որ այս փոփոխման օրենքը ոչ բոլոր
  դեպքերում է աշխատում: Բազմաթիվ իրավիճակներում գրադիենտային իջեցումը
  կարող է ձախողել գլոբալ մինիմումի հայտնաբերման խնդրի լուծումը (մենք այս հարցին
  կանդրադառնանք հետագա գլուխներում): Սակայն պարզվում է, որ հատկապես նեյրոնային
  ցանցերի դեպքում այն հատկապես լավ է աշխատում և արժեքի ֆունկցիան մինիմիզացնելու
  բավականին ազդեցիկ մեթոդ է, այսպիսով օգնում է ցանցին սովորել:
</p>

<p></p><p></p>

<p>
  Տպավորություն է, որ գրադիենտային իջեցումը օպտիմալ մարտավարությունն է մինիմումը
  հայտնաբերելու համար: Ենթադրենք փորձում ենք կատարել $\Delta v$ քայլ այնպես,
  որ $C$-ն նվազի հնարավորինս շատ: Սա համարժեք է $\Delta C \approx \nabla C
  \cdot \Delta v$ մինիմիզացնելուն: Սահմանափակենք քայլի չափն այնպես, որ
  $\| \Delta v \| = \epsilon$, որտեղ $\epsilon > 0$ և ֆիքսված է: Այլ կերպ
  ասած, մեզ պետք է փոքր հաստատուն քայլ, և փորձում ենք գտնել քայլի այնպիսի
  ուղղություն, որը $C$-ն կնվազեցնի հնարավորինս շատ: Կարելի է ապացուցել, որ
  $\nabla C \cdot \Delta v$-ն մինիմիզացնելու համար $\Delta v$-ի ընտրությունը
  կարելի է որոշել $\Delta v = - \eta \nabla C$ արտահայտությամբ, որտեղ
  $\eta = \epsilon / \|\nabla C\|$ որոշվում է $\|\Delta v\| = \epsilon$
  սահմանափակման միջոցով: Այսպիսով, գրադիենտային իջեցումը կարելի է դիտարկել
  որպես փոքր քայլեր վերցնելու մարտավարություն այնպես, որ $C$-ն հնարավորինս նվազի:
</p>

<p>
  <h4><a name="exercises_647181"></a><a href="#exercises_647181">Վարժություններ</a></h4>
  <ul>
    <li> Ապացուցել վերջին պարբերության պնդումը: <em>Հուշում.</em> Եթե դեռ ծանոթ չեք
    <a href="http://en.wikipedia.org/wiki/Cauchy%E2%80%93Schwarz_inequality">Կոշի-Շվարցի
    անհավասարությանը</a>, ապա ծանոթանալը կարող է օգնել այս խնդրի լուծմանը:
</p>

<p>
  <li>
  Մենք դիտարկեցինք գրադիենտային իջեցումը, երբ $C$-ն երկու կամ ավել փոփոխականների
  ֆունկցիա է: Ի՞նչ է տեղի ունենում, երբ $C$-ն մեկ փոփոխականի ֆունկցիա է: Կարո՞ղ
  եք բերել գրադիենտային իջեցման երկրաչափական մեկնաբանությունը միաչափ դեպքում:
</ul>
</p>

<p></p>

<p>
  Գրադիենտային իջեցման բազմաթիվ տարբերակներ են հետազոտվել մինչ այժմ`
  ներառելով այնպիսինները, որոնք հիմնված են գնդակի շարժումը կրկնօրինակելու վրա:
  Վերջիններս ունեն որոշակի առավելություններ, ինչպես նաև էական խնդիրներ. պարզվում
  է, որ պարտադիր է հաշվել $C$-ի երկրորդ կարգի ածանցյալները, ինչը էապես "թանկ"
  գործողություն է ալգորոթմական տեսանկյունից: Որպեսզի համոզվենք դրանում, ենթադրենք
  մեր նպատակն է հաշվել բոլոր երկրորդ կարգի ածանցյալները`
  $\partial^2 C/ \partial v_j \partial v_k$: Եթե $v_j$ փոփոխականների
  քանակը մեկ միլիոն է, ապա մենք կարիք կունենայինք հաշվել մոտավորապես տրիլիոն
  երկրորդ կարգի մասնակի ածանցյալներ*
  <span class="marginnote">
    *Իրականում մոտավորապես կես տրիլիոն, քանի որ
    $\partial^2 C/ \partial v_j \partial v_k = \partial^2 C/ \partial
    v_k \partial v_j$.  Սակայն պարզ է, թե ինչի մասին է խոսքը:
  </span>

  Դա կլինի էապես թանկարժեք հաշվարկման տեսանկյունից: Հաշվի առնելով վերը նշվածը`
  գոյություն ունեն հնարքներ նմանատիպ խնդիրները շրջանցելու համար, ընդ որում,
  գրադիենտային իջեցման ալտերնատիվեների որոնումը ակտիվ ուսումնասիրության
  ուղղություն է: Այնուամենայնիվ, այս գրքում մենք կօգտագործենք գրադիենտային
  իջեցումը որպես հիմնական միջոց նեյրոնային ցանցերի միջոցով ուսուցումը կազմակերպելու
  համար:
</p>

<p>
  Ինչպե՞ս կարող ենք օգտագործել գրադիենտային իջեցումը նեյրոնային ցանցերով ուսուցման
  համար: Գալափարը կայանում է նրանում, որ գրադիենտային իջեցումը օգտագործենք
  $w_k$ կշիռները և $b_l$ շեղումները գտնելու համար, որոնք կմինիմիզացնեն արժեքի

  <span id="margin_167805660230_reveal" class="equation_link">(6)</span><span id="margin_167805660230" class="marginequation" style="display: none;"><a href="chap1.html#eqtn6" style="padding-bottom: 5px;" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';">\begin{eqnarray}  C(w,b) \equiv
    \frac{1}{2n} \sum_x \| y(x) - a\|^2 \nonumber\end{eqnarray}</a></span><script>$('#margin_167805660230_reveal').click(function() {$('#margin_167805660230').toggle('slow', function() {});});</script> ֆունկցիան:

  Որպեսզի տեսնենք, թե ինչպես է այն աշխատում, արտագրենք գրադիենտային
  իջեցման թարմացման օրենքը` $v_j$ փոփոխականները փոխարինելով կշիռներով
  և շեղումներով: Այսպիսով, գրադիենտային իջեցման թարմացման կանոնը կունենա
  հետևյալ տեսքը.

  <a class="displaced_anchor" name="eqtn16"></a>
  <a class="displaced_anchor" name="eqtn17"></a>\begin{eqnarray}
    w_k & \rightarrow & w_k' = w_k-\eta \frac{\partial C}{\partial w_k} \tag{16}\\
    b_l & \rightarrow & b_l' = b_l-\eta \frac{\partial C}{\partial b_l}.
  \tag{17}\end{eqnarray}

  Շարունակաբար իրացնելով այս թարմացման օրենքը, մենք "կգլորվենք բլուրից ներքև"
  և ամենայն հավանականությամբ կգտնենք արժեքի ֆունկցիայի մինիմումը: Այլ կերպ ասած,
  սա այն օրենքն է, որի միջոցով նեյրոնային ցանցերը կսովորեն:
</p>

<p>
  Գրադիենտային իջեցման կիրառման հետ կապված կան որոշակի բարդություններ:
  Մենք դրանք խորությամբ կդիտարկենք ապագա գլուխներում: Այժմ դիտարկենք
  դրանցից մեկը միայն, որի համար դիտարկենք քառակուսային արժեքի հավասարումը
  <span id="margin_786090300230_reveal" class="equation_link">(6)</span><span id="margin_786090300230" class="marginequation" style="display: none;"><a href="chap1.html#eqtn6" style="padding-bottom: 5px;" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';">\begin{eqnarray}  C(w,b) \equiv
  \frac{1}{2n} \sum_x \| y(x) - a\|^2 \nonumber\end{eqnarray}</a></span><script>$('#margin_786090300230_reveal').click(function() {$('#margin_786090300230').toggle('slow', function() {});});</script>:

  Նկատենք, որ արժեքի ֆունկցիան ունի $C = \frac{1}{n} \sum_x C_x$ տեսքը,
  հետևաբար, այն առանձին մուտքային տվյալնիեր համար $C_x \equiv \frac{\|y(x)-a\|^2}{2}$
  արժեքների  հանրահաշվական միջինն է: Պրակտիկորեն, որպեսզի հաշվարկենք $\nabla C$
  գրադիենտը, մենք պետք է հաշվարկենք $\nabla C_x$ առանձին ամեն $x$ մուտքային
  տվյալի համար, այնուհետև հաշվենք նրանց $\nabla C = \frac{1}{n} \sum_x \nabla C_x$
  հանրահաշվական միջինը: ժբախտաբար շատ մեծ քանակությամբ ուսուցման տվյալների դեպքում
  սա կարող է բավական շատ ժամանակ տևել, հետևաբար ուսուցումը կարող է դանդաղ տեղի ունենալ:
</p>

<p>
  Ուսուցումն արագացնելու նպատակով կարելի է օգտագործել մի գաղափար, որը կոչվում է
  <em>ստոկաստիկ գրադիենտային իջեցում (stochastic gradient descent)</em>:
  Գաղափարը կայանում է նրանում, որ պետք է $\nabla C$ գրադիենտը գնահատել`
  հաշվելով ուսուցման տվյալներից փոքրիկ մասի $\nabla C_x$ գրադիենտները: Պարզվում է,
  որ միջինացնելով այդ փոքր հատվածի գրադիենտները՝, մենք արագորեն կարող ենք ստանալ
  իսկական $\nabla C$ գրադիենտի լավ գնահատական: Դա օգնում է արագացնել գրադիենտային
  իջեցումը, հետևաբար նաև ուսուցումը:
</p>

<p>
  Այսպիսով, ստոկաստիկ գրադիենտային իջեցումը աշխատում է` պատահականորեն ընտրելով
  որոշակի ոչ մեծ քանակությամբ $m$ ուսուցման մուտքային տվյալներ: Նշանակենք այդ տվյալները
  որպես $X_1, X_2, \ldots, X_m$ և պայմանավորվենք հղվել նրանց որպես <em> մինի-փաթեթ
  (mini-batch)</em>: Եթե $m$-ը բավականաշափ մեծ է, սպասվում է, որ $\nabla C_{X_j}$-ի
  հանրահաշվական միջինը մոտ կլինի $\nabla C_x$ հանրահաշվական միջինին: Այսպիսով,

  <a class="displaced_anchor" name="eqtn18"></a>\begin{eqnarray}
    \frac{\sum_{j=1}^m \nabla C_{X_{j}}}{m} \approx \frac{\sum_x \nabla C_x}{n} = \nabla C,
  \tag{18}\end{eqnarray}

  որտեղ երկրորդ գումարը ամբողջ ուսուցման տվյալների երկայնքով է: Փոխելով հավասարման
  կողմերը, կստանանք

  <a class="displaced_anchor" name="eqtn19"></a>\begin{eqnarray}
    \nabla C \approx \frac{1}{m} \sum_{j=1}^m \nabla C_{X_{j}},
  \tag{19}\end{eqnarray}

  միևնույն ժամանակ համոզվելով, որ մենք կարոլ ենք գնահատել ամբողջ գրադիենտը միայն
  հաշվելով պատահականորեն ընտրված մինի-փաթեթի գրադիենտները:
</p>

<p>
  Որպեսզի սա ուղղակիորեն կապենք նեյրոնային ցանցերով ուսուցման հետ,
  ենթադրենք, որ $w_k$ և $b_l$-ով նշանակված են մեր ցանցի կշիռներն ու
  շեղումները: Ապա, ստոկաստիկ գրադիենատային իջեցումը աշխատում է
  պատահականորեն ընտրված ուսուցման տվյալների մինի-փաթեթի տվյալների
  հիման վրա`

  <a class="displaced_anchor" name="eqtn20"></a><a class="displaced_anchor" name="eqtn21"></a>\begin{eqnarray}
    w_k & \rightarrow & w_k' = w_k-\frac{\eta}{m}
    \sum_j \frac{\partial C_{X_j}}{\partial w_k} \tag{20}\\

    b_l & \rightarrow & b_l' = b_l-\frac{\eta}{m}
    \sum_j \frac{\partial C_{X_j}}{\partial b_l},
  \tag{21}\end{eqnarray}

  որտեղ գումարը մինի-փաթեթի բոլոր $X_j$ ուսուցման օրինակների երկայնքով է:
  Այնուհետև ընտրում ենք ուրիշ պատահականորեն ընտրված մինի-փաթեթ և կատարում
  ուսուցումը դրանց հիման վրա: Սա կատարում ենք այնքան ժամանակ, մինչև
  օգտագործած լինենք բոլոր ուսուցման մուտքային տվյալները: Այս պրոցեսը այլ կերպ
  կոչվում է ուսուցման <em>դարաշրջան (epoch)</em>: Երբ ավարտում ենք ներկա
  ուսուցման դարաշրջանը, սկսում ենք նորն իրականացնել:
</p>

<p>
  Հարկ է նշել, որ արժեքի ֆունկցիայի և կշռի ու շեղումների մինի-փաթեթային թարմացումների
  տարատեսակ մաշտաբավորումներ (scaling) են ընդունված: Դիտարկենք

  <span id="margin_84852336525_reveal" class="equation_link">(6)</span><span id="margin_84852336525" class="marginequation" style="display: none;"><a href="chap1.html#eqtn6" style="padding-bottom: 5px;" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';">\begin{eqnarray}  C(w,b) \equiv
    \frac{1}{2n} \sum_x \| y(x) - a\|^2 \nonumber\end{eqnarray}</a></span><script>$('#margin_84852336525_reveal').click(function() {$('#margin_84852336525').toggle('slow', function() {});});</script>

  հավասարումը, որտեղ արժեքի ֆունկցիան մաշտաբավորված է $\frac{1}{n}$-ով: Մարդիկ
  երբեմն բաց են թողնում $\frac{1}{n}$-ը, գումարելով արանձին ուսուցման օրինակների
  արժեքի ֆունկցիաները միջինացնելու փոխարեն: Սա կարող է օգտակար լինել, եթե
  ուսուցման օրինակների բազմությունը նախապես հայտնի չէ (օրինակ, երբ իրական ժամանակում
  տվյալ է գեներացվում): Նույն կերպ մինի-փաթեթի

<span id="margin_517690364363_reveal" class="equation_link">(20)
</span><span id="margin_517690364363" class="marginequation" style="display: none;"><a href="chap1.html#eqtn20" style="padding-bottom: 5px;" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';">\begin{eqnarray}
  w_k & \rightarrow & w_k' = w_k-\frac{\eta}{m}
  \sum_j \frac{\partial C_{X_j}}{\partial w_k}  \nonumber\end{eqnarray}</a></span><script>$('#margin_517690364363_reveal').click(function() {$('#margin_517690364363').toggle('slow', function() {});});</script>

  և

  <span id="margin_863737688414_reveal" class="equation_link">(21)</span><span id="margin_863737688414" class="marginequation" style="display: none;"><a href="chap1.html#eqtn21" style="padding-bottom: 5px;" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';">\begin{eqnarray}
    b_l & \rightarrow & b_l' = b_l-\frac{\eta}{m}
    \sum_j \frac{\partial C_{X_j}}{\partial b_l} \nonumber\end{eqnarray}</a></span><script>$('#margin_863737688414_reveal').click(function() {$('#margin_863737688414').toggle('slow', function() {});});</script>

  թարմացման կանոնները երբեմն բաց են փողնում $\frac{1}{m}$ գործակիցը
  գումարի դիմացից: Կոնցեպտուալ առումով, սա էական փոփոխություն չի
  մտցնում, քանի որ այն համարժեք է ուսուցման գործակցի վերամաշտաբավորման
  (rescaling): Սակայն արժե "աչքը չկտրել այս մասով":
</p>

<p>
  Մենք կարող ենք ստոկաստիկ գրադիենտային իջեցման մասին մտածել, որպես
  քաղաքական ցուցակագրում. շատ ավելի հեշտ է օգտագործել փոքր մինի-փաթեթ,
  քան կիրառել գրադիենտային իջեցումն ամբողջ փաթեթի վրա, ինչպես, օրինակ,
  շատ ավելի հեշտ է կատարել քաղաքական հարցում բնակչության մի հատվածի վրա,
  քան իտականացնել ընտրություններ: Օրինակ, եթե ունենք $n = 60,000$ ուսուցման
  տվյալներ, ինչպես MNIST-ում է, և ընտրենք որպես մինի-փաթեթի երկարություն
  $m = 10$, ապա կունենանք գրադիենտի մոտարկման արագության $6,000$
  անգամ լավացում: Իհարկե մոտարկումը կատարյալ չի լինի, կլինեն ստատիստիկ
  տատանումներ, բայց այն կարիք էլ չունի կատարյալ լինելու: Մեզ հետաքրքրում է
  միայն շարժվել այն ուղղությամբ, որը կնվազեցնի $C$-ն: Եվ դա նշանակում է, որ
  մենք կարիք չունենք գրադիենտի ավելորդ հաշվարկում: Պրակտիկորեն, ստոկաստիկ
  գրադիենտային իջեցումը հաճախակի օգտագործվող և հզոր մոտեցում է նեյրոնային
  ցանցերով ուսուցման հարցում և այն հիմքն է բազմաթիվ ուսուցման հմտությունների,
  որոնք մենք կկառուցենք այս գրքում:
</p>

<p></p><p></p><p></p><p></p><p></p>

<p><h4><a name="exercise_263792"></a><a href="#exercise_263792">Exercise</a></h4><ul>
<li> An extreme version of gradient descent is to use a mini-batch
  size of just 1.  That is, given a training input, $x$, we update our
  weights and biases according to the rules $w_k \rightarrow w_k' =
  w_k - \eta \partial C_x / \partial w_k$ and $b_l \rightarrow b_l' =
  b_l - \eta \partial C_x / \partial b_l$.  Then we choose another
  training input, and update the weights and biases again.  And so on,
  repeatedly.  This procedure is known as <em>online</em>,
  <em>on-line</em>, or <em>incremental</em> learning.  In online learning,
  a neural network learns from just one training input at a time (just
  as human beings do).  Name one advantage and one disadvantage of
  online learning, compared to stochastic gradient descent with a
  mini-batch size of, say, $20$.
</ul></p><p>Let me conclude this section by discussing a point that sometimes bugs
people new to gradient descent.  In neural networks the cost $C$ is,
of course, a function of many variables - all the weights and biases
- and so in some sense defines a surface in a very high-dimensional
space.  Some people get hung up thinking: "Hey, I have to be able to
visualize all these extra dimensions".  And they may start to worry:
"I can't think in four dimensions, let alone five (or five
million)".  Is there some special ability they're missing, some
ability that "real" supermathematicians have?  Of course, the answer
is no.  Even most professional mathematicians can't visualize four
dimensions especially well, if at all.  The trick they use, instead,
is to develop other ways of representing what's going on.  That's
exactly what we did above: we used an algebraic (rather than visual)
representation of $\Delta C$ to figure out how to move so as to
decrease $C$.  People who are good at thinking in high dimensions have
a mental library containing many different techniques along these
lines; our algebraic trick is just one example.  Those techniques may
not have the simplicity we're accustomed to when visualizing three
dimensions, but once you build up a library of such techniques, you
can get pretty good at thinking in high dimensions.  I won't go into
more detail here, but if you're interested then you may enjoy reading
<a href="http://mathoverflow.net/questions/25983/intuitive-crutches-for-higher-dimensional-thinking">this
  discussion</a> of some of the techniques professional mathematicians
use to think in high dimensions.  While some of the techniques
discussed are quite complex, much of the best content is intuitive and
accessible, and could be mastered by anyone.</p><p></p><p>
<h3><a name="implementing_our_network_to_classify_digits"></a><a href="#implementing_our_network_to_classify_digits">Implementing our network to classify digits</a></h3></p><p>Alright, let's write a program that learns how to recognize
handwritten digits, using stochastic gradient descent and the MNIST
training data.  The first thing we need is to get the MNIST data.  If
you're a <tt>git</tt> user then you can obtain the data by cloning the
code repository for this book,</p><p><div class="highlight"><pre>git clone https://github.com/mnielsen/neural-networks-and-deep-learning.git
</pre></div>
</p><p>If you don't use <tt>git</tt> then you can download the data and code
<a href="https://github.com/mnielsen/neural-networks-and-deep-learning/archive/master.zip">here</a>.</p><p>Incidentally, when I described the MNIST data earlier, I said it was
split into 60,000 training images, and 10,000 test images.  That's the
official MNIST description.  Actually, we're going to split the data a
little differently.  We'll leave the test images as is, but split the
60,000-image MNIST training set into two parts: a set of 50,000
images, which we'll use to train our neural network, and a separate
10,000 image <em>validation set</em>.  We won't
use the validation data in this chapter, but later in the book we'll
find it useful in figuring out how to set certain
<em>hyper-parameters</em> of the neural network - things like the
learning rate, and so on, which aren't directly selected by our
learning algorithm.  Although the validation data isn't part of the
original MNIST specification, many people use MNIST in this fashion,
and the use of validation data is common in neural networks.  When I
refer to the "MNIST training data" from now on, I'll be referring to
our 50,000 image data set, not the original 60,000 image data
set*<span class="marginnote">
*As noted earlier, the MNIST data set is based on two data
  sets collected by NIST, the United States' National Institute of
  Standards and Technology.  To construct MNIST the NIST data sets
  were stripped down and put into a more convenient format by Yann
  LeCun, Corinna Cortes, and Christopher J. C. Burges.  See
  <a href="http://yann.lecun.com/exdb/mnist/">this link</a> for more
  details.  The data set in my repository is in a form that makes it
  easy to load and manipulate the MNIST data in Python.  I obtained
  this particular form of the data from the LISA machine learning
  laboratory at the University of Montreal
  (<a href="http://www.deeplearning.net/tutorial/gettingstarted.html">link</a>).</span>.</p><p></p><p>Apart from the MNIST data we also need a Python library called
<a href="http://numpy.org">Numpy</a>, for doing fast linear algebra.  If you
don't already have Numpy installed, you can get it
<a href="http://www.scipy.org/install.html">here</a>.</p><p>Let me explain the core features of the neural networks code, before
giving a full listing, below.  The centerpiece is a <tt>Network</tt>
class, which we use to represent a neural network.  Here's the code we
use to initialize a <tt>Network</tt> object:</p><p>
<div class="highlight"><pre><span class="k">class</span> <span class="nc">Network</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sizes</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_layers</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">sizes</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sizes</span> <span class="o">=</span> <span class="n">sizes</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">biases</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">sizes</span><span class="p">[</span><span class="mi">1</span><span class="p">:]]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
                        <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">sizes</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">sizes</span><span class="p">[</span><span class="mi">1</span><span class="p">:])]</span>
</pre></div>
</p><p>In this code, the list <tt>sizes</tt> contains the number of neurons in
the respective layers.  So, for example, if we want to create a
<tt>Network</tt> object with 2 neurons in the first layer, 3 neurons in
the second layer, and 1 neuron in the final layer, we'd do this with
the code:
<div class="highlight"><pre><span class="n">net</span> <span class="o">=</span> <span class="n">Network</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
</pre></div>

<a name="weight_initialization"></a> The biases
and weights in the <tt>Network</tt> object are all initialized randomly,
using the Numpy <tt>np.random.randn</tt> function to generate Gaussian
distributions with mean $0$ and standard deviation $1$.  This random
initialization gives our stochastic gradient descent algorithm a place
to start from.  In later chapters we'll find better ways of
initializing the weights and biases, but this will do for now.  Note
that the <tt>Network</tt> initialization code assumes that the first
layer of neurons is an input layer, and omits to set any biases for
those neurons, since biases are only ever used in computing the
outputs from later layers.</p><p>Note also that the biases and weights are stored as lists of Numpy
matrices.  So, for example <tt>net.weights[1]</tt> is a Numpy matrix
storing the weights connecting the second and third layers of neurons.
(It's not the first and second layers, since Python's list indexing
starts at <tt>0</tt>.)  Since <tt>net.weights[1]</tt> is rather verbose,
let's just denote that matrix $w$.  It's a matrix such that $w_{jk}$
is the weight for the connection between the $k^{\rm th}$ neuron in the
second layer, and the $j^{\rm th}$ neuron in the third layer.  This ordering
of the $j$ and $k$ indices may seem strange - surely it'd make more
sense to swap the $j$ and $k$ indices around?  The big advantage of
using this ordering is that it means that the vector of activations of
the third layer of neurons is:
<a class="displaced_anchor" name="eqtn22"></a>\begin{eqnarray}
  a' = \sigma(w a + b).
\tag{22}\end{eqnarray}
There's quite a bit going on in this equation, so let's unpack it
piece by piece.  $a$ is the vector of activations of the second layer
of neurons. To obtain $a'$ we multiply $a$ by the weight matrix $w$,
and add the vector $b$ of biases.  We then apply the function $\sigma$
elementwise to every entry in the vector $w a +b$.  (This is called
<em>vectorizing</em> the function
$\sigma$.) It's easy to verify that
Equation <span id="margin_621803496648_reveal" class="equation_link">(22)</span><span id="margin_621803496648" class="marginequation" style="display: none;"><a href="chap1.html#eqtn22" style="padding-bottom: 5px;" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';">\begin{eqnarray}
  a' = \sigma(w a + b) \nonumber\end{eqnarray}</a></span><script>$('#margin_621803496648_reveal').click(function() {$('#margin_621803496648').toggle('slow', function() {});});</script> gives the same result as our
earlier rule, Equation <span id="margin_466969638583_reveal" class="equation_link">(4)</span><span id="margin_466969638583" class="marginequation" style="display: none;"><a href="chap1.html#eqtn4" style="padding-bottom: 5px;" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';">\begin{eqnarray}
  \frac{1}{1+\exp(-\sum_j w_j x_j-b)} \nonumber\end{eqnarray}</a></span><script>$('#margin_466969638583_reveal').click(function() {$('#margin_466969638583').toggle('slow', function() {});});</script>, for
computing the output of a sigmoid neuron.</p><p><h4><a name="exercise_997362"></a><a href="#exercise_997362">Exercise</a></h4><ul>
<li> Write out Equation <span id="margin_44996869809_reveal" class="equation_link">(22)</span><span id="margin_44996869809" class="marginequation" style="display: none;"><a href="chap1.html#eqtn22" style="padding-bottom: 5px;" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';">\begin{eqnarray}
  a' = \sigma(w a + b) \nonumber\end{eqnarray}</a></span><script>$('#margin_44996869809_reveal').click(function() {$('#margin_44996869809').toggle('slow', function() {});});</script> in component
  form, and verify that it gives the same result as the
  rule <span id="margin_325948154784_reveal" class="equation_link">(4)</span><span id="margin_325948154784" class="marginequation" style="display: none;"><a href="chap1.html#eqtn4" style="padding-bottom: 5px;" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';">\begin{eqnarray}
  \frac{1}{1+\exp(-\sum_j w_j x_j-b)} \nonumber\end{eqnarray}</a></span><script>$('#margin_325948154784_reveal').click(function() {$('#margin_325948154784').toggle('slow', function() {});});</script> for computing the output
  of a sigmoid neuron.
</ul></p><p>With all this in mind, it's easy to write code computing the output
from a <tt>Network</tt> instance.  We begin by defining the sigmoid
function:
<div class="highlight"><pre><span class="k">def</span> <span class="nf">sigmoid</span><span class="p">(</span><span class="n">z</span><span class="p">):</span>
    <span class="k">return</span> <span class="mf">1.0</span><span class="o">/</span><span class="p">(</span><span class="mf">1.0</span><span class="o">+</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">z</span><span class="p">))</span>
</pre></div>

Note that when the input <tt>z</tt> is a vector or Numpy array, Numpy
automatically applies the function <tt>sigmoid</tt> elementwise, that
is, in vectorized form.</p><p>We then add a <tt>feedforward</tt> method to the <tt>Network</tt> class,
which, given an input <tt>a</tt> for the network, returns the
corresponding output*<span class="marginnote">
*It is assumed that the input <tt>a</tt> is
  an <tt>(n, 1)</tt> Numpy ndarray, not a <tt>(n,)</tt> vector.  Here,
  <tt>n</tt> is the number of inputs to the network.  If you try to use
  an <tt>(n,)</tt> vector as input you'll get strange results.  Although
  using an <tt>(n,)</tt> vector appears the more natural choice, using
  an <tt>(n, 1)</tt> ndarray makes it particularly easy to modify the
  code to feedforward multiple inputs at once, and that is sometimes
  convenient. </span>.  All the method does is applies
Equation <span id="margin_608357269255_reveal" class="equation_link">(22)</span><span id="margin_608357269255" class="marginequation" style="display: none;"><a href="chap1.html#eqtn22" style="padding-bottom: 5px;" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';">\begin{eqnarray}
  a' = \sigma(w a + b) \nonumber\end{eqnarray}</a></span><script>$('#margin_608357269255_reveal').click(function() {$('#margin_608357269255').toggle('slow', function() {});});</script> for each layer:
<div class="highlight"><pre>    <span class="k">def</span> <span class="nf">feedforward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">a</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Return the output of the network if &quot;a&quot; is input.&quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">b</span><span class="p">,</span> <span class="n">w</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">biases</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">):</span>
            <span class="n">a</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">a</span><span class="p">)</span><span class="o">+</span><span class="n">b</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">a</span>
</pre></div>
</p><p>Of course, the main thing we want our <tt>Network</tt> objects to do is
to learn.  To that end we'll give them an <tt>SGD</tt> method which
implements stochastic gradient descent.  Here's the code.  It's a
little mysterious in a few places, but I'll break it down below, after
the listing.</p><p><div class="highlight"><pre>    <span class="k">def</span> <span class="nf">SGD</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">training_data</span><span class="p">,</span> <span class="n">epochs</span><span class="p">,</span> <span class="n">mini_batch_size</span><span class="p">,</span> <span class="n">eta</span><span class="p">,</span>
            <span class="n">test_data</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Train the neural network using mini-batch stochastic</span>
<span class="sd">        gradient descent.  The &quot;training_data&quot; is a list of tuples</span>
<span class="sd">        &quot;(x, y)&quot; representing the training inputs and the desired</span>
<span class="sd">        outputs.  The other non-optional parameters are</span>
<span class="sd">        self-explanatory.  If &quot;test_data&quot; is provided then the</span>
<span class="sd">        network will be evaluated against the test data after each</span>
<span class="sd">        epoch, and partial progress printed out.  This is useful for</span>
<span class="sd">        tracking progress, but slows things down substantially.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">test_data</span><span class="p">:</span> <span class="n">n_test</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">test_data</span><span class="p">)</span>
        <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">training_data</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
            <span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">training_data</span><span class="p">)</span>
            <span class="n">mini_batches</span> <span class="o">=</span> <span class="p">[</span>
                <span class="n">training_data</span><span class="p">[</span><span class="n">k</span><span class="p">:</span><span class="n">k</span><span class="o">+</span><span class="n">mini_batch_size</span><span class="p">]</span>
                <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">mini_batch_size</span><span class="p">)]</span>
            <span class="k">for</span> <span class="n">mini_batch</span> <span class="ow">in</span> <span class="n">mini_batches</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">update_mini_batch</span><span class="p">(</span><span class="n">mini_batch</span><span class="p">,</span> <span class="n">eta</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">test_data</span><span class="p">:</span>
                <span class="k">print</span> <span class="s">&quot;Epoch {0}: {1} / {2}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                    <span class="n">j</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">test_data</span><span class="p">),</span> <span class="n">n_test</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">print</span> <span class="s">&quot;Epoch {0} complete&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">j</span><span class="p">)</span>
</pre></div>
</p><p>The <tt>training_data</tt> is a list of tuples <tt>(x, y)</tt>
representing the training inputs and corresponding desired outputs.
The variables <tt>epochs</tt> and <tt>mini_batch_size</tt> are what you'd
expect - the number of epochs to train for, and the size of the
mini-batches to use when sampling.  <tt>eta</tt> is the learning rate,
$\eta$.  If the optional argument <tt>test_data</tt> is supplied, then
the program will evaluate the network after each epoch of training,
and print out partial progress.  This is useful for tracking progress,
but slows things down substantially.</p><p>The code works as follows.  In each epoch, it starts by randomly
shuffling the training data, and then partitions it into mini-batches
of the appropriate size.  This is an easy way of sampling randomly
from the training data.  Then for each <tt>mini_batch</tt> we apply a
single step of gradient descent.  This is done by the code
<tt>self.update_mini_batch(mini_batch, eta)</tt>, which updates the
network weights and biases according to a single iteration of gradient
descent, using just the training data in <tt>mini_batch</tt>.  Here's
the code for the <tt>update_mini_batch</tt> method:
<div class="highlight"><pre>    <span class="k">def</span> <span class="nf">update_mini_batch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mini_batch</span><span class="p">,</span> <span class="n">eta</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Update the network&#39;s weights and biases by applying</span>
<span class="sd">        gradient descent using backpropagation to a single mini batch.</span>
<span class="sd">        The &quot;mini_batch&quot; is a list of tuples &quot;(x, y)&quot;, and &quot;eta&quot;</span>
<span class="sd">        is the learning rate.&quot;&quot;&quot;</span>
        <span class="n">nabla_b</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">b</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">biases</span><span class="p">]</span>
        <span class="n">nabla_w</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">w</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">mini_batch</span><span class="p">:</span>
            <span class="n">delta_nabla_b</span><span class="p">,</span> <span class="n">delta_nabla_w</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">backprop</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
            <span class="n">nabla_b</span> <span class="o">=</span> <span class="p">[</span><span class="n">nb</span><span class="o">+</span><span class="n">dnb</span> <span class="k">for</span> <span class="n">nb</span><span class="p">,</span> <span class="n">dnb</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">nabla_b</span><span class="p">,</span> <span class="n">delta_nabla_b</span><span class="p">)]</span>
            <span class="n">nabla_w</span> <span class="o">=</span> <span class="p">[</span><span class="n">nw</span><span class="o">+</span><span class="n">dnw</span> <span class="k">for</span> <span class="n">nw</span><span class="p">,</span> <span class="n">dnw</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">nabla_w</span><span class="p">,</span> <span class="n">delta_nabla_w</span><span class="p">)]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="p">[</span><span class="n">w</span><span class="o">-</span><span class="p">(</span><span class="n">eta</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">mini_batch</span><span class="p">))</span><span class="o">*</span><span class="n">nw</span>
                        <span class="k">for</span> <span class="n">w</span><span class="p">,</span> <span class="n">nw</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">,</span> <span class="n">nabla_w</span><span class="p">)]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">biases</span> <span class="o">=</span> <span class="p">[</span><span class="n">b</span><span class="o">-</span><span class="p">(</span><span class="n">eta</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">mini_batch</span><span class="p">))</span><span class="o">*</span><span class="n">nb</span>
                       <span class="k">for</span> <span class="n">b</span><span class="p">,</span> <span class="n">nb</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">biases</span><span class="p">,</span> <span class="n">nabla_b</span><span class="p">)]</span>
</pre></div>

Most of the work is done by the line
<div class="highlight"><pre>            <span class="n">delta_nabla_b</span><span class="p">,</span> <span class="n">delta_nabla_w</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">backprop</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>

This invokes something called the <em>backpropagation</em> algorithm,
which is a fast way of computing the gradient of the cost function.
So <tt>update_mini_batch</tt> works simply by computing these gradients
for every training example in the <tt>mini_batch</tt>, and then updating
<tt>self.weights</tt> and <tt>self.biases</tt> appropriately.</p><p>I'm not going to show the code for <tt>self.backprop</tt> right now.
We'll study how backpropagation works in the next chapter, including
the code for <tt>self.backprop</tt>.  For now, just assume that it
behaves as claimed, returning the appropriate gradient for the cost
associated to the training example <tt>x</tt>.</p><p>Let's look at the full program, including the documentation strings,
which I omitted above.  Apart from <tt>self.backprop</tt> the program is
self-explanatory - all the heavy lifting is done in <tt>self.SGD</tt>
and <tt>self.update_mini_batch</tt>, which we've already discussed.  The
<tt>self.backprop</tt> method makes use of a few extra functions to help
in computing the gradient, namely <tt>sigmoid_prime</tt>, which computes
the derivative of the $\sigma$ function, and
<tt>self.cost_derivative</tt>, which I won't describe here.  You can get
the gist of these (and perhaps the details) just by looking at the
code and documentation strings.  We'll look at them in detail in the
next chapter.
Note that while the program appears lengthy, much of the code is
documentation strings intended to make the code easy to understand.
In fact, the program contains just 74 lines of non-whitespace,
non-comment code.  All the code may be found on GitHub
<a href="https://github.com/mnielsen/neural-networks-and-deep-learning/blob/master/src/network.py">here</a>.</p><p></p><p><div class="highlight"><pre><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">network.py</span>
<span class="sd">~~~~~~~~~~</span>

<span class="sd">A module to implement the stochastic gradient descent learning</span>
<span class="sd">algorithm for a feedforward neural network.  Gradients are calculated</span>
<span class="sd">using backpropagation.  Note that I have focused on making the code</span>
<span class="sd">simple, easily readable, and easily modifiable.  It is not optimized,</span>
<span class="sd">and omits many desirable features.</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="c">#### Libraries</span>
<span class="c"># Standard library</span>
<span class="kn">import</span> <span class="nn">random</span>

<span class="c"># Third-party libraries</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>

<span class="k">class</span> <span class="nc">Network</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sizes</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;The list ``sizes`` contains the number of neurons in the</span>
<span class="sd">        respective layers of the network.  For example, if the list</span>
<span class="sd">        was [2, 3, 1] then it would be a three-layer network, with the</span>
<span class="sd">        first layer containing 2 neurons, the second layer 3 neurons,</span>
<span class="sd">        and the third layer 1 neuron.  The biases and weights for the</span>
<span class="sd">        network are initialized randomly, using a Gaussian</span>
<span class="sd">        distribution with mean 0, and variance 1.  Note that the first</span>
<span class="sd">        layer is assumed to be an input layer, and by convention we</span>
<span class="sd">        won&#39;t set any biases for those neurons, since biases are only</span>
<span class="sd">        ever used in computing the outputs from later layers.&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_layers</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">sizes</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sizes</span> <span class="o">=</span> <span class="n">sizes</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">biases</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">sizes</span><span class="p">[</span><span class="mi">1</span><span class="p">:]]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
                        <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">sizes</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">sizes</span><span class="p">[</span><span class="mi">1</span><span class="p">:])]</span>

    <span class="k">def</span> <span class="nf">feedforward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">a</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Return the output of the network if ``a`` is input.&quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">b</span><span class="p">,</span> <span class="n">w</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">biases</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">):</span>
            <span class="n">a</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">a</span><span class="p">)</span><span class="o">+</span><span class="n">b</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">a</span>

    <span class="k">def</span> <span class="nf">SGD</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">training_data</span><span class="p">,</span> <span class="n">epochs</span><span class="p">,</span> <span class="n">mini_batch_size</span><span class="p">,</span> <span class="n">eta</span><span class="p">,</span>
            <span class="n">test_data</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Train the neural network using mini-batch stochastic</span>
<span class="sd">        gradient descent.  The ``training_data`` is a list of tuples</span>
<span class="sd">        ``(x, y)`` representing the training inputs and the desired</span>
<span class="sd">        outputs.  The other non-optional parameters are</span>
<span class="sd">        self-explanatory.  If ``test_data`` is provided then the</span>
<span class="sd">        network will be evaluated against the test data after each</span>
<span class="sd">        epoch, and partial progress printed out.  This is useful for</span>
<span class="sd">        tracking progress, but slows things down substantially.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">test_data</span><span class="p">:</span> <span class="n">n_test</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">test_data</span><span class="p">)</span>
        <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">training_data</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
            <span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">training_data</span><span class="p">)</span>
            <span class="n">mini_batches</span> <span class="o">=</span> <span class="p">[</span>
                <span class="n">training_data</span><span class="p">[</span><span class="n">k</span><span class="p">:</span><span class="n">k</span><span class="o">+</span><span class="n">mini_batch_size</span><span class="p">]</span>
                <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">mini_batch_size</span><span class="p">)]</span>
            <span class="k">for</span> <span class="n">mini_batch</span> <span class="ow">in</span> <span class="n">mini_batches</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">update_mini_batch</span><span class="p">(</span><span class="n">mini_batch</span><span class="p">,</span> <span class="n">eta</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">test_data</span><span class="p">:</span>
                <span class="k">print</span> <span class="s">&quot;Epoch {0}: {1} / {2}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                    <span class="n">j</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">test_data</span><span class="p">),</span> <span class="n">n_test</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">print</span> <span class="s">&quot;Epoch {0} complete&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">j</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">update_mini_batch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mini_batch</span><span class="p">,</span> <span class="n">eta</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Update the network&#39;s weights and biases by applying</span>
<span class="sd">        gradient descent using backpropagation to a single mini batch.</span>
<span class="sd">        The ``mini_batch`` is a list of tuples ``(x, y)``, and ``eta``</span>
<span class="sd">        is the learning rate.&quot;&quot;&quot;</span>
        <span class="n">nabla_b</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">b</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">biases</span><span class="p">]</span>
        <span class="n">nabla_w</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">w</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">mini_batch</span><span class="p">:</span>
            <span class="n">delta_nabla_b</span><span class="p">,</span> <span class="n">delta_nabla_w</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">backprop</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
            <span class="n">nabla_b</span> <span class="o">=</span> <span class="p">[</span><span class="n">nb</span><span class="o">+</span><span class="n">dnb</span> <span class="k">for</span> <span class="n">nb</span><span class="p">,</span> <span class="n">dnb</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">nabla_b</span><span class="p">,</span> <span class="n">delta_nabla_b</span><span class="p">)]</span>
            <span class="n">nabla_w</span> <span class="o">=</span> <span class="p">[</span><span class="n">nw</span><span class="o">+</span><span class="n">dnw</span> <span class="k">for</span> <span class="n">nw</span><span class="p">,</span> <span class="n">dnw</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">nabla_w</span><span class="p">,</span> <span class="n">delta_nabla_w</span><span class="p">)]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="p">[</span><span class="n">w</span><span class="o">-</span><span class="p">(</span><span class="n">eta</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">mini_batch</span><span class="p">))</span><span class="o">*</span><span class="n">nw</span>
                        <span class="k">for</span> <span class="n">w</span><span class="p">,</span> <span class="n">nw</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">,</span> <span class="n">nabla_w</span><span class="p">)]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">biases</span> <span class="o">=</span> <span class="p">[</span><span class="n">b</span><span class="o">-</span><span class="p">(</span><span class="n">eta</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">mini_batch</span><span class="p">))</span><span class="o">*</span><span class="n">nb</span>
                       <span class="k">for</span> <span class="n">b</span><span class="p">,</span> <span class="n">nb</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">biases</span><span class="p">,</span> <span class="n">nabla_b</span><span class="p">)]</span>

    <span class="k">def</span> <span class="nf">backprop</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Return a tuple ``(nabla_b, nabla_w)`` representing the</span>
<span class="sd">        gradient for the cost function C_x.  ``nabla_b`` and</span>
<span class="sd">        ``nabla_w`` are layer-by-layer lists of numpy arrays, similar</span>
<span class="sd">        to ``self.biases`` and ``self.weights``.&quot;&quot;&quot;</span>
        <span class="n">nabla_b</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">b</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">biases</span><span class="p">]</span>
        <span class="n">nabla_w</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">w</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">]</span>
        <span class="c"># feedforward</span>
        <span class="n">activation</span> <span class="o">=</span> <span class="n">x</span>
        <span class="n">activations</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">]</span> <span class="c"># list to store all the activations, layer by layer</span>
        <span class="n">zs</span> <span class="o">=</span> <span class="p">[]</span> <span class="c"># list to store all the z vectors, layer by layer</span>
        <span class="k">for</span> <span class="n">b</span><span class="p">,</span> <span class="n">w</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">biases</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">):</span>
            <span class="n">z</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">activation</span><span class="p">)</span><span class="o">+</span><span class="n">b</span>
            <span class="n">zs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
            <span class="n">activation</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
            <span class="n">activations</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">activation</span><span class="p">)</span>
        <span class="c"># backward pass</span>
        <span class="n">delta</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cost_derivative</span><span class="p">(</span><span class="n">activations</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">y</span><span class="p">)</span> <span class="o">*</span> \
            <span class="n">sigmoid_prime</span><span class="p">(</span><span class="n">zs</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
        <span class="n">nabla_b</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">delta</span>
        <span class="n">nabla_w</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">delta</span><span class="p">,</span> <span class="n">activations</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">transpose</span><span class="p">())</span>
        <span class="c"># Note that the variable l in the loop below is used a little</span>
        <span class="c"># differently to the notation in Chapter 2 of the book.  Here,</span>
        <span class="c"># l = 1 means the last layer of neurons, l = 2 is the</span>
        <span class="c"># second-last layer, and so on.  It&#39;s a renumbering of the</span>
        <span class="c"># scheme in the book, used here to take advantage of the fact</span>
        <span class="c"># that Python can use negative indices in lists.</span>
        <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_layers</span><span class="p">):</span>
            <span class="n">z</span> <span class="o">=</span> <span class="n">zs</span><span class="p">[</span><span class="o">-</span><span class="n">l</span><span class="p">]</span>
            <span class="n">sp</span> <span class="o">=</span> <span class="n">sigmoid_prime</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
            <span class="n">delta</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">[</span><span class="o">-</span><span class="n">l</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">transpose</span><span class="p">(),</span> <span class="n">delta</span><span class="p">)</span> <span class="o">*</span> <span class="n">sp</span>
            <span class="n">nabla_b</span><span class="p">[</span><span class="o">-</span><span class="n">l</span><span class="p">]</span> <span class="o">=</span> <span class="n">delta</span>
            <span class="n">nabla_w</span><span class="p">[</span><span class="o">-</span><span class="n">l</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">delta</span><span class="p">,</span> <span class="n">activations</span><span class="p">[</span><span class="o">-</span><span class="n">l</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">transpose</span><span class="p">())</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">nabla_b</span><span class="p">,</span> <span class="n">nabla_w</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">evaluate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">test_data</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Return the number of test inputs for which the neural</span>
<span class="sd">        network outputs the correct result. Note that the neural</span>
<span class="sd">        network&#39;s output is assumed to be the index of whichever</span>
<span class="sd">        neuron in the final layer has the highest activation.&quot;&quot;&quot;</span>
        <span class="n">test_results</span> <span class="o">=</span> <span class="p">[(</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">feedforward</span><span class="p">(</span><span class="n">x</span><span class="p">)),</span> <span class="n">y</span><span class="p">)</span>
                        <span class="k">for</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="ow">in</span> <span class="n">test_data</span><span class="p">]</span>
        <span class="k">return</span> <span class="nb">sum</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">x</span> <span class="o">==</span> <span class="n">y</span><span class="p">)</span> <span class="k">for</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="ow">in</span> <span class="n">test_results</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">cost_derivative</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">output_activations</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Return the vector of partial derivatives \partial C_x /</span>
<span class="sd">        \partial a for the output activations.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">output_activations</span><span class="o">-</span><span class="n">y</span><span class="p">)</span>

<span class="c">#### Miscellaneous functions</span>
<span class="k">def</span> <span class="nf">sigmoid</span><span class="p">(</span><span class="n">z</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;The sigmoid function.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="mf">1.0</span><span class="o">/</span><span class="p">(</span><span class="mf">1.0</span><span class="o">+</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">z</span><span class="p">))</span>

<span class="k">def</span> <span class="nf">sigmoid_prime</span><span class="p">(</span><span class="n">z</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Derivative of the sigmoid function.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">z</span><span class="p">)</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">z</span><span class="p">))</span>
</pre></div>
</p><p>How well does the program recognize handwritten digits?  Well, let's
start by loading in the MNIST data.  I'll do this using a little
helper program, <tt>mnist_loader.py</tt>, to be described below.  We
execute the following commands in a Python shell,</p><p><div class="highlight"><pre><span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="nn">mnist_loader</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">training_data</span><span class="p">,</span> <span class="n">validation_data</span><span class="p">,</span> <span class="n">test_data</span> <span class="o">=</span> \
<span class="o">...</span> <span class="n">mnist_loader</span><span class="o">.</span><span class="n">load_data_wrapper</span><span class="p">()</span>
</pre></div>
</p><p>Of course, this could also be done in a separate Python program, but
if you're following along it's probably easiest to do in a Python
shell.  </p><p>After loading the MNIST data, we'll set up a <tt>Network</tt> with $30$
hidden neurons.  We do this after importing the Python program listed
above, which is named <tt>network</tt>,</p><p><div class="highlight"><pre><span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="nn">network</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">net</span> <span class="o">=</span> <span class="n">network</span><span class="o">.</span><span class="n">Network</span><span class="p">([</span><span class="mi">784</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">10</span><span class="p">])</span>
</pre></div>
</p><p>Finally, we'll use stochastic gradient descent to learn from the MNIST
<tt>training_data</tt> over 30 epochs, with a mini-batch size of 10, and a
learning rate of $\eta = 3.0$, </p><p><div class="highlight"><pre><span class="o">&gt;&gt;&gt;</span> <span class="n">net</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">training_data</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">,</span> <span class="n">test_data</span><span class="o">=</span><span class="n">test_data</span><span class="p">)</span>
</pre></div>
</p><p>Note that if you're running the code as you read along, it will take
some time to execute - for a typical machine (as of 2015) it will
likely take a few minutes to run.  I suggest you set things running,
continue to read, and periodically check the output from the code.  If
you're in a rush you can speed things up by decreasing the number of
epochs, by decreasing the number of hidden neurons, or by using only
part of the training data.  Note that production code would be much,
much faster: these Python scripts are intended to help you understand
how neural nets work, not to be high-performance code!  And, of
course, once we've trained a network it can be run very quickly
indeed, on almost any computing platform. For example, once we've
learned a good set of weights and biases for a network, it can easily
be ported to run in Javascript in a web browser, or as a native app on
a mobile device.  In any case, here is a partial transcript of the
output of one training run of the neural network.  The transcript
shows the number of test images correctly recognized by the neural
network after each epoch of training.  As you can see, after just a
single epoch this has reached 9,129 out of 10,000, and the number
continues to grow,</p><p><div class="highlight"><pre>Epoch 0: 9129 / 10000
Epoch 1: 9295 / 10000
Epoch 2: 9348 / 10000
...
Epoch 27: 9528 / 10000
Epoch 28: 9542 / 10000
Epoch 29: 9534 / 10000
</pre></div>
</p><p>That is, the trained network gives us a classification rate of about
$95$ percent - $95.42$ percent at its peak ("Epoch 28")!  That's
quite encouraging as a first attempt.  I should warn you, however,
that if you run the code then your results are not necessarily going
to be quite the same as mine, since we'll be initializing our network
using (different) random weights and biases.  To generate results in
this chapter I've taken best-of-three runs.</p><p>Let's rerun the above experiment, changing the number of hidden
neurons to $100$.  As was the case earlier, if you're running the code
as you read along, you should be warned that it takes quite a while to
execute (on my machine this experiment takes tens of seconds for each
training epoch), so it's wise to continue reading in parallel while
the code executes.</p><p><div class="highlight"><pre><span class="o">&gt;&gt;&gt;</span> <span class="n">net</span> <span class="o">=</span> <span class="n">network</span><span class="o">.</span><span class="n">Network</span><span class="p">([</span><span class="mi">784</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">10</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">net</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">training_data</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">,</span> <span class="n">test_data</span><span class="o">=</span><span class="n">test_data</span><span class="p">)</span>
</pre></div>
</p><p>Sure enough, this improves the results to $96.59$ percent.  At least
in this case, using more hidden neurons helps us get better
results*<span class="marginnote">
*Reader feedback indicates quite some variation in
  results for this experiment, and some training runs give results
  quite a bit worse.  Using the techniques introduced in chapter 3
  will greatly reduce the variation in performance across different
  training runs for our networks.</span>.</p><p>Of course, to obtain these accuracies I had to make specific choices
for the number of epochs of training, the mini-batch size, and the
learning rate, $\eta$.  As I mentioned above, these are known as
hyper-parameters for our neural network, in order to distinguish them
from the parameters (weights and biases) learnt by our learning
algorithm.  If we choose our hyper-parameters poorly, we can get bad
results.  Suppose, for example, that we'd chosen the learning rate to
be $\eta = 0.001$,</p><p><div class="highlight"><pre><span class="o">&gt;&gt;&gt;</span> <span class="n">net</span> <span class="o">=</span> <span class="n">network</span><span class="o">.</span><span class="n">Network</span><span class="p">([</span><span class="mi">784</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">10</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">net</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">training_data</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mf">0.001</span><span class="p">,</span> <span class="n">test_data</span><span class="o">=</span><span class="n">test_data</span><span class="p">)</span>
</pre></div>
</p><p>The results are much less encouraging,
<div class="highlight"><pre>Epoch 0: 1139 / 10000
Epoch 1: 1136 / 10000
Epoch 2: 1135 / 10000
...
Epoch 27: 2101 / 10000
Epoch 28: 2123 / 10000
Epoch 29: 2142 / 10000
</pre></div>

However, you can see that the performance of the network is getting
slowly better over time.  That suggests increasing the learning rate,
say to $\eta = 0.01$.  If we do that, we get better results, which
suggests increasing the learning rate again.  (If making a change
improves things, try doing more!)  If we do that several times over,
we'll end up with a learning rate of something like $\eta = 1.0$ (and
perhaps fine tune to $3.0$), which is close to our earlier
experiments.  So even though we initially made a poor choice of
hyper-parameters, we at least got enough information to help us
improve our choice of hyper-parameters.</p><p>In general, debugging a neural network can be challenging.  This is
especially true when the initial choice of hyper-parameters produces
results no better than random noise.  Suppose we try the successful 30
hidden neuron network architecture from earlier, but with the learning
rate changed to $\eta = 100.0$:
<div class="highlight"><pre><span class="o">&gt;&gt;&gt;</span> <span class="n">net</span> <span class="o">=</span> <span class="n">network</span><span class="o">.</span><span class="n">Network</span><span class="p">([</span><span class="mi">784</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">10</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">net</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">training_data</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mf">100.0</span><span class="p">,</span> <span class="n">test_data</span><span class="o">=</span><span class="n">test_data</span><span class="p">)</span>
</pre></div>

At this point we've actually gone too far, and the learning rate is
too high:
<div class="highlight"><pre><span class="n">Epoch</span> <span class="mi">0</span><span class="p">:</span> <span class="mi">1009</span> <span class="o">/</span> <span class="mi">10000</span>
<span class="n">Epoch</span> <span class="mi">1</span><span class="p">:</span> <span class="mi">1009</span> <span class="o">/</span> <span class="mi">10000</span>
<span class="n">Epoch</span> <span class="mi">2</span><span class="p">:</span> <span class="mi">1009</span> <span class="o">/</span> <span class="mi">10000</span>
<span class="n">Epoch</span> <span class="mi">3</span><span class="p">:</span> <span class="mi">1009</span> <span class="o">/</span> <span class="mi">10000</span>
<span class="o">...</span>
<span class="n">Epoch</span> <span class="mi">27</span><span class="p">:</span> <span class="mi">982</span> <span class="o">/</span> <span class="mi">10000</span>
<span class="n">Epoch</span> <span class="mi">28</span><span class="p">:</span> <span class="mi">982</span> <span class="o">/</span> <span class="mi">10000</span>
<span class="n">Epoch</span> <span class="mi">29</span><span class="p">:</span> <span class="mi">982</span> <span class="o">/</span> <span class="mi">10000</span>
</pre></div>

Now imagine that we were coming to this problem for the first time.
Of course, we <em>know</em> from our earlier experiments that the right
thing to do is to decrease the learning rate.  But if we were coming
to this problem for the first time then there wouldn't be much in the
output to guide us on what to do.  We might worry not only about the
learning rate, but about every other aspect of our neural network.  We
might wonder if we've initialized the weights and biases in a way that
makes it hard for the network to learn?  Or maybe we don't have enough
training data to get meaningful learning?  Perhaps we haven't run for
enough epochs?  Or maybe it's impossible for a neural network with
this architecture to learn to recognize handwritten digits?  Maybe the
learning rate is too <em>low</em>?  Or, maybe, the learning rate is too
high?  When you're coming to a problem for the first time, you're not
always sure.</p><p>The lesson to take away from this is that debugging a neural network
is not trivial, and, just as for ordinary programming, there is an art
to it.  You need to learn that art of debugging in order to get good
results from neural networks.  More generally, we need to develop
heuristics for choosing good hyper-parameters and a good architecture.
We'll discuss all these at length through the book, including how I
chose the hyper-parameters above.</p><p>
<h4><a name="exercise_420023"></a><a href="#exercise_420023">Exercise</a></h4><ul></p><p><li> Try creating a network with just two layers - an input and an
  output layer, no hidden layer - with 784 and 10 neurons,
  respectively.  Train the network using stochastic gradient descent.
  What classification accuracy can you achieve?
</ul></p><p></p><p>Earlier, I skipped over the details of how the MNIST data is loaded.
It's pretty straightforward.  For completeness, here's the code.  The
data structures used to store the MNIST data are described in the
documentation strings - it's straightforward stuff, tuples and lists
of Numpy <tt>ndarray</tt> objects (think of them as vectors if you're
not familiar with <tt>ndarray</tt>s):</p><p><div class="highlight"><pre><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">mnist_loader</span>
<span class="sd">~~~~~~~~~~~~</span>

<span class="sd">A library to load the MNIST image data.  For details of the data</span>
<span class="sd">structures that are returned, see the doc strings for ``load_data``</span>
<span class="sd">and ``load_data_wrapper``.  In practice, ``load_data_wrapper`` is the</span>
<span class="sd">function usually called by our neural network code.</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="c">#### Libraries</span>
<span class="c"># Standard library</span>
<span class="kn">import</span> <span class="nn">cPickle</span>
<span class="kn">import</span> <span class="nn">gzip</span>

<span class="c"># Third-party libraries</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>

<span class="k">def</span> <span class="nf">load_data</span><span class="p">():</span>
    <span class="sd">&quot;&quot;&quot;Return the MNIST data as a tuple containing the training data,</span>
<span class="sd">    the validation data, and the test data.</span>

<span class="sd">    The ``training_data`` is returned as a tuple with two entries.</span>
<span class="sd">    The first entry contains the actual training images.  This is a</span>
<span class="sd">    numpy ndarray with 50,000 entries.  Each entry is, in turn, a</span>
<span class="sd">    numpy ndarray with 784 values, representing the 28 * 28 = 784</span>
<span class="sd">    pixels in a single MNIST image.</span>

<span class="sd">    The second entry in the ``training_data`` tuple is a numpy ndarray</span>
<span class="sd">    containing 50,000 entries.  Those entries are just the digit</span>
<span class="sd">    values (0...9) for the corresponding images contained in the first</span>
<span class="sd">    entry of the tuple.</span>

<span class="sd">    The ``validation_data`` and ``test_data`` are similar, except</span>
<span class="sd">    each contains only 10,000 images.</span>

<span class="sd">    This is a nice data format, but for use in neural networks it&#39;s</span>
<span class="sd">    helpful to modify the format of the ``training_data`` a little.</span>
<span class="sd">    That&#39;s done in the wrapper function ``load_data_wrapper()``, see</span>
<span class="sd">    below.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">f</span> <span class="o">=</span> <span class="n">gzip</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="s">&#39;../data/mnist.pkl.gz&#39;</span><span class="p">,</span> <span class="s">&#39;rb&#39;</span><span class="p">)</span>
    <span class="n">training_data</span><span class="p">,</span> <span class="n">validation_data</span><span class="p">,</span> <span class="n">test_data</span> <span class="o">=</span> <span class="n">cPickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
    <span class="n">f</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">training_data</span><span class="p">,</span> <span class="n">validation_data</span><span class="p">,</span> <span class="n">test_data</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">load_data_wrapper</span><span class="p">():</span>
    <span class="sd">&quot;&quot;&quot;Return a tuple containing ``(training_data, validation_data,</span>
<span class="sd">    test_data)``. Based on ``load_data``, but the format is more</span>
<span class="sd">    convenient for use in our implementation of neural networks.</span>

<span class="sd">    In particular, ``training_data`` is a list containing 50,000</span>
<span class="sd">    2-tuples ``(x, y)``.  ``x`` is a 784-dimensional numpy.ndarray</span>
<span class="sd">    containing the input image.  ``y`` is a 10-dimensional</span>
<span class="sd">    numpy.ndarray representing the unit vector corresponding to the</span>
<span class="sd">    correct digit for ``x``.</span>

<span class="sd">    ``validation_data`` and ``test_data`` are lists containing 10,000</span>
<span class="sd">    2-tuples ``(x, y)``.  In each case, ``x`` is a 784-dimensional</span>
<span class="sd">    numpy.ndarry containing the input image, and ``y`` is the</span>
<span class="sd">    corresponding classification, i.e., the digit values (integers)</span>
<span class="sd">    corresponding to ``x``.</span>

<span class="sd">    Obviously, this means we&#39;re using slightly different formats for</span>
<span class="sd">    the training data and the validation / test data.  These formats</span>
<span class="sd">    turn out to be the most convenient for use in our neural network</span>
<span class="sd">    code.&quot;&quot;&quot;</span>
    <span class="n">tr_d</span><span class="p">,</span> <span class="n">va_d</span><span class="p">,</span> <span class="n">te_d</span> <span class="o">=</span> <span class="n">load_data</span><span class="p">()</span>
    <span class="n">training_inputs</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">(</span><span class="mi">784</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">tr_d</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>
    <span class="n">training_results</span> <span class="o">=</span> <span class="p">[</span><span class="n">vectorized_result</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">tr_d</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span>
    <span class="n">training_data</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="n">training_inputs</span><span class="p">,</span> <span class="n">training_results</span><span class="p">)</span>
    <span class="n">validation_inputs</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">(</span><span class="mi">784</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">va_d</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>
    <span class="n">validation_data</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="n">validation_inputs</span><span class="p">,</span> <span class="n">va_d</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">test_inputs</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">(</span><span class="mi">784</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">te_d</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>
    <span class="n">test_data</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="n">test_inputs</span><span class="p">,</span> <span class="n">te_d</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">training_data</span><span class="p">,</span> <span class="n">validation_data</span><span class="p">,</span> <span class="n">test_data</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">vectorized_result</span><span class="p">(</span><span class="n">j</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Return a 10-dimensional unit vector with a 1.0 in the jth</span>
<span class="sd">    position and zeroes elsewhere.  This is used to convert a digit</span>
<span class="sd">    (0...9) into a corresponding desired output from the neural</span>
<span class="sd">    network.&quot;&quot;&quot;</span>
    <span class="n">e</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">10</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="n">e</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.0</span>
    <span class="k">return</span> <span class="n">e</span>
</pre></div>
</p><p>I said above that our program gets pretty good results.  What does
that mean?  Good compared to what?  It's informative to have some
simple (non-neural-network) baseline tests to compare against, to
understand what it means to perform well.  The simplest baseline of
all, of course, is to randomly guess the digit.  That'll be right
about ten percent of the time.  We're doing much better than that!</p><p>What about a less trivial baseline?  Let's try an extremely simple
idea: we'll look at how <em>dark</em> an image is.  For instance, an
image of a $2$ will typically be quite a bit darker than an image of a
$1$, just because more pixels are blackened out, as the following
examples illustrate:</p><p><center><img src="images/mnist_2_and_1.png" width="256px"></center></p><p>This suggests using the training data to compute average darknesses
for each digit, $0, 1, 2,\ldots, 9$.  When presented with a new image,
we compute how dark the image is, and then guess that it's whichever
digit has the closest average darkness.  This is a simple procedure,
and is easy to code up, so I won't explicitly write out the code -
if you're interested it's in the
<a href="https://github.com/mnielsen/neural-networks-and-deep-learning/blob/master/src/mnist_average_darkness.py">GitHub
  repository</a>.  But it's a big improvement over random guessing,
getting $2,225$ of the $10,000$ test images correct, i.e., $22.25$
percent accuracy.</p><p><a name="SVM"></a></p><p>It's not difficult to find other ideas which achieve accuracies in the
$20$ to $50$ percent range.  If you work a bit harder you can get up
over $50$ percent.  But to get much higher accuracies it helps to use
established machine learning algorithms.  Let's try using one of the
best known algorithms, the <em>support vector
  machine</em>
or <em>SVM</em>.  If you're not
familiar with SVMs, not to worry, we're not going to need to
understand the details of how SVMs work.  Instead, we'll use a Python
library called
<a href="http://scikit-learn.org/stable/">scikit-learn</a>,
which provides a simple Python interface to a fast C-based library for
SVMs known as
<a href="http://www.csie.ntu.edu.tw/&#126;cjlin/libsvm/">LIBSVM</a>.</p><p>If we run scikit-learn's SVM classifier using the default settings,
then it gets 9,435 of 10,000 test images correct.  (The code is
available
<a href="https://github.com/mnielsen/neural-networks-and-deep-learning/blob/master/src/mnist_svm.py">here</a>.)
That's a big improvement over our naive approach of classifying an
image based on how dark it is.  Indeed, it means that the SVM is
performing roughly as well as our neural networks, just a little
worse.  In later chapters we'll introduce new techniques that enable
us to improve our neural networks so that they perform much better
than the SVM.</p><p>That's not the end of the story, however.  The 9,435 of 10,000 result
is for scikit-learn's default settings for SVMs.  SVMs have a number
of tunable parameters, and it's possible to search for parameters
which improve this out-of-the-box performance.  I won't explicitly do
this search, but instead refer you to
<a href="http://peekaboo-vision.blogspot.de/2010/09/mnist-for-ever.html">this
  blog post</a> by <a href="http://peekaboo-vision.blogspot.ca/">Andreas
  Mueller</a> if you'd like to know more.  Mueller shows that with some
work optimizing the SVM's parameters it's possible to get the
performance up above 98.5 percent accuracy.  In other words, a
well-tuned SVM only makes an error on about one digit in 70.  That's
pretty good!  Can neural networks do better?</p><p>In fact, they can.  At present, well-designed neural networks
outperform every other technique for solving MNIST, including SVMs.
The current (2013) record is classifying 9,979 of 10,000 images
correctly.  This was done by <a href="http://www.cs.nyu.edu/&#126;wanli/">Li
  Wan</a>, <a href="http://www.matthewzeiler.com/">Matthew Zeiler</a>, Sixin
Zhang, <a href="http://yann.lecun.com/">Yann LeCun</a>, and
<a href="http://cs.nyu.edu/&#126;fergus/pmwiki/pmwiki.php">Rob Fergus</a>.
We'll see most of the techniques they used later in the book.  At that
level the performance is close to human-equivalent, and is arguably
better, since quite a few of the MNIST images are difficult even for
humans to recognize with confidence, for example:</p><p><center><img src="images/mnist_really_bad_images.png" width="560px"></center></p><p>I trust you'll agree that those are tough to classify!  With images
like these in the MNIST data set it's remarkable that neural networks
can accurately classify all but 21 of the 10,000 test images.
Usually, when programming we believe that solving a complicated
problem like recognizing the MNIST digits requires a sophisticated
algorithm.  But even the neural networks in the Wan <em>et al</em> paper
just mentioned involve quite simple algorithms, variations on the
algorithm we've seen in this chapter.  All the complexity is learned,
automatically, from the training data. In some sense, the moral of
both our results and those in more sophisticated papers, is that for
some problems:
<center>
  sophisticated algorithm $\leq$ simple learning algorithm + good
  training data.
</center></p><p><h3><a name="toward_deep_learning"></a><a href="#toward_deep_learning">Toward deep learning</a></h3></p><p>While our neural network gives impressive performance, that
performance is somewhat mysterious.  The weights and biases in the
network were discovered automatically.  And that means we don't
immediately have an explanation of how the network does what it does.
Can we find some way to understand the principles by which our network
is classifying handwritten digits?  And, given such principles, can we
do better?</p><p>To put these questions more starkly, suppose that a few decades hence
neural networks lead to artificial intelligence (AI).  Will we
understand how such intelligent networks work?  Perhaps the networks
will be opaque to us, with weights and biases we don't understand,
because they've been learned automatically.  In the early days of AI
research people hoped that the effort to build an AI would also help
us understand the principles behind intelligence and, maybe, the
functioning of the human brain.  But perhaps the outcome will be that
we end up understanding neither the brain nor how artificial
intelligence works!</p><p>To address these questions, let's think back to the interpretation of
artificial neurons that I gave at the start of the chapter, as a means
of weighing evidence.  Suppose we want to determine whether an image
shows a human face or not:</p><p> </p><p>  <span class="marginnote">Credits: 1. <a
  href="http://commons.wikimedia.org/wiki/User:ST">Ester Inbar</a>. 2.
  Unknown. 3. NASA, ESA, G. Illingworth, D. Magee, and P. Oesch
  (University of California, Santa Cruz), R. Bouwens (Leiden
  University), and the HUDF09 Team.  Click on the images for more
  details.</span></p><p>  <a
  href="http://commons.wikimedia.org/wiki/File:Kangaroo_ST_03.JPG"><img
  src="images/Kangaroo.JPG" height="190px"/></a> <a
  href="http://commons.wikimedia.org/wiki/File:Albert_Einstein_at_the_age_of_three_(1882).jpg"><img
  src="images/Einstein_crop.jpg" height="190px"/></a> <a
  href="http://commons.wikimedia.org/wiki/File:The_Hubble_eXtreme_Deep_Field.jpg"><img
  src="images/hubble.jpg" height="190px"/></a> </p><p>We could attack this problem the same way we attacked handwriting
recognition - by using the pixels in the image as input to a neural
network, with the output from the network a single neuron indicating
either "Yes, it's a face" or "No, it's not a face".</p><p>Let's suppose we do this, but that we're not using a learning
algorithm.  Instead, we're going to try to design a network by hand,
choosing appropriate weights and biases.  How might we go about it?
Forgetting neural networks entirely for the moment, a heuristic we
could use is to decompose the problem into sub-problems: does the
image have an eye in the top left?  Does it have an eye in the top
right?  Does it have a nose in the middle?  Does it have a mouth in
the bottom middle?  Is there hair on top?  And so on.</p><p>If the answers to several of these questions are "yes", or even just
"probably yes", then we'd conclude that the image is likely to be a
face.  Conversely, if the answers to most of the questions are "no",
then the image probably isn't a face.</p><p>Of course, this is just a rough heuristic, and it suffers from many
deficiencies.  Maybe the person is bald, so they have no hair.  Maybe
we can only see part of the face, or the face is at an angle, so some
of the facial features are obscured.  Still, the heuristic suggests
that if we can solve the sub-problems using neural networks, then
perhaps we can build a neural network for face-detection, by combining
the networks for the sub-problems.  Here's a possible architecture,
with rectangles denoting the sub-networks.  Note that this isn't
intended as a realistic approach to solving the face-detection
problem; rather, it's to help us build intuition about how networks
function.  Here's the architecture:</p><p><center>
<img src="images/tikz14.png"/>
</center></p><p>It's also plausible that the sub-networks can be decomposed.  Suppose
we're considering the question: "Is there an eye in the top left?"
This can be decomposed into questions such as: "Is there an
eyebrow?"; "Are there eyelashes?"; "Is there an iris?"; and so
on.  Of course, these questions should really include positional
information, as well - "Is the eyebrow in the top left, and above
the iris?", that kind of thing - but let's keep it simple.  The
network to answer the question "Is there an eye in the top left?"
can now be decomposed:</p><p><center>
<img src="images/tikz15.png"/>
</center></p><p>Those questions too can be broken down, further and further through
multiple layers.  Ultimately, we'll be working with sub-networks that
answer questions so simple they can easily be answered at the level of
single pixels.  Those questions might, for example, be about the
presence or absence of very simple shapes at particular points in the
image.  Such questions can be answered by single neurons connected to
the raw pixels in the image.</p><p>The end result is a network which breaks down a very complicated
question - does this image show a face or not - into very simple
questions answerable at the level of single pixels.  It does this
through a series of many layers, with early layers answering very
simple and specific questions about the input image, and later layers
building up a hierarchy of ever more complex and abstract concepts.
Networks with this kind of many-layer structure - two or more hidden
layers - are called <em>deep neural networks</em>.</p><p></p><p></p><p>
Of course, I haven't said how to do this recursive decomposition into
sub-networks.  It certainly isn't practical to hand-design the weights
and biases in the network.  Instead, we'd like to use learning
algorithms so that the network can automatically learn the weights and
biases - and thus, the hierarchy of concepts - from training data.
Researchers in the 1980s and 1990s tried using stochastic gradient
descent and backpropagation to train deep networks.  Unfortunately,
except for a few special architectures, they didn't have much luck.
The networks would learn, but very slowly, and in practice often too
slowly to be useful.</p><p>Since 2006, a set of techniques has been developed that enable
learning in deep neural nets.  These deep learning techniques are
based on stochastic gradient descent and backpropagation, but also
introduce new ideas.  These techniques have enabled much deeper (and
larger) networks to be trained - people now routinely train networks
with 5 to 10 hidden layers.  And, it turns out that these perform far
better on many problems than shallow neural networks, i.e., networks
with just a single hidden layer.  The reason, of course, is the
ability of deep nets to build up a complex hierarchy of concepts.
It's a bit like the way conventional programming languages use modular
design and ideas about abstraction to enable the creation of complex
computer programs.  Comparing a deep network to a shallow network is a
bit like comparing a programming language with the ability to make
function calls to a stripped down language with no ability to make
such calls.  Abstraction takes a different form in neural networks
than it does in conventional programming, but it's just as important.</p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p>
</div>






<div class="footer"> <span class="left_footer"> In academic work,
please cite this book as: Michael A. Nielsen, "Neural Networks and
Deep Learning", Determination Press, 2015

<br/>
<br/>

This work is licensed under a <a rel="license"
href="http://creativecommons.org/licenses/by-nc/3.0/deed.en_GB"
style="color: #eee;">Creative Commons Attribution-NonCommercial 3.0
Unported License</a>.  This means you're free to copy, share, and
build on this book, but not to sell it.  If you're interested in
commercial use, please <a
href="mailto:mn@michaelnielsen.org">contact me</a>.
</span>
<span class="right_footer">
Last update: Thu Aug 13 11:49:43 2015
<br/>
<br/>
<br/>
<a rel="license" href="http://creativecommons.org/licenses/by-nc/3.0/deed.en_GB"><img alt="Creative Commons Licence" style="border-width:0" src="https://i.creativecommons.org/l/by-nc/3.0/88x31.png" /></a>
</span>
</div>

</body>
</html>
