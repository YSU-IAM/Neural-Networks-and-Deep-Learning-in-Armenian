<!DOCTYPE html>
<html lang="en">
<!-- Produced from a LaTeX source file.  Note that the production is done -->
<!-- by a very rough-and-ready (and buggy) script, so the HTML and other  -->
<!-- code is quite ugly!  Later versions should be better.                -->
    <meta charset="utf-8">
    <meta name="citation_title" content="Neural Networks and Deep Learning">
    <meta name="citation_author" content="Nielsen, Michael A.">
    <meta name="citation_publication_date" content="2015">
    <meta name="citation_fulltext_html_url" content="http://neuralnetworksanddeeplearning.com">
    <meta name="citation_publisher" content="Determination Press">
    <link rel="icon" href="nnadl_favicon.ICO" />
    <title>Նեյրոնային ցանցեր և խորը ուսուցում: Մայքլ Նիլսենի գրքի թարգմանությունը հայերեն</title>
    <script src="assets/jquery.min.js"></script>
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {inlineMath: [['$','$']]},
        "HTML-CSS":
          {scale: 92},
        TeX: { equationNumbers: { autoNumber: "AMS" }}});
    </script>
    <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>


    <link href="assets/style.css" rel="stylesheet">
    <link href="assets/pygments.css" rel="stylesheet">
    <link rel="stylesheet" href="https://code.jquery.com/ui/1.11.2/themes/smoothness/jquery-ui.css">

<style>
/* Adapted from */
/* https://groups.google.com/d/msg/mathjax-users/jqQxrmeG48o/oAaivLgLN90J, */
/* by David Cervone */

@font-face {
    font-family: 'MJX_Math';
    src: url('https://cdn.mathjax.org/mathjax/latest/fonts/HTML-CSS/TeX/eot/MathJax_Math-Italic.eot'); /* IE9 Compat Modes */
    src: url('https://cdn.mathjax.org/mathjax/latest/fonts/HTML-CSS/TeX/eot/MathJax_Math-Italic.eot?iefix') format('eot'),
    url('https://cdn.mathjax.org/mathjax/latest/fonts/HTML-CSS/TeX/woff/MathJax_Math-Italic.woff')  format('woff'),
    url('https://cdn.mathjax.org/mathjax/latest/fonts/HTML-CSS/TeX/otf/MathJax_Math-Italic.otf')  format('opentype'),
    url('https://cdn.mathjax.org/mathjax/latest/fonts/HTML-CSS/TeX/svg/MathJax_Math-Italic.svg#MathJax_Math-Italic') format('svg');
}

@font-face {
    font-family: 'MJX_Main';
    src: url('https://cdn.mathjax.org/mathjax/latest/fonts/HTML-CSS/TeX/eot/MathJax_Main-Regular.eot'); /* IE9 Compat Modes */
    src: url('https://cdn.mathjax.org/mathjax/latest/fonts/HTML-CSS/TeX/eot/MathJax_Main-Regular.eot?iefix') format('eot'),
    url('https://cdn.mathjax.org/mathjax/latest/fonts/HTML-CSS/TeX/woff/MathJax_Main-Regular.woff')  format('woff'),
    url('https://cdn.mathjax.org/mathjax/latest/fonts/HTML-CSS/TeX/otf/MathJax_Main-Regular.otf')  format('opentype'),
    url('https://cdn.mathjax.org/mathjax/latest/fonts/HTML-CSS/TeX/svg/MathJax_Main-Regular.svg#MathJax_Main-Regular') format('svg');
}
</style>

  </head>
  <body><div class="nonumber_header"><h2><a href="index.html">Նեյրոնային ցանցեր և խորը ուսուցում</a></h2></div><div class="section"><div id="toc">
<p class="toc_title"><a href="index.html">Նեյրոնային ցանցեր և խորը ուսուցում</a></p><p class="toc_not_mainchapter"><a href="about.html">Ինչի՞ մասին է գիրքը</a></p><p class="toc_not_mainchapter"><a href="exercises_and_problems.html">Խնդիրների և վարժությունների մասին</a></p><p class='toc_mainchapter'><a id="toc_using_neural_nets_to_recognize_handwritten_digits_reveal" class="toc_reveal" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';"><img id="toc_img_using_neural_nets_to_recognize_handwritten_digits" src="images/arrow.png" width="15px"></a><a href="chap1.html">Ձեռագիր թվերի ճանաչում օգտագործելով նեյրոնային ցանծեր</a><div id="toc_using_neural_nets_to_recognize_handwritten_digits" style="display: none;"><p class="toc_section"><ul><a href="chap1.html#perceptrons"><li>Պերսեպտրոններ</li></a><a href="chap1.html#sigmoid_neurons"><li>Սիգմոիդ նեյրոններ</li></a><a href="chap1.html#the_architecture_of_neural_networks"><li>Նեյրոնային ցանցերի կառուցվածքը</li></a><a href="chap1.html#a_simple_network_to_classify_handwritten_digits"><li>Պարզ ցանց ձեռագիր թվերի դասակարգման համար</li></a><a href="chap1.html#learning_with_gradient_descent"><li>Սովորում գրադիենտային նվազման միջոցով</li></a><a href="chap1.html#implementing_our_network_to_classify_digits"><li>Թվերի դասակարգման համար նախատեսված ցանցի իրականացումը</li></a><a href="chap1.html#toward_deep_learning"><li>Խորը ուսուցմանն ընդառաջ</li></a></ul></p></div>
<script>
$('#toc_using_neural_nets_to_recognize_handwritten_digits_reveal').click(function() {
   var src = $('#toc_img_using_neural_nets_to_recognize_handwritten_digits').attr('src');
   if(src == 'images/arrow.png') {
     $("#toc_img_using_neural_nets_to_recognize_handwritten_digits").attr('src', 'images/arrow_down.png');
   } else {
     $("#toc_img_using_neural_nets_to_recognize_handwritten_digits").attr('src', 'images/arrow.png');
   };
   $('#toc_using_neural_nets_to_recognize_handwritten_digits').toggle('fast', function() {});
});</script><p class='toc_mainchapter'><a id="toc_how_the_backpropagation_algorithm_works_reveal" class="toc_reveal" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';"><img id="toc_img_how_the_backpropagation_algorithm_works" src="images/arrow.png" width="15px"></a><a href="chap2.html">How the backpropagation algorithm works</a><div id="toc_how_the_backpropagation_algorithm_works" style="display: none;"><p class="toc_section"><ul><a href="chap2.html#warm_up_a_fast_matrix-based_approach_to_computing_the_output
_from_a_neural_network"><li>Warm up: a fast matrix-based approach to computing the output
  from a neural network</li></a><a href="chap2.html#the_two_assumptions_we_need_about_the_cost_function"><li>The two assumptions we need about the cost function</li></a><a href="chap2.html#the_hadamard_product_$s_\odot_t$"><li>The Hadamard product, $s \odot t$</li></a><a href="chap2.html#the_four_fundamental_equations_behind_backpropagation"><li>The four fundamental equations behind backpropagation</li></a><a href="chap2.html#proof_of_the_four_fundamental_equations_(optional)"><li>Proof of the four fundamental equations (optional)</li></a><a href="chap2.html#the_backpropagation_algorithm"><li>The backpropagation algorithm</li></a><a href="chap2.html#the_code_for_backpropagation"><li>The code for backpropagation</li></a><a href="chap2.html#in_what_sense_is_backpropagation_a_fast_algorithm"><li>In what sense is backpropagation a fast algorithm?</li></a><a href="chap2.html#backpropagation_the_big_picture"><li>Backpropagation: the big picture</li></a></ul></p></div>
<script>
$('#toc_how_the_backpropagation_algorithm_works_reveal').click(function() {
   var src = $('#toc_img_how_the_backpropagation_algorithm_works').attr('src');
   if(src == 'images/arrow.png') {
     $("#toc_img_how_the_backpropagation_algorithm_works").attr('src', 'images/arrow_down.png');
   } else {
     $("#toc_img_how_the_backpropagation_algorithm_works").attr('src', 'images/arrow.png');
   };
   $('#toc_how_the_backpropagation_algorithm_works').toggle('fast', function() {});
});</script><p class='toc_mainchapter'><a id="toc_improving_the_way_neural_networks_learn_reveal" class="toc_reveal" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';"><img id="toc_img_improving_the_way_neural_networks_learn" src="images/arrow.png" width="15px"></a><a href="chap3.html">Improving the way neural networks learn</a><div id="toc_improving_the_way_neural_networks_learn" style="display: none;"><p class="toc_section"><ul><a href="chap3.html#the_cross-entropy_cost_function"><li>The cross-entropy cost function</li></a><a href="chap3.html#overfitting_and_regularization"><li>Overfitting and regularization</li></a><a href="chap3.html#weight_initialization"><li>Weight initialization</li></a><a href="chap3.html#handwriting_recognition_revisited_the_code"><li>Handwriting recognition revisited: the code</li></a><a href="chap3.html#how_to_choose_a_neural_network's_hyper-parameters"><li>How to choose a neural network's hyper-parameters?</li></a><a href="chap3.html#other_techniques"><li>Other techniques</li></a></ul></p></div>
<script>
$('#toc_improving_the_way_neural_networks_learn_reveal').click(function() {
   var src = $('#toc_img_improving_the_way_neural_networks_learn').attr('src');
   if(src == 'images/arrow.png') {
     $("#toc_img_improving_the_way_neural_networks_learn").attr('src', 'images/arrow_down.png');
   } else {
     $("#toc_img_improving_the_way_neural_networks_learn").attr('src', 'images/arrow.png');
   };
   $('#toc_improving_the_way_neural_networks_learn').toggle('fast', function() {});
});</script><p class='toc_mainchapter'><a id="toc_a_visual_proof_that_neural_nets_can_compute_any_function_reveal" class="toc_reveal" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';"><img id="toc_img_a_visual_proof_that_neural_nets_can_compute_any_function" src="images/arrow.png" width="15px"></a><a href="chap4.html">A visual proof that neural nets can compute any function</a><div id="toc_a_visual_proof_that_neural_nets_can_compute_any_function" style="display: none;"><p class="toc_section"><ul><a href="chap4.html#two_caveats"><li>Two caveats</li></a><a href="chap4.html#universality_with_one_input_and_one_output"><li>Universality with one input and one output</li></a><a href="chap4.html#many_input_variables"><li>Many input variables</li></a><a href="chap4.html#extension_beyond_sigmoid_neurons"><li>Extension beyond sigmoid neurons</li></a><a href="chap4.html#fixing_up_the_step_functions"><li>Fixing up the step functions</li></a><a href="chap4.html#conclusion"><li>Conclusion</li></a></ul></p></div>
<script>
$('#toc_a_visual_proof_that_neural_nets_can_compute_any_function_reveal').click(function() {
   var src = $('#toc_img_a_visual_proof_that_neural_nets_can_compute_any_function').attr('src');
   if(src == 'images/arrow.png') {
     $("#toc_img_a_visual_proof_that_neural_nets_can_compute_any_function").attr('src', 'images/arrow_down.png');
   } else {
     $("#toc_img_a_visual_proof_that_neural_nets_can_compute_any_function").attr('src', 'images/arrow.png');
   };
   $('#toc_a_visual_proof_that_neural_nets_can_compute_any_function').toggle('fast', function() {});
});</script><p class='toc_mainchapter'><a id="toc_why_are_deep_neural_networks_hard_to_train_reveal" class="toc_reveal" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';"><img id="toc_img_why_are_deep_neural_networks_hard_to_train" src="images/arrow.png" width="15px"></a><a href="chap5.html">Why are deep neural networks hard to train?</a><div id="toc_why_are_deep_neural_networks_hard_to_train" style="display: none;"><p class="toc_section"><ul><a href="chap5.html#the_vanishing_gradient_problem"><li>The vanishing gradient problem</li></a><a href="chap5.html#what's_causing_the_vanishing_gradient_problem_unstable_gradients_in_deep_neural_nets"><li>What's causing the vanishing gradient problem?  Unstable gradients in deep neural nets</li></a><a href="chap5.html#unstable_gradients_in_more_complex_networks"><li>Unstable gradients in more complex networks</li></a><a href="chap5.html#other_obstacles_to_deep_learning"><li>Other obstacles to deep learning</li></a></ul></p></div>
<script>
$('#toc_why_are_deep_neural_networks_hard_to_train_reveal').click(function() {
   var src = $('#toc_img_why_are_deep_neural_networks_hard_to_train').attr('src');
   if(src == 'images/arrow.png') {
     $("#toc_img_why_are_deep_neural_networks_hard_to_train").attr('src', 'images/arrow_down.png');
   } else {
     $("#toc_img_why_are_deep_neural_networks_hard_to_train").attr('src', 'images/arrow.png');
   };
   $('#toc_why_are_deep_neural_networks_hard_to_train').toggle('fast', function() {});
});</script><p class='toc_mainchapter'><a id="toc_deep_learning_reveal" class="toc_reveal" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';"><img id="toc_img_deep_learning" src="images/arrow.png" width="15px"></a><a href="chap6.html">Deep learning</a><div id="toc_deep_learning" style="display: none;"><p class="toc_section"><ul><a href="chap6.html#introducing_convolutional_networks"><li>Introducing convolutional networks</li></a><a href="chap6.html#convolutional_neural_networks_in_practice"><li>Convolutional neural networks in practice</li></a><a href="chap6.html#the_code_for_our_convolutional_networks"><li>The code for our convolutional networks</li></a><a href="chap6.html#recent_progress_in_image_recognition"><li>Recent progress in image recognition</li></a><a href="chap6.html#other_approaches_to_deep_neural_nets"><li>Other approaches to deep neural nets</li></a><a href="chap6.html#on_the_future_of_neural_networks"><li>On the future of neural networks</li></a></ul></p></div>
<script>
$('#toc_deep_learning_reveal').click(function() {
   var src = $('#toc_img_deep_learning').attr('src');
   if(src == 'images/arrow.png') {
     $("#toc_img_deep_learning").attr('src', 'images/arrow_down.png');
   } else {
     $("#toc_img_deep_learning").attr('src', 'images/arrow.png');
   };
   $('#toc_deep_learning').toggle('fast', function() {});
});</script><p class="toc_not_mainchapter"><a href="sai.html">Appendix: Is there a <em>simple</em> algorithm for intelligence?</a></p><p class="toc_not_mainchapter"><a href="acknowledgements.html">Acknowledgements</a></p><p class="toc_not_mainchapter"><a href="faq.html">Frequently Asked Questions</a></p>
</div>



<p>
Մարդկային տեսողական համակարգը աշխարհի հրաշալիքներից է: Դիտարկենք ձեռագիր թվանշանների հետևյալ հերթականությունը: <a name="complete_zero"></a></p>

<p><center><img src="images/digits.png" width="160px"></center> </p>

<p>
  Մարդկանց մեծամասնությունը առանց ջանք գործադրելու կարող է ճանաչել 504192 թվերը: Այդ դյուրինությունը խաբուսիկ է սակայն: Մարդկային ուղեղի կիսագնդերում պարունակվում է հիմնական տեսողական կորտեքսը, որը հայտնի է որպես V1: Այն պարունակում է 140 միլիոն նեյրոններ, որոնք իրար հետ կապված են տասնյակ միլիարդավոր կապերով: Ընդ որում, մարդկային տեսողությունը բաղկացած չէ միայն V1-ից, այլ V2, V3, V4, և V5 տեսողական կորտեքսներից, որոնք իրականացնում են բազմաթիվ նկարների մշակում:
  Մեր գլուխներն ըստ էության պարունակում են սուպեր համակարգիչներ` էվոլյուցիայի միջոցով կատարելագործված միլիոնավոր տարիների ընթացքում և հրաշալիորեն հարմարված տեսանելի աշխարհը հասկանալու համար: Ձեռագիր թվանշանները հասկանալը հեշտ չէ, այնուամենայնիվ, մարկանց մոտ լավ է ստացվում հասկանալ այն ինչ իրենց աչքերն են ընկալում: Սակայն գրեթե ամբողջ այդ աշխատանքը կատարվում է ենթագիտակցորեն, հետևաբար մենք ըստ արժանվույն չենք գնահատում թե ինչպիսի դժվար խնդիր է լուծում տեսողական համակարգը:
</p>

<p>
  Տեսողական օրինաչափությունը հասկանալու դժվարությունը երևան է գալիս այն ժամանակ երբ փորձ է
  արվում ստեղծելու ծրագիր ձեռագիր թվանշաններ ճանաչելու համար: Մեզ հեշտ թվացող այդ երևույթը
  պարզվում է, որ բավականին բարդ է: Պատկերներ ճանաչելու պարզ ինտուիցիան (9 թվանշանը վերևում
  շրջանաձև է, որը կապվում է նրեքևի հետ կոր ուղղաձիգով) պարզվում է որ այնքան էլ պարզ չէ նկարագրել
  ալգորիթմորեն: Երբ փորձ է կատարվում նպանատիպ կանոնները հստակեցնել, միանգամից խճճվում ենք բացառությունների
  կամ հատուկ դեպքերի կծիկի մեջ: Խնդիրը լուծելը արագորեն դառնում է անհույս:
</p>

<p></p>

<p>
  Նեյրոնային ցանցերը խնդրին մոտենում են այլ կերպ: Միտքը կայանում է նրանում, որ
  պետք է վերցնել մեծ քանակությամբ ձեռագիր թվանշաններ, որոնց անվանենք ուսուցման օրինակներ,
</p>

<p>
  <center><img src="images/mnist_100_digits.png" width="440px"></center>
</p>

<p>
  և կառուցել համակարգ որը կարող է սովորել այդ օրինակներից: Այլ կերպ ասած, նեյրոնային
  ցանցը օգտագործում է օրինակները ձեռագիր թվանշանների կառուցվածքն ինքնաբերաբար
  հասկանալու համար: Ավելին, շատացնելով օրինակների քանակը, ցանցը կարող է ավելի շատ
  սովորել ձեռագրերի մասին, այսպիսով բարելավելով ճշգրտությունը: Օրինակ, ցանցը ավելի ճշգրիտ
  կարող է գուշակել սովորելով 1000 օրինակի վրա քան 100 օրինակի:
</p>

<p>
  Այս գլխում կկառուցենք համակարգչային ծրագիր, որը իրականացնում է նեյրոնային ցանց,
  որը իր հերթին սովորում է ճանաչել ձեռագիր թվանշաններ: Ծրագիրը ունի 74 տող երկարություն
  և չի օգտագործում ոչ մի նեյրոնային ցանցերի գրադարան: Սակայն այն կարող է թվանշանները
  ճանաչել 96 տոկոս ճշտությամբ առանց մարդկային միջամտության: Այնուհետև հետագա
  գլուխներում կկառուցենք գաղափարներ, որոնք կօգնեն ճանաչման ճշտությունը հասցնել
  99 տոկոսից ավելի: Փաստացիորեն, լավագույն կոմերցիոն նեյրոնային ցանցերն այնքան
  հուսալի են, որ օգտագործվում են բանկերի կողմից չեկերի մշակման համար, փոստատների
  կողմից հասցեների ճանաչման համար:
</p>

<p>
  Մենք կենտրոնանում ենք ձեռագիր թվանշանների ճանաչման վրա, քանի որ այն ընդհանուր
  առմամբ գերազանց նախատիպային խնդիր է նեյրոնային ցանցերի մասին սովորելու համար:
  Որպես նախատիպային խնդիր ըստ երևույթին այն հեշտ չէ, սակայն այնքան բարդ չէ որ կարիք զգացվի
  չափազանց բարդ լուծման տեխնիկաների կամ համակարգչային հզորության (computational power) օգտագործման:
  Հետևաբար սա հրաշալի մոտեցում է ավելի առաջադեմ տեխնիկաների հմտություններ յուրացնելու համար, օրինակ խորը
  ուսուցումը: Այսպիսով, գրքում պարբերաբար վերադառնալու ենք ձեռագիր թվանշանների
  ճանաչման խնդրին: Ավելի ուշ նաև կքննարկենք թե ինչպես կարելի է օգտագործել այս
  գաղափարները այլ խնդիրների լուծման համար, օրինակ` համակարգչային տեսողության (computer vision),
  բնական լեզվի ճանաչում (speech, natural language processing) և այլն:
</p>

<p>
  Իհարկե, եթե այս գլխի նպատակը լիներ միայն կառուցել ծրագիր, որը ճանաչում է ձեռագիր թվանշանները,
  ապա գլուխը կարճ կլիներ: Մենք խոսելու ենք նաև նեյրոնային ցանցերի մասին այլ կարեևոր գաղափարներից,
  հատկապես երկու կարևոր արհեստական նեյրոնի տեսակների մասին (պերսեպտրոն և սիգմոիդ նեյրոն) և նեյրոնային
  ցանցերի ստանդարտ ուսուցման ալգորիթմի մասին, որը հայտնի ե որպես ստոկաստիկ գրադիենտային իջեցում (stochastic
  gradient descent): Ավելի խորը հասկանալու համար առկան են քննարկումներ թե ինչպես կարելի է կառուցել ինտուցիա
  և կարողանալ հասկանալ թե որ մասը ինչպես է մտածված և կառուցված նեյրոնային ցանցերում և դրանծ ուսուցման մեջ:
</p>

<p>
  <h3><a name="perceptrons"></a><a href="#perceptrons">Պերսեպտրոններ</a></h3>
</p>

<p>Ի՞նչ է նեյրոնային ցանցը: Սկզբում կներկայացնեմ արհեստական նեյրոնի մի տարատեսակ, որ կոչվում է <em>պերսեպտրոն</em>:
Պերսեպտրոնները <a href="http://books.google.ca/books/about/Principles_of_neurodynamics.html?id=7FhRAAAAMAAJ">ստեղծվել են</a> 1950-1960-ականներին <a href="http://en.wikipedia.org/wiki/Frank_Rosenblatt">Ֆրանկ Ռոզեսբլատի կողմից</a>, ոգեշնչված <a href="http://en.wikipedia.org/wiki/Warren_McCulloch">Ուորեն ՄակԿուլոքի</a> և <a href="http://en.wikipedia.org/wiki/Walter_Pitts">Վալտեր Փիթսի</a> ավելի վաղ կատարված <a href="http://scholar.google.ca/scholar?cluster=4035975255085082870">աշխատանքով</a>: Այսօր ավելի հաճախ օգտագործում են արհեստական նեյրոնների այլ մոդելներ․ այս գրքում և նեյրոնային ցանցերի վերաբերյալ ժամանակակից աշխատանքների մեծամասնության մեջ օգտագործվող նեյրոնների հիմնական մոդելը կոչվում է <em>սիգմոիդ նեյրոն</em>: Մենք շուտով կանդրադառնանք սիգմոիդ նեյրոններին: Բայց որպեսզի հասկանանք, թե ինչու են սիգմոիդ նեյրոնները սահմանվում այնպես, ինչպես սահմանվում են, արժե նախ ժամանակ ծախսել պերսեպտրոնները հասկանալու համար:</p><p>Ինչպե՞ս են աշխատում պերսեպտրոնները:  Պերսեպտրոնը մուտքում ստանում է մի քանի երկուական արժեքներ,
$x_1, x_2, \ldots$, և ելքում ստանում է մեկ երկուական արժեք (որպես ելք նշանակենք output, այսուհետ այս երկու տերմինները կօգտագործվեն փոխարինաբար)․
<center>
<img src="images/tikz0.png"/>
</center>
Այս օրինակում պերսեպտրոնը ունի երեք մուտքեր, $x_1, x_2, x_3$:
Ընդհանուր դեպքում այն կարող է ունենալ ավելի շատ կամ ավելի քիչ մուտքեր: Ռոզենբլատը առաջարկել է ելքում ստացվող արժեքը հաշվարկելու պարզ կանոն: Նա ներմուծեց <em>կշիռներ</em>, $w_1,w_2,\ldots$, իրական թվեր, որոնք արտահայտում են համապատասխան մուտքերի կարևորությունը ելքի համար: Նեյրոնի ելքը, $0$ կամ $1$, որոշվում է կախված այն բանից, թե $\sum_j w_j x_j$ կշռված գումարը փոքր է, թե մեծ է որոշակի <em>շեմային արժեքից</em>: Շեմը, ինչպես կշիռները, իրական թիվ է, որը հանդիսանում է նեյրոնի պարամետր:  Ավելի ճշգրիտ հանրահաշվական տերմիններով`
<a class="displaced_anchor" name="eqtn1"></a>\begin{eqnarray}
\mbox{ելք} & = & \left\{ \begin{array}{ll}
0 & \mbox{if } \sum_j w_j x_j \leq \mbox{ շեմ} \\
1 & \mbox{if } \sum_j w_j x_j > \mbox{ շեմ}
\end{array} \right.
\tag{1}\end{eqnarray}

Այսքանն է պերսեպտրոնի աշխատանքի նկարագրությունը:</p>

<p>Սա պարզագույն մաթեմատիկական մոդելն է: Դուք կարող եք պերսեպտրոնը հասկանալ որպես մի սարք, որը փաստերը կշռելով կայացնում է որոշումներ: Քննարկենք մի օրինակ: Օրինակը այնքան էլ իրատեսական չէ, սակայն հեշտ է հասկանալը, և մենք շուտով կդիտարկենք ավելի իրատեսական օրինակներ: Ենթադրենք մոտենում են հանգստյան օրերը և դուք լսել եք, որ ձեր քաղաքում պանրի փառատոն է կայանալու: Դուք պանիր սիրում եք և ուզում եք որոշել արդյոք արժի գնալ փառատոնին: Դուք կայացնում եք որոշում հիմնվելով երեք գործոնների վրա․

<ol>
  <li> Եղանակը լա՞վն է,
  <li> Ձեր ընկերը կամ ընկերուհին ցանկություն ունե՞ն միանալ ձեզ,
  <li> Փառատոնին հնարավո՞ր է մոտենալ հասարակական տրանսպորտով (դուք չունեք ավտոմեքենա):
</ol>

Մենք կարող ենք այս երեք գործոնները ներկայացնել երկուական փոփոխականներով՝
$x_1, x_2$ և $x_3$: Օրինակ, եթե եղանակը լավն է, ապա ունենք $x_1 = 1$, իսկ եթե եղանակը բարենպաստ չէ, ապա $x_1 = 0$: Նմանապես, $x_2 = 1$ եթե ձեր ընկերը կամ ընկերուհին ցանկություն ունեն գնալու, և $x_2 = 0$ հակառակ դեպքում: Եվ նորից նման ձևով $x_3$-ը հասարակական տրանսպորտի հետ կապված:
</p>

<p>Այժմ ենթադրենք որ դուք շատ եք սիրում պանիր, այնքան շատ, որ պարաստ եք գնալ փառատոնին նույնիսկ եթե ձեր ընկերը կամ ընկերուհին հետաքրքրված չեն և փառատոնին հասնելը դժվար է: Բայց գուցե դուք տանել չեք կարողանում վատ եղանակը և հաստատ չեք մասնակցի փառատոնին, եթե եղանակը անբարենպաստ եղավ: Այս բնույթի որոշման կայացումը մոդելավորելու համար կարող եք օգտագործել պերսեպտրոն: Օրինակ, կարելի է եղանակի համար կշիռը վերցնել $w_1 = 6$, իսկ մյուս պայմանների համար՝ $w_2 = 2$ և $w_3 = 2$: $w_1$-ի մեծ արժեքը ցույց է տալիս, որ եղանակը շատ կարևոր է ձեզ համար, շատ ավելի կարևոր է, քան արդյոք ձեր ընկերը կամ ընկերուհին կմիանան ձեզ, կամ հասարակական տրանսպորտի հարմարությունը: Վերջապես, ենթադրենք պերսեպտրոնի շեմը դուք ընտրում եք հավասար 5-ի: Այսպիսի ընտրության դեպքում պերսեպտրոնը իրականացնում է մեր ցանկացած որոշում կայացնող մոդելը, ելքում տալով 1, եթե եղանակը լավն է, և 0, եթե եղանակը բարենպաստ չէ: Ելքի վրա ընդհանրապես չեն ազդի ձեր ընկերոջ կամ ընկերուհու մասնակցելու ցանկությունը կամ հասարակական տրանսպորտի հարմարությունը:</p>

<p>Կշիռները և շեմը փոփոխելով մենք կստանանք որոշման կայացման տարբեր մոդելներ: Օրինակ, որպես շեմ ընտրենք $3$: Այդ դեպքում պերսեպտրոնը կորոշի որ դուք փառատոնին գնաք այն ժամանակ երբ եղանակը բարենպաստ է <em>կամ</em> երբ փառատոնը մոտ է հասարակական տրանսպորտին <em>և</em> ձեր ընկերը կամ ընկերուհին պատրաստ են միանալ ձեզ: Մի խոսքով դա կդառնա որոշում կայացնելու ուրիշ մոդել: Շեմն իջեցնելը նշանակում է որ դուք հակված եք փառատոնին մասնակցելուն:</p>

<p>Պարզ է որ պերսեպտրոնը մարդկային որոշում կայացնելու ամբողջական մոդել չէ: Սակայն օրինակը ցույց տվեց թե ինչպես այն կարող է համեմատել տարատեսակ գործոնները որոշում կայացնելու նպատակով: Ավելին, կարծես իրականալի է թվում այն որ պերսեպտրոնների բարդ կառուցվածքը կարող է անգամ իրականացնել ոչ պարզ որոշումներ:
<center>
  <img src="images/tikz1.png"/>
</center>
Հետևյալ ցանցում պերսեպտրոնների առաջին սյունակը, որին կանվանենք պերսեպտրոնների առաջին <em>շերտ</em>, իրականացնում է 3 պարզ որոշումներ` համեմատելով տրված գործոնները: Իսկ ի՞նչ կարելի է ասել 2-րդ շերտի պերսեպտրոնների մասին: Այդ պերսեպտրոններից յուդաքանչյուրը որոշում է կայացնում համեմատելով առաջին շերտի կայացրած որոշումների արդյունքները: Այդ կերպ երկրորդ շերտի պերսեպտրոնը կարող է կայացնել ավելի բարդ և աբստրակտ մակարդակի որոշում քան առաջին շերտի պերսեպտրոնները: Երրորդ շերտի պերսեպտրոնները կարող են կայացնել անգամ ավելի բարդ որոշումներ: Այս ձևով բազմաշերտ պերսեպտրոնների ցանցը կարող է կայացնել բավականին բարդ որոշումներ:</p>

<p>
  Ի դեպ, պերսեպտրոնի սահմանման մեջ ես նշել էի, որ նրաք ունեն մեկ
  ելքային արժեք: Տպավորություն կարող է ստեղծվել, որ վերևում նկարված ցանցում պերսեպտրոններն
  ունեն մեկից ավել ելքեր: Սակայն դա այդպես չէ, քանի որ մեկից ավել նկարված ելքային սլաքներն ուղղակի
  նշանակում են, որ տվյալ պերսեպտրոնի ելքը հանդիսանում է մուտք բազմաթիվ այլ պերսեպտրոնների:
  Այսպիսի նշանակումն ավելի հարմար է դարձնում ցանց նկարելն ու պատկերացնելը:
</p>

<p>
  Պարզեցնենք պերսեպտրոնի նկարագրությունը: $\sum_j w_j x_j > \mbox{շեմ}$ պայմանը
  կարելի է պարզեցնել երկու փոփոխություններով: Առաջին փոփոխությունն է` գրենք $\sum_j w_j x_j$ գումարը որպես
  $w \cdot x \equiv \sum_j w_j x_j$ սկալյար արտադրյալ, որտեղ $w$-ն կշիռների վեկտորն է,
  $x$-ը` մուտքային: Երկրորդ փոփոխությունն է` տանել ելքը անհավասարման մյուս մասը և վերանվանել այն
  որպես պերսեպտրոնի <em>շեղում</em>` $b \equiv -\mbox{շեմ}$: Օգտագործելով շեղումը շեմի փոխարեն,
  պերսեպտրոնը կգրենք.

  <a class="displaced_anchor" name="eqtn2"></a>
  \begin{eqnarray}
    \mbox{ելք} = \left\{
      \begin{array}{ll}
        0 & \mbox{if } w\cdot x + b \leq 0 \\
        1 & \mbox{if } w\cdot x + b > 0
      \end{array}
    \right.
  \tag{2}\end{eqnarray}

  Շեղումը կարելի է ընկալել որպես մի մեծություն, որը ցույց է տալիս, թե ինչքան հեշտությամբ կարելի է այնպես անել,
  որ պերսեպտրոնը ելքում ստանա $1$ արժեքը կամ կենսաբանական տերմիններով ասած, շեղումը ցույց է
  տալիս թե որքան հեշտությամբ կարելի ա այնպես անել, որ պերսեպտրոնը <em>հրահանգի(fire - ԿՏ)</em>:
  Մեծ շեղումով պերսեպտրոններն ավելի դյուրին է ելքում $1$ ստանում համեմատած փոքր շեղումների, որոնց դեպքում
  շեղման փոքրանալով, պերսեպտրոնի $1$ ելքային արժեք ունենալը դժվարանում է: Պարզ է, որ շեղումը չնչին
  փոփոխություն է պերսեպտրոնների նկարագրության մեջ, սակայն ավելի ուշ կհամոզվենք որ դա կբերի էական պարզեցումների:
  Այդ իսկ պատճառով, այսուհետ կօգտագործենք շեղում տերմինը շեմի փոխարեն:
</p>


<p>
  Ես նկարագրել եմ պերսեպտրոնները որպես վկայությունների կշռման մեթոդ, որի միջոցով
  կարելի է կատարել որոշումներ: Պերսեպտրոնի կարելի է օգտագործել
  պարզագույն հաշվողական այնպիսի միավորների կառուցման համար, ինչպիսիք են <CODE>AND</CODE>, <CODE>OR</CODE>
  և <CODE>NAND</CODE> գործողությունները: Օրինակ, ենթադրենք, որ ունենք պերսեպտրոն երկու
  մուտքերով, ամենքի արժեքը` $-2$, իսկ շեղումը $3$ է: Ահա մեր պերսեպրտոնը.
  <center>
    <img src="images/tikz2.png"/>
  </center>
  Հեշտ է նկատել, որ $00$ մուտքից ստացվում է $1$ ելք, քանի որ $(-2)*0+(-2)*0+3 = 3$
  դրական է: $*$ սիմվոլի օգտագործումը նախատեսված է բազմապատկումն ավելի ակնառու դարձնելու համար:
  Նույն ձևով հեշտ է համոզվել, որ $01$ և $10$ մուտքերի դեպքում արժեքը $1$ է: Սակայն
  $11$ մուտքի դեպքում արժեքը $0$ է, քանի որ $(-2)*1+(-2)*1+3 = -1$ բացասական է: Այսպիսով,
  նկատենք, որ մեր պերսեպտրոնը իրականացնում է <CODE>NAND</CODE> գործողությունը:
</p>

<p>
<a name="universality"></a>
</p>

<p>
  <CODE>NAND</CODE>-ի օրինակը ցույց է տալիս, որ կարող ենք հասշվել պարզ տրամաբանական
  ֆունկցիաներ: Իրականում պերսեպտրոնների ցանցի միջոցով կարելի է հաշվել <em>կամայական</em> տրամաբանական
  ֆունկցիա, քանի որ <CODE>NAND</CODE>-ը ունիվերսալ հաշվողական միավոր է, որով կարելի է կառուցել մնացած
  գործողությունները: Օրինակ, <CODE>NAND</CODE>-ը կարող ենք օգտագործել գումարման սխեմա կառուցելու համար,
  որը գումարում է $x_1$ և $x_2$ բիթերը: Սա նշանակում է հաշվել $x_1 \oplus x_2$ բիթ առ բիթ գումարումը և
  մնացորդային բիթը, որը $1$ է, երբ $x_1$ և $x_2$ բիթերը $1$ են, 0 մնացած դեպքերում:

  <center>
   <img src="images/tikz3.png"/>
  </center>

  Համարժեք պերսեպտրոնների ցանց ստանալու համար, բոլոր <CODE>NAND</CODE>-երը
  փոխարինենք երկումուտքանի պերսեպտրոններով, յուրաքանչյուրը $-2$ կշռով և $3$ շեղումով:
  Ահա թե ինչ ցանց է ստացվում: Նկատենք, որ աջ ներքևի <CODE>NAND</CODE> գործողությանը
  համապատասխանող գագաթը տեղաշարժված է նկարելն ավելի հեշտացնելու նպատակով:

  <center>
    <img src="images/tikz4.png"/>
  </center>

  Նկատենք, որ ամենաձախում գտնվող պերսեպտրոնի ելքերը հանդիսանում են մուտքեր
  ամենաներքևում գտնվող պերսեպտրոնի համար: Պերսեպտրոնի սահմանման մեջ նշված չէր,
  որ այսպիսի նկարագրություն թույլատրելի է, սակայն դա ոչ մի նշանակություն չունի: Եթե
  որոշում ենք թույլ չտալ նմանատիպ նշանակումներ, ապա կարող ենք միացնել երկու գծերը
  և դարձնել այն մեկ կապ -4 կշռով երկու -2 կշռով կապերի փոխարեն: (Եթե այս մասը ակնհայտ չեք
  համարում, ապա խորհուրդ եմ տալիս կանգ առնել և համոզվել որ սա էկվիվալենտ է): Այդ
  փոփոխությունից հետո ցանցի տեսքը կլինի այսպիսի (բոլոր չնշված կշիռները -2, բոլոր շեղումները
  3 և վերոնշյալ կապը -4 կշռով, ինչպես նշված է)

  <center>
   <img src="images/tikz5.png"/>
  </center>

  Նպատակահարմար է նաև վերցնել $x_1$ և $x_2$ մուտքային արժեքները որպես մուտքային պերսեպտրոնների
  <em>շերտ</em>.

  <center>
   <img src="images/tikz6.png"/>
  </center>

  Օգտագործենք հետևյալ նշանակումն այն պերսեպտրոնների համար, ովքեր ունեն ելք բայց
  չունեն մուտք.

  <center>
    <img src="images/tikz7.png"/>
  </center>
</p>

<p>
  Գումարման գործողության իրականացումը ցույց է տալիս, թե ինչպես կարելի է օգտագործել
  պերսեպտրոնները բազմաթիվ <CODE>NAND</CODE> գործողություններ պարունակող սխեմա
  սիմուլացնել: Եվ քանի որ <CODE>NAND</CODE>-երը ունիվերսալ հաշվարկային () միավորներ են,
  ապա հետևում է, որ նույնը ճիշտ է նաև պերսեպտրոնների համար:
</p>

<p>
  Պերսեպտրոնների ունիվրսալ հաշվողունակությունը միժամանակ և՛ հուսադրող է, և՛ հիասթափեցնող:
  Այն հուսադրող է, քանի որ այն ցույց է տալիս, որ պերսեպտրոնների ցանցը կարող է կամայակն այլ
  հաշվողական սարքին հավասար հզոր լինել: Սակայն դա նույնքան հիասթափեցնող է, քանի որ մյուս
  կողմից էլ ստացվում է, որ պերսեպտրոնները պարզապես <CODE>NAND</CODE>-ի նոր տեսակ են: Դա
  այդքան էլ մեծ նորություն չէ:
</p>

<p>
  Այնուամենայնիվ, իրավիճակը շատ ավելի բարվոք է: Պարզվում է, որ հնարավոր է դուրս բերել
  <em>սովորող ալգորիթմներ</em>, որը ինքնաբերաբար կարող է ձևափոխել արհեստական նեյրոնների
  կշիռներն ու շեղումները: Այսպիսի ձևափոխումը տեղի է ունենում ի պատասխան արտաքին գործոնների,
  այլ ոչ ծրագրավորողի: Սովորող ալգորիթմները թույլ են տալիս մեզ արհեստական նեյրոնները օգտագործել
  էապես տարբեր ձևով, համեմատած արդեն ընդունված տրամաբանական գործողությունների: Ուղղակիորեն
  <CODE>NAND</CODE> գործողությունների հերթականություն մշակելու փոխարեն, նեյրոնային ցանցը պարզապես
  սովորում է լուծել խնդիրներ, երբեմն խնդիրներ, որոնց լուծելու համար ավանդական սխեմա կառուցելը շատ
  բարդ կլիներ:
</p>

<p>
  <h3>
    <a name="sigmoid_neurons"></a>
    <a href="#sigmoid_neurons">Սիգմոիդ Նեյրոններ</a>
  </h3>
</p>

<p>
  Սովորող ալգորիթմները հրաշալի է հնչում: Բայց ինչպե՞ս կարող ենք դուրս
  բերել նմանատիպ ալգորիթմներ նեյրոնային ցանցերի համար: Ենթադրենք պերսեպտրոնների
  ցանց ունենք, որը կուզենայինք օգտագործել որոշակի խնդիր լուծելու նպատակով: Օրինակ,
  որպես մուտքային տվյալներ կարող են հանդիսանալ ձեռագիր թվանշանի թվային նկարի պիքսելները:
  Եվ մենք կնախընտրեինք, որ ցանցը սովորեր կշիռներն ու շեղումները այնպես, որ ցանցի ելքում
  կստանայինք թվանշանների դասակարգումը: Որպեսզի հասկանանք, թե ինչպես ուսուցումը կարող է
  աշխատել, ենթադրենք ցանցում` կշռի կամ շեղման մեջ կատարել ենք փոքրիկ փոփոխություն:
  Մեզ համար նախընտրելի արդյունքը կլիներ տեսնել, որ այդ փոքր փոփոխությունը առաջացներ
  փոկր փոփոխություն ցանցի ելքում: Ինչպես շուտով կհամոզվենք, այս հատկությունը ուսուցումը
  հնարավոր է դարձնում: Սխեմատիկորեն սա այն է, ինչ մեզ պետք է (ակնհայտ է, որ այս ցանցը
  չափազանց պարզ է ձեռագիր թվանշաններ ճանաչելու համար).
</p>

<p>
  <center>
    <img src="images/tikz8.png"/>
  </center>
</p>

<p>
  Եթե կշռի կամ շեղման փոքր փոփոխության հետևանքով առաջանար փոքր փոփոխություն
  ելքում, ապա մենք կկարողանայինք օգտագործել այդ փաստը կշիռներն ու շեղումները
  փոփոխելու համար այնպես, որ ցանցը ստանաս մեզ համար ցանկալի վարքագիծ: Օրինակ,
  ենթադրենք ցանցը սխալմամբ "9" թվանշանը ճանաչում է որպես "8": Մենք կարող ենք
  գտնել մի այնպիսի փոփոխություն շեղման և կշիռների համար, որ ցանցը փոքր ինչ ավելի
  մոտենա թվանշանը որպես "9" ճանաչելուն: Այնուհետև կարող ենք կրկնել այս քայլը այնքան
  մինչև ստանանք ավելի և ավելի լավ ելքեր: Ցանցը կասենք, որ սովորում է
</p>

<p>
  Խնդիրը կայանում է նրանում, որ սա այն չէ ինչ պատահում է պերսեպտրոնների դեպքում:
  Իրականում երբեմն մեկ պերսեպտրոնի կշիռների և շեղման չնչին փոփոխությունը կարող է
  հանգեցնել ելքի կտրուկ փոփոխության, օրինակ $0$-ից $1$: Այս փոփոխությունը կարող է
  հանգեցնել ցանցի մնացած հատվածներում բավականին կոմպլեքս փոփոխություններ: Այսպիսով,
  անգամ եթե 9-ը ճանաչվի ճիշտ, վարքագիծը այլ մուտքերի դեպքում կարող է անկառավարելիորեն
  փոխվել: Սա կշիռների և շեղման փոքրիկ փոփոխությամբ ցանցի վարքագիծը փոխելու հետևանքով
  նպատակին մոտենալը դարձնում է դժվարին: Կարող է պատահի այս խնդիրը շրջանցելու
  խելացի միջոց գոյություն ունի, սակայն միանգամից ակնհայտ չէ, թե ինչպես կարող ենք սովորեցնել
  պերսեպտրոնների ցանցին:
</p>

<p>
  Մենք կարող ենք շրջանցել այս խնդիրը ներմուծելով նոր տեսակի արհեստական նեյրոն,
  որը կոչվում է <em>սիգմոիդ</em> նեյրոն: Սիգմոիդ նեյրոնները նման են պերսոտրոններին,
  սակայն փոփոխված են այնպես, որ կշռի կամ շեղման փոքր փոփոխություններիը առաջացնում են
  փոքր փոփոխություններ ելքում: Սա է այն պայմանը, որի դեպքում սիգմոիդ նեյրոնների ցանցը կկարողանա
  սովորել:
</p>

<p>
  Նկարագրենք սիգմոիդ նեյրոնը: Կնկարենք այն այնպես ինչպես նկարել էինք պերսեպտրոնը.
  <center>
    <img src="images/tikz9.png"/>
  </center>
  Պերսեպտրոնի նման, սիգմոիդն ունի $x_1, x_2, \ldots$. մուտքեր: Սակայն $0$ կամ $1$-ի
  փոխարեն նրանք կարող են ընդունել կամայական արժեք $0$-ի և $1$-ի միջև: Օրինակ, $0.638\ldots$-ը
  ընդունելի աժեք է մուտքի համար: Ինչպես պերսեպտրոնը, սիգմոիդ նեյրոններն ունեն կշիռներ $w_1, w_2, \ldots$
  և շեղում $b$: Սակայն ելքը $0$ կամ $1$-ի փոխարեն $\sigma(w \cdot x+b)$ է, որտեղ $\sigma$ ֆունկցիան կոչվում է
  <em>սիգմոիդ</em>*
    <span class="marginnote">
      *Ի դեպ, $\sigma$-ն երբեմն կոչվում է <em>լոգիստիկ ֆունկցիա(logistic function)</em>, և հետևաբար,
      նեյրոնների այս նոր տիպը` <em>լոգիստիկ նեյրոններ(logistic neurons)</em>: Հետևյալ տերմինները նույնպես
      հաճախ օգտագործվող են, հետևաբար արժե տեղյակ լինել, սակայն այս գրքում մենք կօգտագործենք սիգմոիդ անվանումը:
    </span>:
  և սահմանվում է.

  <a class="displaced_anchor" name="eqtn3"></a>
  \begin{eqnarray}
    \sigma(z) \equiv \frac{1}{1+e^{-z}}.
    \tag{3}
  \end{eqnarray}

  Այսպիսով, սիգմոիդ նեյրոնի ելքը $x_1,x_2,\ldots$ մուտքերի, $w_1,w_2,\ldots$ կշիռների
  և $b$ շեղման դեպքում.

  <a class="displaced_anchor" name="eqtn4"></a>
  \begin{eqnarray}
    \frac{1}{1+\exp(-\sum_j w_j x_j-b)}.
    \tag{4}
  \end{eqnarray}
</p>

<p>
  Առաջին հայացքից սիգմոիդ նեյրոնները կարող են պերսեպտրոններից տարբեր թվալ:
  Սիգմոիդի տեսքը կարող է ոչ ակնհայտ լինել ետե ծանոթ չեք ֆունկցիայի հետ: Իրականում
  պերսեպտրոնների և սիգմոիդ նեյրոնների միջև կան բազմաթիվ նմանություններ:
</p>

<p>
  Որպեսզի հասկանանք այդ նմանությունները, ենթադրենք $z$-ը մեծ դրական թիվ է ներկայացված հետևյալ տեսքով`
  $z \equiv w \cdot x + b$: Հետևաբար, $e^{-z} \approx 0$ և $\sigma(z) \approx 1$:
  Այլ կերպ ասած, $z = w \cdot x+b$ մեծ և դրական է, սիգմոիդ նեյրոնի արժեքը մոտավորապես $1$ է
  (այնպես, ինչպես կլիներ պերսեպտրոնի համար): Մյուս կողմից ենթադրենք, որ $z = w \cdot x+b$ շատ փոքր
  բացասական թիվ է, ապա $e^{-z} \rightarrow \infty$ և $\sigma(z) \approx 0$, հետևաբար, եթե
  $z = w \cdot x +b$ շատ փոքր բացասական թիվ է, ապա սիգմոիդի արժեքը ձգտում է պերսեպտրոնի արժեքին:
  Միայն $w \cdot x+b$-ի ոչ մեծ բացարձակ արժեքների դեպքում է, որ սիգմոիդի ու պերսեպտրոնի մոդելները տարբերվում են:
</p>

<p>
  Իսկ ի՞նչ տեսք ունի $\sigma$-ն: Ինչպե՞ս հասկանանք այն: Իրականում $\sigma$-ի ճշգրիտ արժեքն էական չէ, էական է
  այն, թե ինչ տեսք ունի ֆունկցիայի գրաֆիկը: Ահա այն.
</p>

<p>
  <div id="sigmoid_graph"><a name="sigmoid_graph"></a></div>
  <script src="https://d3js.org/d3.v3.min.js"></script>
  <script>
    function s(x) {return 1/(1+Math.exp(-x));}
    var m = [40, 120, 50, 120];
    var height = 290 - m[0] - m[2];
    var width = 600 - m[1] - m[3];
    var xmin = -5;
    var xmax = 5;
    var sample = 400;
    var x1 = d3.scale.linear().domain([0, sample]).range([xmin, xmax]);
    var data = d3.range(sample).map(function(d){ return {
            x: x1(d),
            y: s(x1(d))};
        });
    var x = d3.scale.linear().domain([xmin, xmax]).range([0, width]);
    var y = d3.scale.linear()
                    .domain([0, 1])
                    .range([height, 0]);
    var line = d3.svg.line()
        .x(function(d) { return x(d.x); })
        .y(function(d) { return y(d.y); })
    var graph = d3.select("#sigmoid_graph")
        .append("svg")
        .attr("width", width + m[1] + m[3])
        .attr("height", height + m[0] + m[2])
        .append("g")
        .attr("transform", "translate(" + m[3] + "," + m[0] + ")");
    var xAxis = d3.svg.axis()
                      .scale(x)
                      .tickValues(d3.range(-4, 5, 1))
                      .orient("bottom")
    graph.append("g")
        .attr("class", "x axis")
        .attr("transform", "translate(0, " + height + ")")
        .call(xAxis);
    var yAxis = d3.svg.axis()
                      .scale(y)
                      .tickValues(d3.range(0, 1.01, 0.2))
                      .orient("left")
                      .ticks(5)
    graph.append("g")
        .attr("class", "y axis")
        .call(yAxis);
    graph.append("path").attr("d", line(data));
    graph.append("text")
         .attr("class", "x label")
         .attr("text-anchor", "end")
         .attr("x", width/2)
         .attr("y", height+35)
         .text("z");
    graph.append("text")
            .attr("x", (width / 2))
            .attr("y", -10)
            .attr("text-anchor", "middle")
            .style("font-size", "16px")
            .text("sigmoid function");
  </script>
</p>

<p>
  Սա քայլ ֆունկցիայի (step function) "հարթեցված" տարբերակն է:
</p>

<p>
  <div id="step_graph"></div>
  <script>
  function s(x) {return x < 0 ? 0 : 1;}
  var m = [40, 120, 50, 120];
  var height = 290 - m[0] - m[2];
  var width = 600 - m[1] - m[3];
  var xmin = -5;
  var xmax = 5;
  var sample = 400;
  var x1 = d3.scale.linear().domain([0, sample]).range([xmin, xmax]);
  var data = d3.range(sample).map(function(d){ return {
          x: x1(d),
          y: s(x1(d))};
      });
  var x = d3.scale.linear().domain([xmin, xmax]).range([0, width]);
  var y = d3.scale.linear()
                  .domain([0,1])
                  .range([height, 0]);
  var line = d3.svg.line()
      .x(function(d) { return x(d.x); })
      .y(function(d) { return y(d.y); })
  var graph = d3.select("#step_graph")
      .append("svg")
      .attr("width", width + m[1] + m[3])
      .attr("height", height + m[0] + m[2])
      .append("g")
      .attr("transform", "translate(" + m[3] + "," + m[0] + ")");
  var xAxis = d3.svg.axis()
                    .scale(x)
                    .tickValues(d3.range(-4, 5, 1))
                    .orient("bottom")
  graph.append("g")
      .attr("class", "x axis")
      .attr("transform", "translate(0, " + height + ")")
      .call(xAxis);
  var yAxis = d3.svg.axis()
                    .scale(y)
                    .tickValues(d3.range(0, 1.01, 0.2))
                    .orient("left")
                    .ticks(5)
  graph.append("g")
      .attr("class", "y axis")
      .call(yAxis);
  graph.append("path").attr("d", line(data));
  graph.append("text")
       .attr("class", "x label")
       .attr("text-anchor", "end")
       .attr("x", width/2)
       .attr("y", height+35)
       .text("z");
  graph.append("text")
          .attr("x", (width / 2))
          .attr("y", -10)
          .attr("text-anchor", "middle")
          .style("font-size", "16px")
          .text("step function");
  </script>
</p>

<p>
  Եթե $\sigma$-ն լիներ քայլ ֆունկցիան, ապա սիգմոիդ նեյրոնը կլիներ պերսեպտրոնը,
  քանի որ ելքում կստացվեին $1$ կամ $0$ արժեքները կախված նրանից, թե $w\cdot x+b$
  դրական է, թե բացասական*:

  <span class="marginnote">
    *Իրականում, $w \cdot x +b = 0$ պերսեպտրոնի արժեքը $0$ է, երբ քայլ ֆունկցիայի
    արժեքը $1$ է: Այսպիսով, ճշգրիտության համար նշեմ, որ կարիք կլինի փոխել քայլ ֆունկցիայի
    արժեքը այդ կետում: Սակայն պարզ է ընդհանուր գաղափարը:
  </span>

  Օգտագործելով $\sigma$ ֆունկցիան, մենք ստանում ենք պերսեպտրոնի փոքր-ինչ հարթեցված
  տարբերակը, ինչը ամենակարևորն է, քանի որ դա նշանակում է՝ որ կշռի $\Delta w_j$ և շեղման
  $\Delta b$ փոքր փոփոխությունների արդյունքում վերջնական արժեքի փոփոխությունը $\Delta \mbox{output}$
  կլինի նույնպես փոքր: Ըստ էության, $\Delta \mbox{output}$ կարելի է մոտարկել

  <a class="displaced_anchor" name="eqtn5"></a>
  \begin{eqnarray}
    \Delta \mbox{ելք} \approx \sum_j \frac{\partial \, \mbox{ելք}}{\partial w_j}
    \Delta w_j + \frac{\partial \, \mbox{ելք}}{\partial b} \Delta b,
    \tag{5}
  \end{eqnarray}

  որտեղ գումարն ըստ բոլոր $w_j$ կշիռների է, իսկ $\partial \,
  \mbox{ելք} / \partial w_j$ և $\partial \, \mbox{ելք} /\partial
  b$ $\mbox{ելք}$-ի  մասնակի ածանցյալներն են ըստ $w_j$ և $b$ փոփոխականների
  համապատասխանաբար: Խուճապի մի մատնվեք, եթե հարմարավետ չեն մասնակի ածանցյալները
  ձեզ համար: Կարող է թվալ, որ վերևի արտահայտությունը բարդ է, սակայն այն ուղղակի նշանակում է,
  որ  $\Delta \mbox{ելք}$-ը գծային ֆունկցիա է $\Delta w_j$ և $\Delta b$ կշիռների և շեղման
  փոփոխություններից կախված: Գծայնությունը թույլ է տալիս հեշտությամբ ընտրել փոքր փոփոխություն
  կշիռների և շեղումների համար, որը կհանգեցնի փոքր փոփոխություն ելքում: Այսպիսով, սիգմոիդները
  ունենալով պերսեպտրոններին նման որակական հատկանիշներ, միաժամանակ թույլ են տալիս հեշտությամբ
  հասկանալ, թե ինչպես կազդի կշիռների և շեղման փոփոխությունը նեյրոնի ելքում:
</p>

<p>
  Քանի որ $\sigma$ ֆունկցիայի գրաֆիկի տեսքն է ավելի կարևոր, քան ֆունկցիան ինքնին, ապա ինչու՞
  օգտագոեծենք $\sigma$-ի
  <span id="margin_850263336921_reveal" class="equation_link">(3)</span>
  <span id="margin_850263336921" class="marginequation" style="display: none;">
    <a href="chap1.html#eqtn3" style="padding-bottom: 5px;" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';">
      \begin{eqnarray}
        \sigma(z) \equiv \frac{1}{1+e^{-z}} \nonumber
      \end{eqnarray}
    </a>
  </span>
  <script>
    $('#margin_850263336921_reveal').click(function() {$('#margin_850263336921').toggle('slow', function() {});});
  </script>
  -ում տրված տեսքը: Ըստ էության ավելի ուշ մենք կտեսնենք նեյրոններ, որոնց աեժեքը $f(w \cdot x + b)$ է
  որևիցէ այլ $f(\cdot)$ <em>ակտիվացման ֆունկցիայի</em> դեպքում: Ակտիվացման ֆունկցիայի փոփոխության
  հետևանքով կարող են փոխվել միայն մասնակի ածանցյալների արժեքները

  <span id="margin_444952422305_reveal" class="equation_link">(5)</span>
  <span id="margin_444952422305" class="marginequation" style="display: none;">
    <a href="chap1.html#eqtn5" style="padding-bottom: 5px;" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';">
      \begin{eqnarray}
      \Delta \mbox{ելք} \approx \sum_j \frac{\partial \, \mbox{ելք}}{\partial w_j}
      \Delta w_j + \frac{\partial \, \mbox{ելք}}{\partial b}
      \Delta b \nonumber\end{eqnarray}
    </a>
  </span>
  <script>
    $('#margin_444952422305_reveal').click(function() {$('#margin_444952422305').toggle('slow', function() {});});
  </script>

  հավասարման մեջ: Հեշտ է նկատել նաև, որ վերոնշյալ մասնակի ածանցյալներ հաշվելիս $\sigma$ ֆունկցիան
  կհեշտացնի հաշվելու գործընթացը, քանի որ էքսպոնենցիալ ֆունկցիաները դիֆերենցելիս ունեն հրաշալի հատկություններ:
  Այնուամենայնիվ, $\sigma$-ն բավականին տարածված է նեյրոնային ցանցերում որպես ակտիվացման ֆունկցիա, և մենք
  այն կօգտագործենք բավականին հաճախ այս գրքում:
</p>

<p>
  Իսկ ինչպես պետք է մեկնաբանել սիգմոիդ նեյրոնի ելքը (արժեքը): Հեշտ է նկատել, որ
  պերսեպտրոնին համեմատ, սիգմոիդ նեյրոնի ելքում միայն $0$ կամ $1$ չէ, այլ արժեքներ
  $0$-ից $1$-ի միջև (օրինակ $0.173\ldots$ կամ $0.689\ldots$ և այլն): Այդ հատկությունը
  կարելի է օգտագործել բազմաթիվ ձևերով: Օրինակ, այն կարելի է օգտագործել ելքային արժեքը
  որպես նկարի (որպես մուտք նեյրոնային ցանցին) պիքսելների միջին ինտենսիվություն ներկայացնելու համար:
  Սակայն երբ նպատակը ելքում բինար արժեք ներկայացնելն է (օրինակ մուտքային նկարը "9" է կամ "9" չէ),
  ապա այդ դեպքում կարելի է օգտագործել այլ ստրատեգիա` եթե արժեքը $0.5$-ից փոքր է, ապա "9" է և
  համապատասխանաբար "9" չէ երբ ելքի արժեքը $0.5$-ից փոքր չէ: Նմանատիպ պայմանավորվածությունները
  միշտ հստակ կնշվեն գրքի հետագա քննարկումներում, որպեսզի շփոթություն չառաջանա:
</p>

<p>
  <h4>
    <a name="exercises_191892"></a>
    <a href="#exercises_191892">Վարժություններ</a>
  </h4>
  <ul>
    <li>
    <strong>Պերսեպտրոն սիմուլացնող սիգմոիդ նեյրոններ, մաս I</strong>
    $\mbox{}$ <br/>
    Ենթադրենք պերսեպտրոնների ցանցի բոլոր շեղումները և կշիռները բազմապատկում ենք
    $c > 0$ դրական հաստատունով: Ցույց տվեք, որ ցանցի վարքագիծը դրանից չի փոխվում:
    </p><p>
    <li>
      <strong>Պերսեպտրոն սիմուլացնող սիգմոիդ նեյրոններ, մաս II</strong>
      $\mbox{}$ <br/>
      Դիտարկենք պերսեպտրոնների ցանց: Ենթադրենք ցանցի մուտքն արդեն ընտրված է:
      Մուտքային արժեքը էական չէ, էական է այն, որ այն ֆիքսված է:
      Ենթադրենք կշիռներն ու շեղումները բավարարում են $w \cdot x + b \neq 0$ պայմանին
      $x$ մուտքի և ցանցի կամայական պերսեպտրոնի համար: Այժմ փոխարինենք ցանցի բոլոր պերսեպտրոնները
      սիգմոիդ նեյրոններով և բազմապատկենք կշիռներն ու շեղումները $c > 0$ հաստատունով:
      Ցույց տվեք, որ երբ $c \rightarrow \infty$, ապա սիգմոիդ նեյրոնների ցանցի վարքագիծը
      նույնն է, ինչ պերսեպտրոնների ցանցինը: Ինչպե՞ս վերոնշյալ հատկությունը կարող է տեղի չունենալ
      գոնե մեկ պերսպտրոնի համար, որը չի բավարարում $w \cdot x + b = 0$ պայմանին:
</ul>
</p>

<p>
  <h3>
    <a name="the_architecture_of_neural_networks"></a>
    <a href="#the_architecture_of_neural_networks">
      Նեյրոնային ցանցերի կառուցվածքը
    </a>
  </h3>
</p>


<p>
  Հաջորդ բաժնում կներկայացնենք նեյրոնային ցանց, որը բավականին հաջողությամբ կարողանում է
  դասակարգել ձեռագիր թվանշանները: Որպես նախապատրաստական աշխատանք, նպատակահարմար է
  բացատրել որոշ տերմիններ, որը մեզ թույլ կտա անվանումներ տալ ցանցի բաղադրիչներին: Ենթադրենք, որ
  ունենք որևէ ցանց.
  <center>
    <img src="images/tikz10.png"/>
  </center>
  Հայտնի է արդեն, որ ամենից ձախ գտնվող շերտը կոչվում է մուտքային շերտ, որին պատկանող
  նեյրոնները համապատասխանաբար կոչվում են <em>մուտքային նեյրոններ</em>: Աջակողմյան շետը
  կոչվում է <em>ելքային</em> (վերը նշված դեպքում միակ ելքային նեյրոն): Միջին շերտերը կոչվում են
  <em>թաքնված շերտեր</em>, քանի որ այս շերտի նեյրոնները ոչ մուտքային են, ոչ ելքային: Չնայած նրան,
  որ թաքնված տերմինը միստիկ հնըչողություն ունի, սակայն այն ոչ մի խորը մաթեմատիկական կամ փիլիսոփայական
  նշանակություն չունի, այն պարզապես նշանակում ո՛չ մուտքային, ո՛չ ելքային: Վերևում նկարված ցանցը
  ունի միայն մեկ թաքնված շերտ, սակայն որոշ ցանցեր ունենբազմաթիվ թաքնված շերտեր: Օրինակ, հետևյալ
  չորս շերտանոց ցանցն ունի երկու թաքնված շերտ.
  <center>
    <img src="images/tikz11.png"/>
  </center>
  Նշենք, որ պատմականորեն, այդպիսի բազմաշերտ ցանցերը ինչ-ինչ պատճառով կոչվում են
  <em>բազմաշերտ պերսեպտրոններ</em>` չնայած անյն փաստին, որ իրենք կառուցված են սիգմոիդներից
  այլ ոչ պերսեպտրոններից: Մենք չենք օգտագործի այդպիսի տերմինաբանություն, քանի-որ այն
  շփոթոյթյան մեջ կարող է գցել ընթերցողին:
</p>

<p>
  Մուտքային և ելքային շերտերի կառուցվածքները հիմնականում ակնհայտ են լինում:
  Օրինակ, ենթադրենք ցանկանում ենք պարզել արդյոք ձեռագիր թվանշանը
  ցույց է տալիս "9" թիվը: Ցանցը կառուցելու բնական մեթոդը կլինի նկարի պիքսելների
  խտության արտապատկերումը մուտքային նեյրոններին: Եթե նկարը $64$-ը $64$-ի վրա
  անգույն նկար է, այդ դեպքում կունենանճ $4,096 = 64 \times 64$ մուտքային նեյրոններ,
  որտեղ խտությունները նորմավորված են $0$-ից $1$ միջակայքում: Ելքային շերտը կպարունակի
  միայն մեկ նեյրոն, որի արժեքի $0.5$-ից մեծ լինելը կնշանակի նկարը 9 է, իսկ փոքր լինեու դեպքպւմ` ոչ:
</p>

<p></p><p></p>

<p>
  Մինչդեռ նեյրոնային ցանցի մուտքային և ելքային շերտերի կառուցվածքը հիմնականում ակնհայտ է, սակայն
  թաքնված շերտերի կառուցվածքը կարող է էապես բարդ լինել: Բավականին դժվար է ընդհանուր բնութագրել
  թաքնված շերտերի կառուցման պրոցեսը մի քանի ընդհանուր պնդումներով: Փոխարենը նեյրոնային ցանցեր
  հետազոտողները ստեղծել են բազմաթիվ կառուցվածքներ, մոտեցումներ, որոնք օգնում են ստանալ նպատակային
  արդյունքը` օգտագործելով նեյրոնային ցանցեր: Մենք կհանդիպենք այդպիսի կառուցվածքներից մի քանիսին
  ավելի ուշ գրքում:
</p>

<p>
  Մինչ այժմ մենք քննարկում էինք այնպիսի նեյրոնային ցանցեր, որոնցում մի շերտի ելքն
  օգտագործվում է որպես մուտք հաջորդ շերտի համար: Այդպիսի ցանցերը կոչվում են
  <em>առաջաբեր(feedforward)</em> նեյրոնային ցանցեր: Սա նշանակում է, որ ցանցում
  չկան ցիկլեր. ինֆորմացիան միշտ առաջ է բերվում և ոչ մի դեպքում ետ: Եթե թույլ տայինք ցիկլեր,
  ապա կստացվեր, որ $\sigma$-ի մուտքը կախված կլիներ ելքից, այդ պատճառով մենք թույլ չենք տալիս
  այդպիսի ցիկլեր:
</p>

<p>
  Սակայն գոյություն ունեն այնպիսի նեյրոնային ցանցեր, որոնց մեջ ցիկլերը հնարավոր են:
  Այդպիսի մոդելները կոչվում են <a href="http://en.wikipedia.org/wiki/Recurrent_neural_network">ռեկուրենտ նեյրոնային ցանցեր</a>: Գաղափարը կայանում է նրանում, որ այդպիսի մոդելներում նեյրոնը
  աշխատի ինչ-որ սահմանափակ ժամանակ մինչև պասիվանալը: Այդ աշխատանքը կարող է խթանել
  այլ նեյրոններին, որպեսզի նրանք էլ սկսեն աշխատել ինչ-որ ժամանակ անց ինչ-որ չափավոր ժամանակով:
  Այդ իր հերթին հանգեցնում է նոր նեյրոնների աշխատանքին, այսպիսով հանգեցնելպվ նեյրոններ կասկադային
  աշխատանքին: Ցիկլերն այս դեպքում ոչնչի վրա չեն ազդում, քանի որ նեյրոնի ելքը ազդեցություն ունի
  մուտքի վրա ինչ-որ ժամանակ անց, այլ ոչ անմիջապես:
</p>

<p></p>

<p>
  Ռեկուրենտ նեյրոնային ցանցերում հետազոտությունները ժամանակի ընթացքում ավելանում են,
  հետևաբար նաև կիրառությունները: Այս տեսակի ցանցերը ըստ էության, ավելի մոտիկ են ուղեղի
  աշխատանքի մոդելին, քան առաջաբեր ցանցերը: Ռեկուրենտ ցանցերն ունակ են լուծելու այնպիսի
  խնդիրներ, որոնք առաջաբեր ցանցերի համար մեծ դժվարություն են ներկայացնում: Այնուամենայնիվ,
  սահմանափակելով մեր շրջանակը, այս գրքում կկենտրոնանք ավելի լայնորեն կիրառվող առաջաբեր
  ցանցերի վրա:
</p>

<p>
  <h3>
    <a name="a_simple_network_to_classify_handwritten_digits"></a>
    <a href="#a_simple_network_to_classify_handwritten_digits">
      Պարզ ցանց ձեռագիր թվանշանները ճանաչելու համար
    </a>
  </h3>
</p>

<p>Having defined neural networks, let's return to handwriting
recognition.  We can split the problem of recognizing handwritten
digits into two sub-problems.  First, we'd like a way of breaking an
image containing many digits into a sequence of separate images, each
containing a single digit.  For example, we'd like to break the image</p><p><center><img src="images/digits.png" width="300px"></center></p><p>into six separate images,</p><p><center><img src="images/digits_separate.png" width="440px"></center> </p><p>We humans solve this <em>segmentation
  problem</em> with ease, but it's challenging
for a computer program to correctly break up the image.  Once the
image has been segmented, the program then needs to classify each
individual digit.  So, for instance, we'd like our program to
recognize that the first digit above,</p><p><center><img src="images/mnist_first_digit.png" width="64px"></center></p><p>is a 5.</p><p>We'll focus on writing a program to solve the second problem, that is,
classifying individual digits.  We do this because it turns out that
the segmentation problem is not so difficult to solve, once you have a
good way of classifying individual digits.  There are many approaches
to solving the segmentation problem.  One approach is to trial many
different ways of segmenting the image, using the individual digit
classifier to score each trial segmentation.  A trial segmentation
gets a high score if the individual digit classifier is confident of
its classification in all segments, and a low score if the classifier
is having a lot of trouble in one or more segments.  The idea is that
if the classifier is having trouble somewhere, then it's probably
having trouble because the segmentation has been chosen incorrectly.
This idea and other variations can be used to solve the segmentation
problem quite well.  So instead of worrying about segmentation we'll
concentrate on developing a neural network which can solve the more
interesting and difficult problem, namely, recognizing individual
handwritten digits.</p><p>To recognize individual digits we will use a three-layer neural
network:</p><p><center>
<img src="images/tikz12.png"/>
</center></p><p>The input layer of the network contains neurons encoding the values of
the input pixels.  As discussed in the next section, our training data
for the network will consist of many $28$ by $28$ pixel images of
scanned handwritten digits, and so the input layer contains $784 = 28
\times 28$ neurons.  For simplicity I've omitted most of the $784$
input neurons in the diagram above.  The input pixels are greyscale,
with a value of $0.0$ representing white, a value of $1.0$
representing black, and in between values representing gradually
darkening shades of grey.</p><p>The second layer of the network is a hidden layer.  We denote the
number of neurons in this hidden layer by $n$, and we'll experiment
with different values for $n$.  The example shown illustrates a small
hidden layer, containing just $n = 15$ neurons.</p><p>The output layer of the network contains 10 neurons.  If the first
neuron fires, i.e., has an output $\approx 1$, then that will indicate
that the network thinks the digit is a $0$.  If the second neuron
fires then that will indicate that the network thinks the digit is a
$1$.  And so on.  A little more precisely, we number the output
neurons from $0$ through $9$, and figure out which neuron has the
highest activation value.  If that neuron is, say, neuron number $6$,
then our network will guess that the input digit was a $6$.  And so on
for the other output neurons.</p><p>You might wonder why we use $10$ output neurons.  After all, the goal
of the network is to tell us which digit ($0, 1, 2, \ldots, 9$)
corresponds to the input image.  A seemingly natural way of doing that
is to use just $4$ output neurons, treating each neuron as taking on a
binary value, depending on whether the neuron's output is closer to
$0$ or to $1$.  Four neurons are enough to encode the answer, since
$2^4 = 16$ is more than the 10 possible values for the input digit.
Why should our network use $10$ neurons instead?  Isn't that
inefficient?  The ultimate justification is empirical: we can try out
both network designs, and it turns out that, for this particular
problem, the network with $10$ output neurons learns to recognize
digits better than the network with $4$ output neurons.  But that
leaves us wondering <em>why</em> using $10$ output neurons works better.
Is there some heuristic that would tell us in advance that we should
use the $10$-output encoding instead of the $4$-output encoding?</p><p>To understand why we do this, it helps to think about what the neural
network is doing from first principles.  Consider first the case where
we use $10$ output neurons.  Let's concentrate on the first output
neuron, the one that's trying to decide whether or not the digit is a
$0$.  It does this by weighing up evidence from the hidden layer of
neurons.  What are those hidden neurons doing?  Well, just suppose for
the sake of argument that the first neuron in the hidden layer detects
whether or not an image like the following is present:</p><p><center><img src="images/mnist_top_left_feature.png" width="130px"></center></p><p>It can do this by heavily weighting input pixels which overlap with
the image, and only lightly weighting the other inputs.  In a similar
way, let's suppose for the sake of argument that the second, third,
and fourth neurons in the hidden layer detect whether or not the
following images are present:</p><p><center><img src="images/mnist_other_features.png" width="424px"></center></p><p>As you may have guessed, these four images together make up the $0$
image that we saw in the line of digits shown <a
  href="#complete_zero">earlier</a>:</p><p><center><img src="images/mnist_complete_zero.png" width="130px"></center></p><p>So if all four of these hidden neurons are firing then we can conclude
that the digit is a $0$.  Of course, that's not the <em>only</em> sort
of evidence we can use to conclude that the image was a $0$ - we
could legitimately get a $0$ in many other ways (say, through
translations of the above images, or slight distortions).  But it
seems safe to say that at least in this case we'd conclude that the
input was a $0$.</p><p></p><p></p><p></p><p>Supposing the neural network functions in this way, we can give a
plausible explanation for why it's better to have $10$ outputs from
the network, rather than $4$.  If we had $4$ outputs, then the first
output neuron would be trying to decide what the most significant bit
of the digit was.  And there's no easy way to relate that most
significant bit to simple shapes like those shown above.  It's hard to
imagine that there's any good historical reason the component shapes
of the digit will be closely related to (say) the most significant bit
in the output.</p><p>Now, with all that said, this is all just a heuristic.  Nothing says
that the three-layer neural network has to operate in the way I
described, with the hidden neurons detecting simple component shapes.
Maybe a clever learning algorithm will find some assignment of weights
that lets us use only $4$ output neurons.  But as a heuristic the way
of thinking I've described works pretty well, and can save you a lot
of time in designing good neural network architectures.</p><p><h4><a name="exercise_513527"></a><a href="#exercise_513527">Exercise</a></h4><ul>
<li> There is a way of determining the bitwise representation of a
  digit by adding an extra layer to the three-layer network above.
  The extra layer converts the output from the previous layer into a
  binary representation, as illustrated in the figure below.  Find a
  set of weights and biases for the new output layer.  Assume that the
  first $3$ layers of neurons are such that the correct output in the
  third layer (i.e., the old output layer) has activation at least
  $0.99$, and incorrect outputs have activation less than $0.01$.
</ul></p><p><center>
<img src="images/tikz13.png"/>
</center></p><p></p><p></p><p></p><p><h3><a name="learning_with_gradient_descent"></a><a href="#learning_with_gradient_descent">Learning with gradient descent</a></h3></p><p></p><p>Now that we have a design for our neural network, how can it learn to
recognize digits?  The first thing we'll need is a data set to learn
from - a so-called training data set.  We'll use the
 <a href="http://yann.lecun.com/exdb/mnist/">MNIST
  data set</a>, which contains tens of thousands of scanned images of
handwritten digits, together with their correct classifications.
MNIST's name comes from the fact that it is a modified subset of two
data sets collected by
<a href="http://en.wikipedia.org/wiki/National_Institute_of_Standards_and_Technology">NIST</a>,
the United States' National Institute of Standards and
Technology. Here's a few images from MNIST:</p><p><center><img src="images/digits_separate.png" width="420px"></center> </p><p>As you can see, these digits are, in fact, the same as those shown
at the <a
  href="#complete_zero">beginning of this chapter</a> as a challenge
to recognize.  Of course, when testing our network we'll ask it to
recognize images which aren't in the training set!</p><p>The MNIST data comes in two parts.  The first part contains 60,000
images to be used as training data.  These images are scanned
handwriting samples from 250 people, half of whom were US Census
Bureau employees, and half of whom were high school students.  The
images are greyscale and 28 by 28 pixels in size.  The second part of
the MNIST data set is 10,000 images to be used as test data.  Again,
these are 28 by 28 greyscale images.  We'll use the test data to
evaluate how well our neural network has learned to recognize digits.
To make this a good test of performance, the test data was taken from
a <em>different</em> set of 250 people than the original training data
(albeit still a group split between Census Bureau employees and high
school students).  This helps give us confidence that our system can
recognize digits from people whose writing it didn't see during
training.</p><p>We'll use the notation $x$ to denote a training input.  It'll be
convenient to regard each training input $x$ as a $28 \times 28 =
784$-dimensional vector.  Each entry in the vector represents the grey
value for a single pixel in the image.  We'll denote the corresponding
desired output by $y = y(x)$, where $y$ is a $10$-dimensional vector.
For example, if a particular training image, $x$, depicts a $6$, then
$y(x) = (0, 0, 0, 0, 0, 0, 1, 0, 0, 0)^T$ is the desired output from
the network.  Note that $T$ here is the transpose operation, turning a
row vector into an ordinary (column) vector.</p><p>What we'd like is an algorithm which lets us find weights and biases
so that the output from the network approximates $y(x)$ for all
training inputs $x$.  To quantify how well we're achieving this goal
we define a <em>cost function</em>*<span class="marginnote">
*Sometimes referred to as a
  <em>loss</em> or <em>objective</em> function.  We use the term cost
  function throughout this book, but you should note the other
  terminology, since it's often used in research papers and other
  discussions of neural networks. </span>:
<a class="displaced_anchor" name="eqtn6"></a>\begin{eqnarray}  C(w,b) \equiv
  \frac{1}{2n} \sum_x \| y(x) - a\|^2.
\tag{6}\end{eqnarray}
Here, $w$ denotes the collection of all weights in the network, $b$
all the biases, $n$ is the total number of training inputs, $a$ is the
vector of outputs from the network when $x$ is input, and the sum is
over all training inputs, $x$.  Of course, the output $a$ depends on
$x$, $w$ and $b$, but to keep the notation simple I haven't explicitly
indicated this dependence.  The notation $\| v \|$ just denotes the
usual length function for a vector $v$.  We'll call $C$ the
<em>quadratic</em> cost function; it's also
sometimes known as the <em>mean squared error</em> or just <em>MSE</em>.
Inspecting the form of the quadratic cost function, we see that
$C(w,b)$ is non-negative, since every term in the sum is non-negative.
Furthermore, the cost $C(w,b)$ becomes small, i.e., $C(w,b) \approx
0$, precisely when $y(x)$ is approximately equal to the output, $a$,
for all training inputs, $x$.  So our training algorithm has done a
good job if it can find weights and biases so that $C(w,b) \approx 0$.
By contrast, it's not doing so well when $C(w,b)$ is large - that
would mean that $y(x)$ is not close to the output $a$ for a large
number of inputs.  So the aim of our training algorithm will be to
minimize the cost $C(w,b)$ as a function of the weights and biases.
In other words, we want to find a set of weights and biases which make
the cost as small as possible.  We'll do that using an algorithm known
as <em>gradient descent</em>.</p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p>
Why introduce the quadratic cost?  After all, aren't we primarily
interested in the number of images correctly classified by the
network?  Why not try to maximize that number directly, rather than
minimizing a proxy measure like the quadratic cost?  The problem with
that is that the number of images correctly classified is not a smooth
function of the weights and biases in the network.  For the most part,
making small changes to the weights and biases won't cause any change
at all in the number of training images classified correctly.  That
makes it difficult to figure out how to change the weights and biases
to get improved performance.  If we instead use a smooth cost function
like the quadratic cost it turns out to be easy to figure out how to
make small changes in the weights and biases so as to get an
improvement in the cost.  That's why we focus first on minimizing the
quadratic cost, and only after that will we examine the classification
accuracy.</p><p></p><p>Even given that we want to use a smooth cost function, you may still
wonder why we choose the quadratic function used in
Equation <span id="margin_432054929623_reveal" class="equation_link">(6)</span><span id="margin_432054929623" class="marginequation" style="display: none;"><a href="chap1.html#eqtn6" style="padding-bottom: 5px;" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';">\begin{eqnarray}  C(w,b) \equiv
  \frac{1}{2n} \sum_x \| y(x) - a\|^2 \nonumber\end{eqnarray}</a></span><script>$('#margin_432054929623_reveal').click(function() {$('#margin_432054929623').toggle('slow', function() {});});</script>.  Isn't this a rather <em>ad
  hoc</em> choice?  Perhaps if we chose a different cost function we'd get
a totally different set of minimizing weights and biases?  This is a
valid concern, and later we'll revisit the cost function, and make
some modifications.  However, the quadratic cost function of
Equation <span id="margin_488284336334_reveal" class="equation_link">(6)</span><span id="margin_488284336334" class="marginequation" style="display: none;"><a href="chap1.html#eqtn6" style="padding-bottom: 5px;" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';">\begin{eqnarray}  C(w,b) \equiv
  \frac{1}{2n} \sum_x \| y(x) - a\|^2 \nonumber\end{eqnarray}</a></span><script>$('#margin_488284336334_reveal').click(function() {$('#margin_488284336334').toggle('slow', function() {});});</script> works perfectly well for
understanding the basics of learning in neural networks, so we'll
stick with it for now.</p><p>Recapping, our goal in training a neural network is to find weights
and biases which minimize the quadratic cost function $C(w, b)$.  This
is a well-posed problem, but it's got a lot of distracting structure
as currently posed - the interpretation of $w$ and $b$ as weights
and biases, the $\sigma$ function lurking in the background, the
choice of network architecture, MNIST, and so on.  It turns out that
we can understand a tremendous amount by ignoring most of that
structure, and just concentrating on the minimization aspect.  So for
now we're going to forget all about the specific form of the cost
function, the connection to neural networks, and so on.  Instead,
we're going to imagine that we've simply been given a function of many
variables and we want to minimize that function.  We're going to
develop a technique called <em>gradient descent</em> which can be used
to solve such minimization problems.  Then we'll come back to the
specific function we want to minimize for neural networks.</p><p>Okay, let's suppose we're trying to minimize some function, $C(v)$.
This could be any real-valued function of many variables, $v = v_1,
v_2, \ldots$.  Note that I've replaced the $w$ and $b$ notation by $v$
to emphasize that this could be any function - we're not
specifically thinking in the neural networks context any more.  To
minimize $C(v)$ it helps to imagine $C$ as a function of just two
variables, which we'll call $v_1$ and $v_2$:</p><p><center><img src="images/valley.png" width="542px"></center></p><p>What we'd like is to find where $C$ achieves its global minimum.  Now,
of course, for the function plotted above, we can eyeball the graph
and find the minimum.  In that sense, I've perhaps shown slightly
<em>too</em> simple a function! A general function, $C$, may be a
complicated function of many variables, and it won't usually be
possible to just eyeball the graph to find the minimum.</p><p>One way of attacking the problem is to use calculus to try to find the
minimum analytically.  We could compute derivatives and then try using
them to find places where $C$ is an extremum.  With some luck that
might work when $C$ is a function of just one or a few variables.  But
it'll turn into a nightmare when we have many more variables.  And for
neural networks we'll often want <em>far</em> more variables - the
biggest neural networks have cost functions which depend on billions
of weights and biases in an extremely complicated way.  Using calculus
to minimize that just won't work!</p><p>(After asserting that we'll gain insight by imagining $C$ as a
function of just two variables, I've turned around twice in two
paragraphs and said, "hey, but what if it's a function of many more
than two variables?"  Sorry about that.  Please believe me when I say
that it really does help to imagine $C$ as a function of two
variables.  It just happens that sometimes that picture breaks down,
and the last two paragraphs were dealing with such breakdowns.  Good
thinking about mathematics often involves juggling multiple intuitive
pictures, learning when it's appropriate to use each picture, and when
it's not.)</p><p><a name="gradient_descent"></a></p><p>Okay, so calculus doesn't work.  Fortunately, there is a beautiful
analogy which suggests an algorithm which works pretty well.  We start
by thinking of our function as a kind of a valley.  If you squint just
a little at the plot above, that shouldn't be too hard.  And we
imagine a ball rolling down the slope of the valley.  Our everyday
experience tells us that the ball will eventually roll to the bottom
of the valley.  Perhaps we can use this idea as a way to find a
minimum for the function?  We'd randomly choose a starting point for
an (imaginary) ball, and then simulate the motion of the ball as it
rolled down to the bottom of the valley.  We could do this simulation
simply by computing derivatives (and perhaps some second derivatives)
of $C$ - those derivatives would tell us everything we need to know
about the local "shape" of the valley, and therefore how our ball
should roll.</p><p>Based on what I've just written, you might suppose that we'll be
trying to write down Newton's equations of motion for the ball,
considering the effects of friction and gravity, and so on.  Actually,
we're not going to take the ball-rolling analogy quite that seriously
- we're devising an algorithm to minimize $C$, not developing an
accurate simulation of the laws of physics!  The ball's-eye view is
meant to stimulate our imagination, not constrain our thinking.  So
rather than get into all the messy details of physics, let's simply
ask ourselves: if we were declared God for a day, and could make up
our own laws of physics, dictating to the ball how it should roll,
what law or laws of motion could we pick that would make it so the
ball always rolled to the bottom of the valley?</p><p>To make this question more precise, let's think about what happens
when we move the ball a small amount $\Delta v_1$ in the $v_1$
direction, and a small amount $\Delta v_2$ in the $v_2$ direction.
Calculus tells us that $C$ changes as follows:
<a class="displaced_anchor" name="eqtn7"></a>\begin{eqnarray}
  \Delta C \approx \frac{\partial C}{\partial v_1} \Delta v_1 +
  \frac{\partial C}{\partial v_2} \Delta v_2.
\tag{7}\end{eqnarray}
We're going to find a way of choosing $\Delta v_1$ and $\Delta v_2$ so
as to make $\Delta C$ negative; i.e., we'll choose them so the ball is
rolling down into the valley.  To figure out how to make such a choice
it helps to define $\Delta v$ to be the vector of changes in $v$,
$\Delta v \equiv (\Delta v_1, \Delta v_2)^T$, where $T$ is again the
transpose operation, turning row vectors into column vectors.  We'll
also define the <em>gradient</em> of $C$
to be the vector of partial derivatives, $\left(\frac{\partial
    C}{\partial v_1}, \frac{\partial C}{\partial v_2}\right)^T$.  We
denote the gradient vector by $\nabla C$, i.e.:
<a class="displaced_anchor" name="eqtn8"></a>\begin{eqnarray}
  \nabla C \equiv \left( \frac{\partial C}{\partial v_1},
  \frac{\partial C}{\partial v_2} \right)^T.
\tag{8}\end{eqnarray}
In a moment we'll rewrite the change $\Delta C$ in terms of $\Delta v$
and the gradient, $\nabla C$.  Before getting to that, though, I want
to clarify something that sometimes gets people hung up on the
gradient.  When meeting the $\nabla C$ notation for the first time,
people sometimes wonder how they should think about the $\nabla$
symbol.  What, exactly, does $\nabla$ mean?  In fact, it's perfectly
fine to think of $\nabla C$ as a single mathematical object - the
vector defined above - which happens to be written using two
symbols.  In this point of view, $\nabla$ is just a piece of
notational flag-waving, telling you "hey, $\nabla C$ is a gradient
vector".  There are more advanced points of view where $\nabla$ can
be viewed as an independent mathematical entity in its own right (for
example, as a differential operator), but we won't need such points of
view.</p><p>With these definitions, the expression <span id="margin_659965637148_reveal" class="equation_link">(7)</span><span id="margin_659965637148" class="marginequation" style="display: none;"><a href="chap1.html#eqtn7" style="padding-bottom: 5px;" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';">\begin{eqnarray}
  \Delta C \approx \frac{\partial C}{\partial v_1} \Delta v_1 +
  \frac{\partial C}{\partial v_2} \Delta v_2 \nonumber\end{eqnarray}</a></span><script>$('#margin_659965637148_reveal').click(function() {$('#margin_659965637148').toggle('slow', function() {});});</script> for
$\Delta C$ can be rewritten as
<a class="displaced_anchor" name="eqtn9"></a>\begin{eqnarray}
  \Delta C \approx \nabla C \cdot \Delta v.
\tag{9}\end{eqnarray}
This equation helps explain why $\nabla C$ is called the gradient
vector: $\nabla C$ relates changes in $v$ to changes in $C$, just as
we'd expect something called a gradient to do.  But what's really
exciting about the equation is that it lets us see how to choose
$\Delta v$ so as to make $\Delta C$ negative.  In particular, suppose
we choose
<a class="displaced_anchor" name="eqtn10"></a>\begin{eqnarray}
  \Delta v = -\eta \nabla C,
\tag{10}\end{eqnarray}
where $\eta$ is a small, positive parameter (known as the
<em>learning rate</em>).
Then Equation <span id="margin_859162866010_reveal" class="equation_link">(9)</span><span id="margin_859162866010" class="marginequation" style="display: none;"><a href="chap1.html#eqtn9" style="padding-bottom: 5px;" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';">\begin{eqnarray}
  \Delta C \approx \nabla C \cdot \Delta v \nonumber\end{eqnarray}</a></span><script>$('#margin_859162866010_reveal').click(function() {$('#margin_859162866010').toggle('slow', function() {});});</script> tells us that $\Delta C \approx -\eta
\nabla C \cdot \nabla C = -\eta \|\nabla C\|^2$.  Because $\| \nabla C
\|^2 \geq 0$, this guarantees that $\Delta C \leq 0$, i.e., $C$ will
always decrease, never increase, if we change $v$ according to the
prescription in <span id="margin_116668158518_reveal" class="equation_link">(10)</span><span id="margin_116668158518" class="marginequation" style="display: none;"><a href="chap1.html#eqtn10" style="padding-bottom: 5px;" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';">\begin{eqnarray}
  \Delta v = -\eta \nabla C \nonumber\end{eqnarray}</a></span><script>$('#margin_116668158518_reveal').click(function() {$('#margin_116668158518').toggle('slow', function() {});});</script>.  (Within, of course, the
limits of the approximation in Equation <span id="margin_780815505894_reveal" class="equation_link">(9)</span><span id="margin_780815505894" class="marginequation" style="display: none;"><a href="chap1.html#eqtn9" style="padding-bottom: 5px;" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';">\begin{eqnarray}
  \Delta C \approx \nabla C \cdot \Delta v \nonumber\end{eqnarray}</a></span><script>$('#margin_780815505894_reveal').click(function() {$('#margin_780815505894').toggle('slow', function() {});});</script>).  This is
exactly the property we wanted!  And so we'll take
Equation <span id="margin_11850183887_reveal" class="equation_link">(10)</span><span id="margin_11850183887" class="marginequation" style="display: none;"><a href="chap1.html#eqtn10" style="padding-bottom: 5px;" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';">\begin{eqnarray}
  \Delta v = -\eta \nabla C \nonumber\end{eqnarray}</a></span><script>$('#margin_11850183887_reveal').click(function() {$('#margin_11850183887').toggle('slow', function() {});});</script> to define the "law of motion"
for the ball in our gradient descent algorithm.  That is, we'll use
Equation <span id="margin_838405111504_reveal" class="equation_link">(10)</span><span id="margin_838405111504" class="marginequation" style="display: none;"><a href="chap1.html#eqtn10" style="padding-bottom: 5px;" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';">\begin{eqnarray}
  \Delta v = -\eta \nabla C \nonumber\end{eqnarray}</a></span><script>$('#margin_838405111504_reveal').click(function() {$('#margin_838405111504').toggle('slow', function() {});});</script> to compute a value for $\Delta
v$, then move the ball's position $v$ by that amount:
<a class="displaced_anchor" name="eqtn11"></a>\begin{eqnarray}
  v \rightarrow v' = v -\eta \nabla C.
\tag{11}\end{eqnarray}
Then we'll use this update rule again, to make another move.  If we
keep doing this, over and over, we'll keep decreasing $C$ until - we
hope - we reach a global minimum.</p><p>Summing up, the way the gradient descent algorithm works is to
repeatedly compute the gradient $\nabla C$, and then to move in the
<em>opposite</em> direction, "falling down" the slope of the valley.
We can visualize it like this:</p><p><center><img src="images/valley_with_ball.png" width="542px"></center></p><p>Notice that with this rule gradient descent doesn't reproduce real
physical motion.  In real life a ball has momentum, and that momentum
may allow it to roll across the slope, or even (momentarily) roll
uphill.  It's only after the effects of friction set in that the ball
is guaranteed to roll down into the valley.  By contrast, our rule for
choosing $\Delta v$ just says "go down, right now".  That's still a
pretty good rule for finding the minimum!</p><p>To make gradient descent work correctly, we need to choose the
learning rate $\eta$ to be small
enough that Equation <span id="margin_261741104421_reveal" class="equation_link">(9)</span><span id="margin_261741104421" class="marginequation" style="display: none;"><a href="chap1.html#eqtn9" style="padding-bottom: 5px;" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';">\begin{eqnarray}
  \Delta C \approx \nabla C \cdot \Delta v \nonumber\end{eqnarray}</a></span><script>$('#margin_261741104421_reveal').click(function() {$('#margin_261741104421').toggle('slow', function() {});});</script> is a good approximation.  If
we don't, we might end up with $\Delta C > 0$, which obviously would
not be good!  At the same time, we don't want $\eta$ to be too small,
since that will make the changes $\Delta v$ tiny, and thus the
gradient descent algorithm will work very slowly.  In practical
implementations, $\eta$ is often varied so that
Equation <span id="margin_89917482490_reveal" class="equation_link">(9)</span><span id="margin_89917482490" class="marginequation" style="display: none;"><a href="chap1.html#eqtn9" style="padding-bottom: 5px;" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';">\begin{eqnarray}
  \Delta C \approx \nabla C \cdot \Delta v \nonumber\end{eqnarray}</a></span><script>$('#margin_89917482490_reveal').click(function() {$('#margin_89917482490').toggle('slow', function() {});});</script> remains a good approximation, but the
algorithm isn't too slow.  We'll see later how this
works. </p><p>I've explained gradient descent when $C$ is a function of just two
variables.  But, in fact, everything works just as well even when $C$
is a function of many more variables.  Suppose in particular that $C$
is a function of $m$ variables, $v_1,\ldots,v_m$.  Then the change
$\Delta C$ in $C$ produced by a small change $\Delta v = (\Delta v_1,
\ldots, \Delta v_m)^T$ is
<a class="displaced_anchor" name="eqtn12"></a>\begin{eqnarray}
  \Delta C \approx \nabla C \cdot \Delta v,
\tag{12}\end{eqnarray}
where the gradient $\nabla C$ is the vector
<a class="displaced_anchor" name="eqtn13"></a>\begin{eqnarray}
  \nabla C \equiv \left(\frac{\partial C}{\partial v_1}, \ldots,
  \frac{\partial C}{\partial v_m}\right)^T.
\tag{13}\end{eqnarray}
Just as for the two variable case, we can
choose
<a class="displaced_anchor" name="eqtn14"></a>\begin{eqnarray}
  \Delta v = -\eta \nabla C,
\tag{14}\end{eqnarray}
and we're guaranteed that our (approximate)
expression <span id="margin_737008049048_reveal" class="equation_link">(12)</span><span id="margin_737008049048" class="marginequation" style="display: none;"><a href="chap1.html#eqtn12" style="padding-bottom: 5px;" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';">\begin{eqnarray}
  \Delta C \approx \nabla C \cdot \Delta v \nonumber\end{eqnarray}</a></span><script>$('#margin_737008049048_reveal').click(function() {$('#margin_737008049048').toggle('slow', function() {});});</script> for $\Delta C$ will be negative.
This gives us a way of following the gradient to a minimum, even when
$C$ is a function of many variables, by repeatedly applying the update
rule
<a class="displaced_anchor" name="eqtn15"></a>\begin{eqnarray}
  v \rightarrow v' = v-\eta \nabla C.
\tag{15}\end{eqnarray}
You can think of this update rule as <em>defining</em> the gradient
descent algorithm.  It gives us a way of repeatedly changing the
position $v$ in order to find a minimum of the function $C$.  The rule
doesn't always work - several things can go wrong and prevent
gradient descent from finding the global minimum of $C$, a point we'll
return to explore in later chapters.  But, in practice gradient
descent often works extremely well, and in neural networks we'll find
that it's a powerful way of minimizing the cost function, and so
helping the net learn.</p><p></p><p></p><p>Indeed, there's even a sense in which gradient descent is the optimal
strategy for searching for a minimum.  Let's suppose that we're trying
to make a move $\Delta v$ in position so as to decrease $C$ as much as
possible.  This is equivalent to minimizing $\Delta C \approx \nabla C
\cdot \Delta v$.  We'll constrain the size of the move so that $\|
\Delta v \| = \epsilon$ for some small fixed $\epsilon > 0$.  In other
words, we want a move that is a small step of a fixed size, and we're
trying to find the movement direction which decreases $C$ as much as
possible.  It can be proved that the choice of $\Delta v$ which
minimizes $\nabla C \cdot \Delta v$ is $\Delta v = - \eta \nabla C$,
where $\eta = \epsilon / \|\nabla C\|$ is determined by the size
constraint $\|\Delta v\| = \epsilon$.  So gradient descent can be
viewed as a way of taking small steps in the direction which does the
most to immediately decrease $C$.</p><p><h4><a name="exercises_647181"></a><a href="#exercises_647181">Exercises</a></h4><ul>
<li> Prove the assertion of the last paragraph.  <em>Hint:</em> If
    you're not already familiar with the
    <a href="http://en.wikipedia.org/wiki/Cauchy%E2%80%93Schwarz_inequality">Cauchy-Schwarz
      inequality</a>, you may find it helpful to familiarize yourself
    with it.</p><p><li> I explained gradient descent when $C$ is a function of two
  variables, and when it's a function of more than two variables.
  What happens when $C$ is a function of just one variable?  Can you
  provide a geometric interpretation of what gradient descent is doing
  in the one-dimensional case?
</ul></p><p></p><p>People have investigated many variations of gradient descent,
including variations that more closely mimic a real physical ball.
These ball-mimicking variations have some advantages, but also have a
major disadvantage: it turns out to be necessary to compute second
partial derivatives of $C$, and this can be quite costly.  To see why
it's costly, suppose we want to compute all the second partial
derivatives $\partial^2 C/ \partial v_j \partial v_k$.  If there are a
million such $v_j$ variables then we'd need to compute something like
a trillion (i.e., a million squared) second partial
derivatives*<span class="marginnote">
*Actually, more like half a trillion, since
  $\partial^2 C/ \partial v_j \partial v_k = \partial^2 C/ \partial
  v_k \partial v_j$.  Still, you get the point.</span>!  That's going to be
computationally costly.  With that said, there are tricks for avoiding
this kind of problem, and finding alternatives to gradient descent is
an active area of investigation.  But in this book we'll use gradient
descent (and variations) as our main approach to learning in neural
networks.</p><p>How can we apply gradient descent to learn in a neural network?  The
idea is to use gradient descent to find the weights $w_k$ and biases
$b_l$ which minimize the cost in
Equation <span id="margin_167805660230_reveal" class="equation_link">(6)</span><span id="margin_167805660230" class="marginequation" style="display: none;"><a href="chap1.html#eqtn6" style="padding-bottom: 5px;" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';">\begin{eqnarray}  C(w,b) \equiv
  \frac{1}{2n} \sum_x \| y(x) - a\|^2 \nonumber\end{eqnarray}</a></span><script>$('#margin_167805660230_reveal').click(function() {$('#margin_167805660230').toggle('slow', function() {});});</script>.  To see how this works, let's
restate the gradient descent update rule, with the weights and biases
replacing the variables $v_j$.  In other words, our "position" now
has components $w_k$ and $b_l$, and the gradient vector $\nabla C$ has
corresponding components $\partial C / \partial w_k$ and $\partial C
/ \partial b_l$.  Writing out the gradient descent update rule in
terms of components, we have
<a class="displaced_anchor" name="eqtn16"></a><a class="displaced_anchor" name="eqtn17"></a>\begin{eqnarray}
  w_k & \rightarrow & w_k' = w_k-\eta \frac{\partial C}{\partial w_k} \tag{16}\\
  b_l & \rightarrow & b_l' = b_l-\eta \frac{\partial C}{\partial b_l}.
\tag{17}\end{eqnarray}
By repeatedly applying this update rule we can "roll down the hill",
and hopefully find a minimum of the cost function.  In other words,
this is a rule which can be used to learn in a neural network.</p><p>There are a number of challenges in applying the gradient descent
rule.  We'll look into those in depth in later chapters.  But for now
I just want to mention one problem.  To understand what the problem
is, let's look back at the quadratic cost in
Equation <span id="margin_786090300230_reveal" class="equation_link">(6)</span><span id="margin_786090300230" class="marginequation" style="display: none;"><a href="chap1.html#eqtn6" style="padding-bottom: 5px;" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';">\begin{eqnarray}  C(w,b) \equiv
  \frac{1}{2n} \sum_x \| y(x) - a\|^2 \nonumber\end{eqnarray}</a></span><script>$('#margin_786090300230_reveal').click(function() {$('#margin_786090300230').toggle('slow', function() {});});</script>.  Notice that this cost
function has the form $C = \frac{1}{n} \sum_x C_x$, that is, it's an
average over costs $C_x \equiv \frac{\|y(x)-a\|^2}{2}$ for individual
training examples.  In practice, to compute the gradient $\nabla C$ we
need to compute the gradients $\nabla C_x$ separately for each
training input, $x$, and then average them, $\nabla C = \frac{1}{n}
\sum_x \nabla C_x$.  Unfortunately, when the number of training inputs
is very large this can take a long time, and learning thus occurs
slowly.</p><p>An idea called <em>stochastic gradient descent</em> can be used to speed
up learning.  The idea is to estimate the gradient $\nabla C$ by
computing $\nabla C_x$ for a small sample of randomly chosen training
inputs.  By averaging over this small sample it turns out that we can
quickly get a good estimate of the true gradient $\nabla C$, and this
helps speed up gradient descent, and thus learning.</p><p>To make these ideas more precise, stochastic gradient descent works by
randomly picking out a small number $m$ of randomly chosen training
inputs.  We'll label those random training inputs $X_1, X_2, \ldots,
X_m$, and refer to them as a <em>mini-batch</em>.  Provided the sample
size $m$ is large enough we expect that the average value of the
$\nabla C_{X_j}$ will be roughly equal to the average over all $\nabla
C_x$, that is,
<a class="displaced_anchor" name="eqtn18"></a>\begin{eqnarray}
  \frac{\sum_{j=1}^m \nabla C_{X_{j}}}{m} \approx \frac{\sum_x \nabla C_x}{n} = \nabla C,
\tag{18}\end{eqnarray}
where the second sum is over the entire set of training data.
Swapping sides we get
<a class="displaced_anchor" name="eqtn19"></a>\begin{eqnarray}
  \nabla C \approx \frac{1}{m} \sum_{j=1}^m \nabla C_{X_{j}},
\tag{19}\end{eqnarray}
confirming that we can estimate the overall gradient by computing
gradients just for the randomly chosen mini-batch. </p><p>To connect this explicitly to learning in neural networks, suppose
$w_k$ and $b_l$ denote the weights and biases in our neural network.
Then stochastic gradient descent works by picking out a randomly
chosen mini-batch of training inputs, and training with those,
<a class="displaced_anchor" name="eqtn20"></a><a class="displaced_anchor" name="eqtn21"></a>\begin{eqnarray}
  w_k & \rightarrow & w_k' = w_k-\frac{\eta}{m}
  \sum_j \frac{\partial C_{X_j}}{\partial w_k} \tag{20}\\

  b_l & \rightarrow & b_l' = b_l-\frac{\eta}{m}
  \sum_j \frac{\partial C_{X_j}}{\partial b_l},
\tag{21}\end{eqnarray}
where the sums are over all the training examples $X_j$ in the current
mini-batch.  Then we pick out another randomly chosen mini-batch and
train with those.  And so on, until we've exhausted the training
inputs, which is said to complete an
<em>epoch</em> of training.  At that point
we start over with a new training epoch.</p><p>Incidentally, it's worth noting that conventions vary about scaling of
the cost function and of mini-batch updates to the weights and biases.
In Equation <span id="margin_84852336525_reveal" class="equation_link">(6)</span><span id="margin_84852336525" class="marginequation" style="display: none;"><a href="chap1.html#eqtn6" style="padding-bottom: 5px;" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';">\begin{eqnarray}  C(w,b) \equiv
  \frac{1}{2n} \sum_x \| y(x) - a\|^2 \nonumber\end{eqnarray}</a></span><script>$('#margin_84852336525_reveal').click(function() {$('#margin_84852336525').toggle('slow', function() {});});</script> we scaled the overall cost
function by a factor $\frac{1}{n}$.  People sometimes omit the
$\frac{1}{n}$, summing over the costs of individual training examples
instead of averaging.  This is particularly useful when the total
number of training examples isn't known in advance.  This can occur if
more training data is being generated in real time, for instance.
And, in a similar way, the mini-batch update rules <span id="margin_517690364363_reveal" class="equation_link">(20)</span><span id="margin_517690364363" class="marginequation" style="display: none;"><a href="chap1.html#eqtn20" style="padding-bottom: 5px;" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';">\begin{eqnarray}
  w_k & \rightarrow & w_k' = w_k-\frac{\eta}{m}
  \sum_j \frac{\partial C_{X_j}}{\partial w_k}  \nonumber\end{eqnarray}</a></span><script>$('#margin_517690364363_reveal').click(function() {$('#margin_517690364363').toggle('slow', function() {});});</script>
and <span id="margin_863737688414_reveal" class="equation_link">(21)</span><span id="margin_863737688414" class="marginequation" style="display: none;"><a href="chap1.html#eqtn21" style="padding-bottom: 5px;" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';">\begin{eqnarray}
  b_l & \rightarrow & b_l' = b_l-\frac{\eta}{m}
  \sum_j \frac{\partial C_{X_j}}{\partial b_l} \nonumber\end{eqnarray}</a></span><script>$('#margin_863737688414_reveal').click(function() {$('#margin_863737688414').toggle('slow', function() {});});</script> sometimes omit the $\frac{1}{m}$ term out the
front of the sums.  Conceptually this makes little difference, since
it's equivalent to rescaling the learning rate $\eta$.  But when doing
detailed comparisons of different work it's worth watching out for.</p><p>We can think of stochastic gradient descent as being like political
polling: it's much easier to sample a small mini-batch than it is to
apply gradient descent to the full batch, just as carrying out a poll
is easier than running a full election.  For example, if we have a
training set of size $n = 60,000$, as in MNIST, and choose a
mini-batch size of (say) $m = 10$, this means we'll get a factor of
$6,000$ speedup in estimating the gradient!  Of course, the estimate
won't be perfect - there will be statistical fluctuations - but it
doesn't need to be perfect: all we really care about is moving in a
general direction that will help decrease $C$, and that means we don't
need an exact computation of the gradient.  In practice, stochastic
gradient descent is a commonly used and powerful technique for
learning in neural networks, and it's the basis for most of the
learning techniques we'll develop in this book.</p><p></p><p></p><p></p><p></p><p></p><p><h4><a name="exercise_263792"></a><a href="#exercise_263792">Exercise</a></h4><ul>
<li> An extreme version of gradient descent is to use a mini-batch
  size of just 1.  That is, given a training input, $x$, we update our
  weights and biases according to the rules $w_k \rightarrow w_k' =
  w_k - \eta \partial C_x / \partial w_k$ and $b_l \rightarrow b_l' =
  b_l - \eta \partial C_x / \partial b_l$.  Then we choose another
  training input, and update the weights and biases again.  And so on,
  repeatedly.  This procedure is known as <em>online</em>,
  <em>on-line</em>, or <em>incremental</em> learning.  In online learning,
  a neural network learns from just one training input at a time (just
  as human beings do).  Name one advantage and one disadvantage of
  online learning, compared to stochastic gradient descent with a
  mini-batch size of, say, $20$.
</ul></p><p>Let me conclude this section by discussing a point that sometimes bugs
people new to gradient descent.  In neural networks the cost $C$ is,
of course, a function of many variables - all the weights and biases
- and so in some sense defines a surface in a very high-dimensional
space.  Some people get hung up thinking: "Hey, I have to be able to
visualize all these extra dimensions".  And they may start to worry:
"I can't think in four dimensions, let alone five (or five
million)".  Is there some special ability they're missing, some
ability that "real" supermathematicians have?  Of course, the answer
is no.  Even most professional mathematicians can't visualize four
dimensions especially well, if at all.  The trick they use, instead,
is to develop other ways of representing what's going on.  That's
exactly what we did above: we used an algebraic (rather than visual)
representation of $\Delta C$ to figure out how to move so as to
decrease $C$.  People who are good at thinking in high dimensions have
a mental library containing many different techniques along these
lines; our algebraic trick is just one example.  Those techniques may
not have the simplicity we're accustomed to when visualizing three
dimensions, but once you build up a library of such techniques, you
can get pretty good at thinking in high dimensions.  I won't go into
more detail here, but if you're interested then you may enjoy reading
<a href="http://mathoverflow.net/questions/25983/intuitive-crutches-for-higher-dimensional-thinking">this
  discussion</a> of some of the techniques professional mathematicians
use to think in high dimensions.  While some of the techniques
discussed are quite complex, much of the best content is intuitive and
accessible, and could be mastered by anyone.</p><p></p><p>
<h3><a name="implementing_our_network_to_classify_digits"></a><a href="#implementing_our_network_to_classify_digits">Implementing our network to classify digits</a></h3></p><p>Alright, let's write a program that learns how to recognize
handwritten digits, using stochastic gradient descent and the MNIST
training data.  The first thing we need is to get the MNIST data.  If
you're a <tt>git</tt> user then you can obtain the data by cloning the
code repository for this book,</p><p><div class="highlight"><pre>git clone https://github.com/mnielsen/neural-networks-and-deep-learning.git
</pre></div>
</p><p>If you don't use <tt>git</tt> then you can download the data and code
<a href="https://github.com/mnielsen/neural-networks-and-deep-learning/archive/master.zip">here</a>.</p><p>Incidentally, when I described the MNIST data earlier, I said it was
split into 60,000 training images, and 10,000 test images.  That's the
official MNIST description.  Actually, we're going to split the data a
little differently.  We'll leave the test images as is, but split the
60,000-image MNIST training set into two parts: a set of 50,000
images, which we'll use to train our neural network, and a separate
10,000 image <em>validation set</em>.  We won't
use the validation data in this chapter, but later in the book we'll
find it useful in figuring out how to set certain
<em>hyper-parameters</em> of the neural network - things like the
learning rate, and so on, which aren't directly selected by our
learning algorithm.  Although the validation data isn't part of the
original MNIST specification, many people use MNIST in this fashion,
and the use of validation data is common in neural networks.  When I
refer to the "MNIST training data" from now on, I'll be referring to
our 50,000 image data set, not the original 60,000 image data
set*<span class="marginnote">
*As noted earlier, the MNIST data set is based on two data
  sets collected by NIST, the United States' National Institute of
  Standards and Technology.  To construct MNIST the NIST data sets
  were stripped down and put into a more convenient format by Yann
  LeCun, Corinna Cortes, and Christopher J. C. Burges.  See
  <a href="http://yann.lecun.com/exdb/mnist/">this link</a> for more
  details.  The data set in my repository is in a form that makes it
  easy to load and manipulate the MNIST data in Python.  I obtained
  this particular form of the data from the LISA machine learning
  laboratory at the University of Montreal
  (<a href="http://www.deeplearning.net/tutorial/gettingstarted.html">link</a>).</span>.</p><p></p><p>Apart from the MNIST data we also need a Python library called
<a href="http://numpy.org">Numpy</a>, for doing fast linear algebra.  If you
don't already have Numpy installed, you can get it
<a href="http://www.scipy.org/install.html">here</a>.</p><p>Let me explain the core features of the neural networks code, before
giving a full listing, below.  The centerpiece is a <tt>Network</tt>
class, which we use to represent a neural network.  Here's the code we
use to initialize a <tt>Network</tt> object:</p><p>
<div class="highlight"><pre><span class="k">class</span> <span class="nc">Network</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sizes</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_layers</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">sizes</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sizes</span> <span class="o">=</span> <span class="n">sizes</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">biases</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">sizes</span><span class="p">[</span><span class="mi">1</span><span class="p">:]]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
                        <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">sizes</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">sizes</span><span class="p">[</span><span class="mi">1</span><span class="p">:])]</span>
</pre></div>
</p><p>In this code, the list <tt>sizes</tt> contains the number of neurons in
the respective layers.  So, for example, if we want to create a
<tt>Network</tt> object with 2 neurons in the first layer, 3 neurons in
the second layer, and 1 neuron in the final layer, we'd do this with
the code:
<div class="highlight"><pre><span class="n">net</span> <span class="o">=</span> <span class="n">Network</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
</pre></div>

<a name="weight_initialization"></a> The biases
and weights in the <tt>Network</tt> object are all initialized randomly,
using the Numpy <tt>np.random.randn</tt> function to generate Gaussian
distributions with mean $0$ and standard deviation $1$.  This random
initialization gives our stochastic gradient descent algorithm a place
to start from.  In later chapters we'll find better ways of
initializing the weights and biases, but this will do for now.  Note
that the <tt>Network</tt> initialization code assumes that the first
layer of neurons is an input layer, and omits to set any biases for
those neurons, since biases are only ever used in computing the
outputs from later layers.</p><p>Note also that the biases and weights are stored as lists of Numpy
matrices.  So, for example <tt>net.weights[1]</tt> is a Numpy matrix
storing the weights connecting the second and third layers of neurons.
(It's not the first and second layers, since Python's list indexing
starts at <tt>0</tt>.)  Since <tt>net.weights[1]</tt> is rather verbose,
let's just denote that matrix $w$.  It's a matrix such that $w_{jk}$
is the weight for the connection between the $k^{\rm th}$ neuron in the
second layer, and the $j^{\rm th}$ neuron in the third layer.  This ordering
of the $j$ and $k$ indices may seem strange - surely it'd make more
sense to swap the $j$ and $k$ indices around?  The big advantage of
using this ordering is that it means that the vector of activations of
the third layer of neurons is:
<a class="displaced_anchor" name="eqtn22"></a>\begin{eqnarray}
  a' = \sigma(w a + b).
\tag{22}\end{eqnarray}
There's quite a bit going on in this equation, so let's unpack it
piece by piece.  $a$ is the vector of activations of the second layer
of neurons. To obtain $a'$ we multiply $a$ by the weight matrix $w$,
and add the vector $b$ of biases.  We then apply the function $\sigma$
elementwise to every entry in the vector $w a +b$.  (This is called
<em>vectorizing</em> the function
$\sigma$.) It's easy to verify that
Equation <span id="margin_621803496648_reveal" class="equation_link">(22)</span><span id="margin_621803496648" class="marginequation" style="display: none;"><a href="chap1.html#eqtn22" style="padding-bottom: 5px;" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';">\begin{eqnarray}
  a' = \sigma(w a + b) \nonumber\end{eqnarray}</a></span><script>$('#margin_621803496648_reveal').click(function() {$('#margin_621803496648').toggle('slow', function() {});});</script> gives the same result as our
earlier rule, Equation <span id="margin_466969638583_reveal" class="equation_link">(4)</span><span id="margin_466969638583" class="marginequation" style="display: none;"><a href="chap1.html#eqtn4" style="padding-bottom: 5px;" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';">\begin{eqnarray}
  \frac{1}{1+\exp(-\sum_j w_j x_j-b)} \nonumber\end{eqnarray}</a></span><script>$('#margin_466969638583_reveal').click(function() {$('#margin_466969638583').toggle('slow', function() {});});</script>, for
computing the output of a sigmoid neuron.</p><p><h4><a name="exercise_997362"></a><a href="#exercise_997362">Exercise</a></h4><ul>
<li> Write out Equation <span id="margin_44996869809_reveal" class="equation_link">(22)</span><span id="margin_44996869809" class="marginequation" style="display: none;"><a href="chap1.html#eqtn22" style="padding-bottom: 5px;" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';">\begin{eqnarray}
  a' = \sigma(w a + b) \nonumber\end{eqnarray}</a></span><script>$('#margin_44996869809_reveal').click(function() {$('#margin_44996869809').toggle('slow', function() {});});</script> in component
  form, and verify that it gives the same result as the
  rule <span id="margin_325948154784_reveal" class="equation_link">(4)</span><span id="margin_325948154784" class="marginequation" style="display: none;"><a href="chap1.html#eqtn4" style="padding-bottom: 5px;" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';">\begin{eqnarray}
  \frac{1}{1+\exp(-\sum_j w_j x_j-b)} \nonumber\end{eqnarray}</a></span><script>$('#margin_325948154784_reveal').click(function() {$('#margin_325948154784').toggle('slow', function() {});});</script> for computing the output
  of a sigmoid neuron.
</ul></p><p>With all this in mind, it's easy to write code computing the output
from a <tt>Network</tt> instance.  We begin by defining the sigmoid
function:
<div class="highlight"><pre><span class="k">def</span> <span class="nf">sigmoid</span><span class="p">(</span><span class="n">z</span><span class="p">):</span>
    <span class="k">return</span> <span class="mf">1.0</span><span class="o">/</span><span class="p">(</span><span class="mf">1.0</span><span class="o">+</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">z</span><span class="p">))</span>
</pre></div>

Note that when the input <tt>z</tt> is a vector or Numpy array, Numpy
automatically applies the function <tt>sigmoid</tt> elementwise, that
is, in vectorized form.</p><p>We then add a <tt>feedforward</tt> method to the <tt>Network</tt> class,
which, given an input <tt>a</tt> for the network, returns the
corresponding output*<span class="marginnote">
*It is assumed that the input <tt>a</tt> is
  an <tt>(n, 1)</tt> Numpy ndarray, not a <tt>(n,)</tt> vector.  Here,
  <tt>n</tt> is the number of inputs to the network.  If you try to use
  an <tt>(n,)</tt> vector as input you'll get strange results.  Although
  using an <tt>(n,)</tt> vector appears the more natural choice, using
  an <tt>(n, 1)</tt> ndarray makes it particularly easy to modify the
  code to feedforward multiple inputs at once, and that is sometimes
  convenient. </span>.  All the method does is applies
Equation <span id="margin_608357269255_reveal" class="equation_link">(22)</span><span id="margin_608357269255" class="marginequation" style="display: none;"><a href="chap1.html#eqtn22" style="padding-bottom: 5px;" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';">\begin{eqnarray}
  a' = \sigma(w a + b) \nonumber\end{eqnarray}</a></span><script>$('#margin_608357269255_reveal').click(function() {$('#margin_608357269255').toggle('slow', function() {});});</script> for each layer:
<div class="highlight"><pre>    <span class="k">def</span> <span class="nf">feedforward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">a</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Return the output of the network if &quot;a&quot; is input.&quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">b</span><span class="p">,</span> <span class="n">w</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">biases</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">):</span>
            <span class="n">a</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">a</span><span class="p">)</span><span class="o">+</span><span class="n">b</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">a</span>
</pre></div>
</p><p>Of course, the main thing we want our <tt>Network</tt> objects to do is
to learn.  To that end we'll give them an <tt>SGD</tt> method which
implements stochastic gradient descent.  Here's the code.  It's a
little mysterious in a few places, but I'll break it down below, after
the listing.</p><p><div class="highlight"><pre>    <span class="k">def</span> <span class="nf">SGD</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">training_data</span><span class="p">,</span> <span class="n">epochs</span><span class="p">,</span> <span class="n">mini_batch_size</span><span class="p">,</span> <span class="n">eta</span><span class="p">,</span>
            <span class="n">test_data</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Train the neural network using mini-batch stochastic</span>
<span class="sd">        gradient descent.  The &quot;training_data&quot; is a list of tuples</span>
<span class="sd">        &quot;(x, y)&quot; representing the training inputs and the desired</span>
<span class="sd">        outputs.  The other non-optional parameters are</span>
<span class="sd">        self-explanatory.  If &quot;test_data&quot; is provided then the</span>
<span class="sd">        network will be evaluated against the test data after each</span>
<span class="sd">        epoch, and partial progress printed out.  This is useful for</span>
<span class="sd">        tracking progress, but slows things down substantially.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">test_data</span><span class="p">:</span> <span class="n">n_test</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">test_data</span><span class="p">)</span>
        <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">training_data</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
            <span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">training_data</span><span class="p">)</span>
            <span class="n">mini_batches</span> <span class="o">=</span> <span class="p">[</span>
                <span class="n">training_data</span><span class="p">[</span><span class="n">k</span><span class="p">:</span><span class="n">k</span><span class="o">+</span><span class="n">mini_batch_size</span><span class="p">]</span>
                <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">mini_batch_size</span><span class="p">)]</span>
            <span class="k">for</span> <span class="n">mini_batch</span> <span class="ow">in</span> <span class="n">mini_batches</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">update_mini_batch</span><span class="p">(</span><span class="n">mini_batch</span><span class="p">,</span> <span class="n">eta</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">test_data</span><span class="p">:</span>
                <span class="k">print</span> <span class="s">&quot;Epoch {0}: {1} / {2}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                    <span class="n">j</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">test_data</span><span class="p">),</span> <span class="n">n_test</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">print</span> <span class="s">&quot;Epoch {0} complete&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">j</span><span class="p">)</span>
</pre></div>
</p><p>The <tt>training_data</tt> is a list of tuples <tt>(x, y)</tt>
representing the training inputs and corresponding desired outputs.
The variables <tt>epochs</tt> and <tt>mini_batch_size</tt> are what you'd
expect - the number of epochs to train for, and the size of the
mini-batches to use when sampling.  <tt>eta</tt> is the learning rate,
$\eta$.  If the optional argument <tt>test_data</tt> is supplied, then
the program will evaluate the network after each epoch of training,
and print out partial progress.  This is useful for tracking progress,
but slows things down substantially.</p><p>The code works as follows.  In each epoch, it starts by randomly
shuffling the training data, and then partitions it into mini-batches
of the appropriate size.  This is an easy way of sampling randomly
from the training data.  Then for each <tt>mini_batch</tt> we apply a
single step of gradient descent.  This is done by the code
<tt>self.update_mini_batch(mini_batch, eta)</tt>, which updates the
network weights and biases according to a single iteration of gradient
descent, using just the training data in <tt>mini_batch</tt>.  Here's
the code for the <tt>update_mini_batch</tt> method:
<div class="highlight"><pre>    <span class="k">def</span> <span class="nf">update_mini_batch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mini_batch</span><span class="p">,</span> <span class="n">eta</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Update the network&#39;s weights and biases by applying</span>
<span class="sd">        gradient descent using backpropagation to a single mini batch.</span>
<span class="sd">        The &quot;mini_batch&quot; is a list of tuples &quot;(x, y)&quot;, and &quot;eta&quot;</span>
<span class="sd">        is the learning rate.&quot;&quot;&quot;</span>
        <span class="n">nabla_b</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">b</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">biases</span><span class="p">]</span>
        <span class="n">nabla_w</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">w</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">mini_batch</span><span class="p">:</span>
            <span class="n">delta_nabla_b</span><span class="p">,</span> <span class="n">delta_nabla_w</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">backprop</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
            <span class="n">nabla_b</span> <span class="o">=</span> <span class="p">[</span><span class="n">nb</span><span class="o">+</span><span class="n">dnb</span> <span class="k">for</span> <span class="n">nb</span><span class="p">,</span> <span class="n">dnb</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">nabla_b</span><span class="p">,</span> <span class="n">delta_nabla_b</span><span class="p">)]</span>
            <span class="n">nabla_w</span> <span class="o">=</span> <span class="p">[</span><span class="n">nw</span><span class="o">+</span><span class="n">dnw</span> <span class="k">for</span> <span class="n">nw</span><span class="p">,</span> <span class="n">dnw</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">nabla_w</span><span class="p">,</span> <span class="n">delta_nabla_w</span><span class="p">)]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="p">[</span><span class="n">w</span><span class="o">-</span><span class="p">(</span><span class="n">eta</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">mini_batch</span><span class="p">))</span><span class="o">*</span><span class="n">nw</span>
                        <span class="k">for</span> <span class="n">w</span><span class="p">,</span> <span class="n">nw</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">,</span> <span class="n">nabla_w</span><span class="p">)]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">biases</span> <span class="o">=</span> <span class="p">[</span><span class="n">b</span><span class="o">-</span><span class="p">(</span><span class="n">eta</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">mini_batch</span><span class="p">))</span><span class="o">*</span><span class="n">nb</span>
                       <span class="k">for</span> <span class="n">b</span><span class="p">,</span> <span class="n">nb</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">biases</span><span class="p">,</span> <span class="n">nabla_b</span><span class="p">)]</span>
</pre></div>

Most of the work is done by the line
<div class="highlight"><pre>            <span class="n">delta_nabla_b</span><span class="p">,</span> <span class="n">delta_nabla_w</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">backprop</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>

This invokes something called the <em>backpropagation</em> algorithm,
which is a fast way of computing the gradient of the cost function.
So <tt>update_mini_batch</tt> works simply by computing these gradients
for every training example in the <tt>mini_batch</tt>, and then updating
<tt>self.weights</tt> and <tt>self.biases</tt> appropriately.</p><p>I'm not going to show the code for <tt>self.backprop</tt> right now.
We'll study how backpropagation works in the next chapter, including
the code for <tt>self.backprop</tt>.  For now, just assume that it
behaves as claimed, returning the appropriate gradient for the cost
associated to the training example <tt>x</tt>.</p><p>Let's look at the full program, including the documentation strings,
which I omitted above.  Apart from <tt>self.backprop</tt> the program is
self-explanatory - all the heavy lifting is done in <tt>self.SGD</tt>
and <tt>self.update_mini_batch</tt>, which we've already discussed.  The
<tt>self.backprop</tt> method makes use of a few extra functions to help
in computing the gradient, namely <tt>sigmoid_prime</tt>, which computes
the derivative of the $\sigma$ function, and
<tt>self.cost_derivative</tt>, which I won't describe here.  You can get
the gist of these (and perhaps the details) just by looking at the
code and documentation strings.  We'll look at them in detail in the
next chapter.
Note that while the program appears lengthy, much of the code is
documentation strings intended to make the code easy to understand.
In fact, the program contains just 74 lines of non-whitespace,
non-comment code.  All the code may be found on GitHub
<a href="https://github.com/mnielsen/neural-networks-and-deep-learning/blob/master/src/network.py">here</a>.</p><p></p><p><div class="highlight"><pre><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">network.py</span>
<span class="sd">~~~~~~~~~~</span>

<span class="sd">A module to implement the stochastic gradient descent learning</span>
<span class="sd">algorithm for a feedforward neural network.  Gradients are calculated</span>
<span class="sd">using backpropagation.  Note that I have focused on making the code</span>
<span class="sd">simple, easily readable, and easily modifiable.  It is not optimized,</span>
<span class="sd">and omits many desirable features.</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="c">#### Libraries</span>
<span class="c"># Standard library</span>
<span class="kn">import</span> <span class="nn">random</span>

<span class="c"># Third-party libraries</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>

<span class="k">class</span> <span class="nc">Network</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sizes</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;The list ``sizes`` contains the number of neurons in the</span>
<span class="sd">        respective layers of the network.  For example, if the list</span>
<span class="sd">        was [2, 3, 1] then it would be a three-layer network, with the</span>
<span class="sd">        first layer containing 2 neurons, the second layer 3 neurons,</span>
<span class="sd">        and the third layer 1 neuron.  The biases and weights for the</span>
<span class="sd">        network are initialized randomly, using a Gaussian</span>
<span class="sd">        distribution with mean 0, and variance 1.  Note that the first</span>
<span class="sd">        layer is assumed to be an input layer, and by convention we</span>
<span class="sd">        won&#39;t set any biases for those neurons, since biases are only</span>
<span class="sd">        ever used in computing the outputs from later layers.&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_layers</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">sizes</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sizes</span> <span class="o">=</span> <span class="n">sizes</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">biases</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">sizes</span><span class="p">[</span><span class="mi">1</span><span class="p">:]]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
                        <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">sizes</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">sizes</span><span class="p">[</span><span class="mi">1</span><span class="p">:])]</span>

    <span class="k">def</span> <span class="nf">feedforward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">a</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Return the output of the network if ``a`` is input.&quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">b</span><span class="p">,</span> <span class="n">w</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">biases</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">):</span>
            <span class="n">a</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">a</span><span class="p">)</span><span class="o">+</span><span class="n">b</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">a</span>

    <span class="k">def</span> <span class="nf">SGD</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">training_data</span><span class="p">,</span> <span class="n">epochs</span><span class="p">,</span> <span class="n">mini_batch_size</span><span class="p">,</span> <span class="n">eta</span><span class="p">,</span>
            <span class="n">test_data</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Train the neural network using mini-batch stochastic</span>
<span class="sd">        gradient descent.  The ``training_data`` is a list of tuples</span>
<span class="sd">        ``(x, y)`` representing the training inputs and the desired</span>
<span class="sd">        outputs.  The other non-optional parameters are</span>
<span class="sd">        self-explanatory.  If ``test_data`` is provided then the</span>
<span class="sd">        network will be evaluated against the test data after each</span>
<span class="sd">        epoch, and partial progress printed out.  This is useful for</span>
<span class="sd">        tracking progress, but slows things down substantially.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">test_data</span><span class="p">:</span> <span class="n">n_test</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">test_data</span><span class="p">)</span>
        <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">training_data</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
            <span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">training_data</span><span class="p">)</span>
            <span class="n">mini_batches</span> <span class="o">=</span> <span class="p">[</span>
                <span class="n">training_data</span><span class="p">[</span><span class="n">k</span><span class="p">:</span><span class="n">k</span><span class="o">+</span><span class="n">mini_batch_size</span><span class="p">]</span>
                <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">mini_batch_size</span><span class="p">)]</span>
            <span class="k">for</span> <span class="n">mini_batch</span> <span class="ow">in</span> <span class="n">mini_batches</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">update_mini_batch</span><span class="p">(</span><span class="n">mini_batch</span><span class="p">,</span> <span class="n">eta</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">test_data</span><span class="p">:</span>
                <span class="k">print</span> <span class="s">&quot;Epoch {0}: {1} / {2}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                    <span class="n">j</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">test_data</span><span class="p">),</span> <span class="n">n_test</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">print</span> <span class="s">&quot;Epoch {0} complete&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">j</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">update_mini_batch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mini_batch</span><span class="p">,</span> <span class="n">eta</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Update the network&#39;s weights and biases by applying</span>
<span class="sd">        gradient descent using backpropagation to a single mini batch.</span>
<span class="sd">        The ``mini_batch`` is a list of tuples ``(x, y)``, and ``eta``</span>
<span class="sd">        is the learning rate.&quot;&quot;&quot;</span>
        <span class="n">nabla_b</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">b</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">biases</span><span class="p">]</span>
        <span class="n">nabla_w</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">w</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">mini_batch</span><span class="p">:</span>
            <span class="n">delta_nabla_b</span><span class="p">,</span> <span class="n">delta_nabla_w</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">backprop</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
            <span class="n">nabla_b</span> <span class="o">=</span> <span class="p">[</span><span class="n">nb</span><span class="o">+</span><span class="n">dnb</span> <span class="k">for</span> <span class="n">nb</span><span class="p">,</span> <span class="n">dnb</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">nabla_b</span><span class="p">,</span> <span class="n">delta_nabla_b</span><span class="p">)]</span>
            <span class="n">nabla_w</span> <span class="o">=</span> <span class="p">[</span><span class="n">nw</span><span class="o">+</span><span class="n">dnw</span> <span class="k">for</span> <span class="n">nw</span><span class="p">,</span> <span class="n">dnw</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">nabla_w</span><span class="p">,</span> <span class="n">delta_nabla_w</span><span class="p">)]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="p">[</span><span class="n">w</span><span class="o">-</span><span class="p">(</span><span class="n">eta</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">mini_batch</span><span class="p">))</span><span class="o">*</span><span class="n">nw</span>
                        <span class="k">for</span> <span class="n">w</span><span class="p">,</span> <span class="n">nw</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">,</span> <span class="n">nabla_w</span><span class="p">)]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">biases</span> <span class="o">=</span> <span class="p">[</span><span class="n">b</span><span class="o">-</span><span class="p">(</span><span class="n">eta</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">mini_batch</span><span class="p">))</span><span class="o">*</span><span class="n">nb</span>
                       <span class="k">for</span> <span class="n">b</span><span class="p">,</span> <span class="n">nb</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">biases</span><span class="p">,</span> <span class="n">nabla_b</span><span class="p">)]</span>

    <span class="k">def</span> <span class="nf">backprop</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Return a tuple ``(nabla_b, nabla_w)`` representing the</span>
<span class="sd">        gradient for the cost function C_x.  ``nabla_b`` and</span>
<span class="sd">        ``nabla_w`` are layer-by-layer lists of numpy arrays, similar</span>
<span class="sd">        to ``self.biases`` and ``self.weights``.&quot;&quot;&quot;</span>
        <span class="n">nabla_b</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">b</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">biases</span><span class="p">]</span>
        <span class="n">nabla_w</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">w</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">]</span>
        <span class="c"># feedforward</span>
        <span class="n">activation</span> <span class="o">=</span> <span class="n">x</span>
        <span class="n">activations</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">]</span> <span class="c"># list to store all the activations, layer by layer</span>
        <span class="n">zs</span> <span class="o">=</span> <span class="p">[]</span> <span class="c"># list to store all the z vectors, layer by layer</span>
        <span class="k">for</span> <span class="n">b</span><span class="p">,</span> <span class="n">w</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">biases</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">):</span>
            <span class="n">z</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">activation</span><span class="p">)</span><span class="o">+</span><span class="n">b</span>
            <span class="n">zs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
            <span class="n">activation</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
            <span class="n">activations</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">activation</span><span class="p">)</span>
        <span class="c"># backward pass</span>
        <span class="n">delta</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cost_derivative</span><span class="p">(</span><span class="n">activations</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">y</span><span class="p">)</span> <span class="o">*</span> \
            <span class="n">sigmoid_prime</span><span class="p">(</span><span class="n">zs</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
        <span class="n">nabla_b</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">delta</span>
        <span class="n">nabla_w</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">delta</span><span class="p">,</span> <span class="n">activations</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">transpose</span><span class="p">())</span>
        <span class="c"># Note that the variable l in the loop below is used a little</span>
        <span class="c"># differently to the notation in Chapter 2 of the book.  Here,</span>
        <span class="c"># l = 1 means the last layer of neurons, l = 2 is the</span>
        <span class="c"># second-last layer, and so on.  It&#39;s a renumbering of the</span>
        <span class="c"># scheme in the book, used here to take advantage of the fact</span>
        <span class="c"># that Python can use negative indices in lists.</span>
        <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_layers</span><span class="p">):</span>
            <span class="n">z</span> <span class="o">=</span> <span class="n">zs</span><span class="p">[</span><span class="o">-</span><span class="n">l</span><span class="p">]</span>
            <span class="n">sp</span> <span class="o">=</span> <span class="n">sigmoid_prime</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
            <span class="n">delta</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">[</span><span class="o">-</span><span class="n">l</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">transpose</span><span class="p">(),</span> <span class="n">delta</span><span class="p">)</span> <span class="o">*</span> <span class="n">sp</span>
            <span class="n">nabla_b</span><span class="p">[</span><span class="o">-</span><span class="n">l</span><span class="p">]</span> <span class="o">=</span> <span class="n">delta</span>
            <span class="n">nabla_w</span><span class="p">[</span><span class="o">-</span><span class="n">l</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">delta</span><span class="p">,</span> <span class="n">activations</span><span class="p">[</span><span class="o">-</span><span class="n">l</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">transpose</span><span class="p">())</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">nabla_b</span><span class="p">,</span> <span class="n">nabla_w</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">evaluate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">test_data</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Return the number of test inputs for which the neural</span>
<span class="sd">        network outputs the correct result. Note that the neural</span>
<span class="sd">        network&#39;s output is assumed to be the index of whichever</span>
<span class="sd">        neuron in the final layer has the highest activation.&quot;&quot;&quot;</span>
        <span class="n">test_results</span> <span class="o">=</span> <span class="p">[(</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">feedforward</span><span class="p">(</span><span class="n">x</span><span class="p">)),</span> <span class="n">y</span><span class="p">)</span>
                        <span class="k">for</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="ow">in</span> <span class="n">test_data</span><span class="p">]</span>
        <span class="k">return</span> <span class="nb">sum</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">x</span> <span class="o">==</span> <span class="n">y</span><span class="p">)</span> <span class="k">for</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="ow">in</span> <span class="n">test_results</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">cost_derivative</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">output_activations</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Return the vector of partial derivatives \partial C_x /</span>
<span class="sd">        \partial a for the output activations.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">output_activations</span><span class="o">-</span><span class="n">y</span><span class="p">)</span>

<span class="c">#### Miscellaneous functions</span>
<span class="k">def</span> <span class="nf">sigmoid</span><span class="p">(</span><span class="n">z</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;The sigmoid function.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="mf">1.0</span><span class="o">/</span><span class="p">(</span><span class="mf">1.0</span><span class="o">+</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">z</span><span class="p">))</span>

<span class="k">def</span> <span class="nf">sigmoid_prime</span><span class="p">(</span><span class="n">z</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Derivative of the sigmoid function.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">z</span><span class="p">)</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">z</span><span class="p">))</span>
</pre></div>
</p><p>How well does the program recognize handwritten digits?  Well, let's
start by loading in the MNIST data.  I'll do this using a little
helper program, <tt>mnist_loader.py</tt>, to be described below.  We
execute the following commands in a Python shell,</p><p><div class="highlight"><pre><span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="nn">mnist_loader</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">training_data</span><span class="p">,</span> <span class="n">validation_data</span><span class="p">,</span> <span class="n">test_data</span> <span class="o">=</span> \
<span class="o">...</span> <span class="n">mnist_loader</span><span class="o">.</span><span class="n">load_data_wrapper</span><span class="p">()</span>
</pre></div>
</p><p>Of course, this could also be done in a separate Python program, but
if you're following along it's probably easiest to do in a Python
shell.  </p><p>After loading the MNIST data, we'll set up a <tt>Network</tt> with $30$
hidden neurons.  We do this after importing the Python program listed
above, which is named <tt>network</tt>,</p><p><div class="highlight"><pre><span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="nn">network</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">net</span> <span class="o">=</span> <span class="n">network</span><span class="o">.</span><span class="n">Network</span><span class="p">([</span><span class="mi">784</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">10</span><span class="p">])</span>
</pre></div>
</p><p>Finally, we'll use stochastic gradient descent to learn from the MNIST
<tt>training_data</tt> over 30 epochs, with a mini-batch size of 10, and a
learning rate of $\eta = 3.0$, </p><p><div class="highlight"><pre><span class="o">&gt;&gt;&gt;</span> <span class="n">net</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">training_data</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">,</span> <span class="n">test_data</span><span class="o">=</span><span class="n">test_data</span><span class="p">)</span>
</pre></div>
</p><p>Note that if you're running the code as you read along, it will take
some time to execute - for a typical machine (as of 2015) it will
likely take a few minutes to run.  I suggest you set things running,
continue to read, and periodically check the output from the code.  If
you're in a rush you can speed things up by decreasing the number of
epochs, by decreasing the number of hidden neurons, or by using only
part of the training data.  Note that production code would be much,
much faster: these Python scripts are intended to help you understand
how neural nets work, not to be high-performance code!  And, of
course, once we've trained a network it can be run very quickly
indeed, on almost any computing platform. For example, once we've
learned a good set of weights and biases for a network, it can easily
be ported to run in Javascript in a web browser, or as a native app on
a mobile device.  In any case, here is a partial transcript of the
output of one training run of the neural network.  The transcript
shows the number of test images correctly recognized by the neural
network after each epoch of training.  As you can see, after just a
single epoch this has reached 9,129 out of 10,000, and the number
continues to grow,</p><p><div class="highlight"><pre>Epoch 0: 9129 / 10000
Epoch 1: 9295 / 10000
Epoch 2: 9348 / 10000
...
Epoch 27: 9528 / 10000
Epoch 28: 9542 / 10000
Epoch 29: 9534 / 10000
</pre></div>
</p><p>That is, the trained network gives us a classification rate of about
$95$ percent - $95.42$ percent at its peak ("Epoch 28")!  That's
quite encouraging as a first attempt.  I should warn you, however,
that if you run the code then your results are not necessarily going
to be quite the same as mine, since we'll be initializing our network
using (different) random weights and biases.  To generate results in
this chapter I've taken best-of-three runs.</p><p>Let's rerun the above experiment, changing the number of hidden
neurons to $100$.  As was the case earlier, if you're running the code
as you read along, you should be warned that it takes quite a while to
execute (on my machine this experiment takes tens of seconds for each
training epoch), so it's wise to continue reading in parallel while
the code executes.</p><p><div class="highlight"><pre><span class="o">&gt;&gt;&gt;</span> <span class="n">net</span> <span class="o">=</span> <span class="n">network</span><span class="o">.</span><span class="n">Network</span><span class="p">([</span><span class="mi">784</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">10</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">net</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">training_data</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">,</span> <span class="n">test_data</span><span class="o">=</span><span class="n">test_data</span><span class="p">)</span>
</pre></div>
</p><p>Sure enough, this improves the results to $96.59$ percent.  At least
in this case, using more hidden neurons helps us get better
results*<span class="marginnote">
*Reader feedback indicates quite some variation in
  results for this experiment, and some training runs give results
  quite a bit worse.  Using the techniques introduced in chapter 3
  will greatly reduce the variation in performance across different
  training runs for our networks.</span>.</p><p>Of course, to obtain these accuracies I had to make specific choices
for the number of epochs of training, the mini-batch size, and the
learning rate, $\eta$.  As I mentioned above, these are known as
hyper-parameters for our neural network, in order to distinguish them
from the parameters (weights and biases) learnt by our learning
algorithm.  If we choose our hyper-parameters poorly, we can get bad
results.  Suppose, for example, that we'd chosen the learning rate to
be $\eta = 0.001$,</p><p><div class="highlight"><pre><span class="o">&gt;&gt;&gt;</span> <span class="n">net</span> <span class="o">=</span> <span class="n">network</span><span class="o">.</span><span class="n">Network</span><span class="p">([</span><span class="mi">784</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">10</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">net</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">training_data</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mf">0.001</span><span class="p">,</span> <span class="n">test_data</span><span class="o">=</span><span class="n">test_data</span><span class="p">)</span>
</pre></div>
</p><p>The results are much less encouraging,
<div class="highlight"><pre>Epoch 0: 1139 / 10000
Epoch 1: 1136 / 10000
Epoch 2: 1135 / 10000
...
Epoch 27: 2101 / 10000
Epoch 28: 2123 / 10000
Epoch 29: 2142 / 10000
</pre></div>

However, you can see that the performance of the network is getting
slowly better over time.  That suggests increasing the learning rate,
say to $\eta = 0.01$.  If we do that, we get better results, which
suggests increasing the learning rate again.  (If making a change
improves things, try doing more!)  If we do that several times over,
we'll end up with a learning rate of something like $\eta = 1.0$ (and
perhaps fine tune to $3.0$), which is close to our earlier
experiments.  So even though we initially made a poor choice of
hyper-parameters, we at least got enough information to help us
improve our choice of hyper-parameters.</p><p>In general, debugging a neural network can be challenging.  This is
especially true when the initial choice of hyper-parameters produces
results no better than random noise.  Suppose we try the successful 30
hidden neuron network architecture from earlier, but with the learning
rate changed to $\eta = 100.0$:
<div class="highlight"><pre><span class="o">&gt;&gt;&gt;</span> <span class="n">net</span> <span class="o">=</span> <span class="n">network</span><span class="o">.</span><span class="n">Network</span><span class="p">([</span><span class="mi">784</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">10</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">net</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">training_data</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mf">100.0</span><span class="p">,</span> <span class="n">test_data</span><span class="o">=</span><span class="n">test_data</span><span class="p">)</span>
</pre></div>

At this point we've actually gone too far, and the learning rate is
too high:
<div class="highlight"><pre><span class="n">Epoch</span> <span class="mi">0</span><span class="p">:</span> <span class="mi">1009</span> <span class="o">/</span> <span class="mi">10000</span>
<span class="n">Epoch</span> <span class="mi">1</span><span class="p">:</span> <span class="mi">1009</span> <span class="o">/</span> <span class="mi">10000</span>
<span class="n">Epoch</span> <span class="mi">2</span><span class="p">:</span> <span class="mi">1009</span> <span class="o">/</span> <span class="mi">10000</span>
<span class="n">Epoch</span> <span class="mi">3</span><span class="p">:</span> <span class="mi">1009</span> <span class="o">/</span> <span class="mi">10000</span>
<span class="o">...</span>
<span class="n">Epoch</span> <span class="mi">27</span><span class="p">:</span> <span class="mi">982</span> <span class="o">/</span> <span class="mi">10000</span>
<span class="n">Epoch</span> <span class="mi">28</span><span class="p">:</span> <span class="mi">982</span> <span class="o">/</span> <span class="mi">10000</span>
<span class="n">Epoch</span> <span class="mi">29</span><span class="p">:</span> <span class="mi">982</span> <span class="o">/</span> <span class="mi">10000</span>
</pre></div>

Now imagine that we were coming to this problem for the first time.
Of course, we <em>know</em> from our earlier experiments that the right
thing to do is to decrease the learning rate.  But if we were coming
to this problem for the first time then there wouldn't be much in the
output to guide us on what to do.  We might worry not only about the
learning rate, but about every other aspect of our neural network.  We
might wonder if we've initialized the weights and biases in a way that
makes it hard for the network to learn?  Or maybe we don't have enough
training data to get meaningful learning?  Perhaps we haven't run for
enough epochs?  Or maybe it's impossible for a neural network with
this architecture to learn to recognize handwritten digits?  Maybe the
learning rate is too <em>low</em>?  Or, maybe, the learning rate is too
high?  When you're coming to a problem for the first time, you're not
always sure.</p><p>The lesson to take away from this is that debugging a neural network
is not trivial, and, just as for ordinary programming, there is an art
to it.  You need to learn that art of debugging in order to get good
results from neural networks.  More generally, we need to develop
heuristics for choosing good hyper-parameters and a good architecture.
We'll discuss all these at length through the book, including how I
chose the hyper-parameters above.</p><p>
<h4><a name="exercise_420023"></a><a href="#exercise_420023">Exercise</a></h4><ul></p><p><li> Try creating a network with just two layers - an input and an
  output layer, no hidden layer - with 784 and 10 neurons,
  respectively.  Train the network using stochastic gradient descent.
  What classification accuracy can you achieve?
</ul></p><p></p><p>Earlier, I skipped over the details of how the MNIST data is loaded.
It's pretty straightforward.  For completeness, here's the code.  The
data structures used to store the MNIST data are described in the
documentation strings - it's straightforward stuff, tuples and lists
of Numpy <tt>ndarray</tt> objects (think of them as vectors if you're
not familiar with <tt>ndarray</tt>s):</p><p><div class="highlight"><pre><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">mnist_loader</span>
<span class="sd">~~~~~~~~~~~~</span>

<span class="sd">A library to load the MNIST image data.  For details of the data</span>
<span class="sd">structures that are returned, see the doc strings for ``load_data``</span>
<span class="sd">and ``load_data_wrapper``.  In practice, ``load_data_wrapper`` is the</span>
<span class="sd">function usually called by our neural network code.</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="c">#### Libraries</span>
<span class="c"># Standard library</span>
<span class="kn">import</span> <span class="nn">cPickle</span>
<span class="kn">import</span> <span class="nn">gzip</span>

<span class="c"># Third-party libraries</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>

<span class="k">def</span> <span class="nf">load_data</span><span class="p">():</span>
    <span class="sd">&quot;&quot;&quot;Return the MNIST data as a tuple containing the training data,</span>
<span class="sd">    the validation data, and the test data.</span>

<span class="sd">    The ``training_data`` is returned as a tuple with two entries.</span>
<span class="sd">    The first entry contains the actual training images.  This is a</span>
<span class="sd">    numpy ndarray with 50,000 entries.  Each entry is, in turn, a</span>
<span class="sd">    numpy ndarray with 784 values, representing the 28 * 28 = 784</span>
<span class="sd">    pixels in a single MNIST image.</span>

<span class="sd">    The second entry in the ``training_data`` tuple is a numpy ndarray</span>
<span class="sd">    containing 50,000 entries.  Those entries are just the digit</span>
<span class="sd">    values (0...9) for the corresponding images contained in the first</span>
<span class="sd">    entry of the tuple.</span>

<span class="sd">    The ``validation_data`` and ``test_data`` are similar, except</span>
<span class="sd">    each contains only 10,000 images.</span>

<span class="sd">    This is a nice data format, but for use in neural networks it&#39;s</span>
<span class="sd">    helpful to modify the format of the ``training_data`` a little.</span>
<span class="sd">    That&#39;s done in the wrapper function ``load_data_wrapper()``, see</span>
<span class="sd">    below.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">f</span> <span class="o">=</span> <span class="n">gzip</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="s">&#39;../data/mnist.pkl.gz&#39;</span><span class="p">,</span> <span class="s">&#39;rb&#39;</span><span class="p">)</span>
    <span class="n">training_data</span><span class="p">,</span> <span class="n">validation_data</span><span class="p">,</span> <span class="n">test_data</span> <span class="o">=</span> <span class="n">cPickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
    <span class="n">f</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">training_data</span><span class="p">,</span> <span class="n">validation_data</span><span class="p">,</span> <span class="n">test_data</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">load_data_wrapper</span><span class="p">():</span>
    <span class="sd">&quot;&quot;&quot;Return a tuple containing ``(training_data, validation_data,</span>
<span class="sd">    test_data)``. Based on ``load_data``, but the format is more</span>
<span class="sd">    convenient for use in our implementation of neural networks.</span>

<span class="sd">    In particular, ``training_data`` is a list containing 50,000</span>
<span class="sd">    2-tuples ``(x, y)``.  ``x`` is a 784-dimensional numpy.ndarray</span>
<span class="sd">    containing the input image.  ``y`` is a 10-dimensional</span>
<span class="sd">    numpy.ndarray representing the unit vector corresponding to the</span>
<span class="sd">    correct digit for ``x``.</span>

<span class="sd">    ``validation_data`` and ``test_data`` are lists containing 10,000</span>
<span class="sd">    2-tuples ``(x, y)``.  In each case, ``x`` is a 784-dimensional</span>
<span class="sd">    numpy.ndarry containing the input image, and ``y`` is the</span>
<span class="sd">    corresponding classification, i.e., the digit values (integers)</span>
<span class="sd">    corresponding to ``x``.</span>

<span class="sd">    Obviously, this means we&#39;re using slightly different formats for</span>
<span class="sd">    the training data and the validation / test data.  These formats</span>
<span class="sd">    turn out to be the most convenient for use in our neural network</span>
<span class="sd">    code.&quot;&quot;&quot;</span>
    <span class="n">tr_d</span><span class="p">,</span> <span class="n">va_d</span><span class="p">,</span> <span class="n">te_d</span> <span class="o">=</span> <span class="n">load_data</span><span class="p">()</span>
    <span class="n">training_inputs</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">(</span><span class="mi">784</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">tr_d</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>
    <span class="n">training_results</span> <span class="o">=</span> <span class="p">[</span><span class="n">vectorized_result</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">tr_d</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span>
    <span class="n">training_data</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="n">training_inputs</span><span class="p">,</span> <span class="n">training_results</span><span class="p">)</span>
    <span class="n">validation_inputs</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">(</span><span class="mi">784</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">va_d</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>
    <span class="n">validation_data</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="n">validation_inputs</span><span class="p">,</span> <span class="n">va_d</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">test_inputs</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">(</span><span class="mi">784</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">te_d</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>
    <span class="n">test_data</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="n">test_inputs</span><span class="p">,</span> <span class="n">te_d</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">training_data</span><span class="p">,</span> <span class="n">validation_data</span><span class="p">,</span> <span class="n">test_data</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">vectorized_result</span><span class="p">(</span><span class="n">j</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Return a 10-dimensional unit vector with a 1.0 in the jth</span>
<span class="sd">    position and zeroes elsewhere.  This is used to convert a digit</span>
<span class="sd">    (0...9) into a corresponding desired output from the neural</span>
<span class="sd">    network.&quot;&quot;&quot;</span>
    <span class="n">e</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">10</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="n">e</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.0</span>
    <span class="k">return</span> <span class="n">e</span>
</pre></div>
</p><p>I said above that our program gets pretty good results.  What does
that mean?  Good compared to what?  It's informative to have some
simple (non-neural-network) baseline tests to compare against, to
understand what it means to perform well.  The simplest baseline of
all, of course, is to randomly guess the digit.  That'll be right
about ten percent of the time.  We're doing much better than that!</p><p>What about a less trivial baseline?  Let's try an extremely simple
idea: we'll look at how <em>dark</em> an image is.  For instance, an
image of a $2$ will typically be quite a bit darker than an image of a
$1$, just because more pixels are blackened out, as the following
examples illustrate:</p><p><center><img src="images/mnist_2_and_1.png" width="256px"></center></p><p>This suggests using the training data to compute average darknesses
for each digit, $0, 1, 2,\ldots, 9$.  When presented with a new image,
we compute how dark the image is, and then guess that it's whichever
digit has the closest average darkness.  This is a simple procedure,
and is easy to code up, so I won't explicitly write out the code -
if you're interested it's in the
<a href="https://github.com/mnielsen/neural-networks-and-deep-learning/blob/master/src/mnist_average_darkness.py">GitHub
  repository</a>.  But it's a big improvement over random guessing,
getting $2,225$ of the $10,000$ test images correct, i.e., $22.25$
percent accuracy.</p><p><a name="SVM"></a></p><p>It's not difficult to find other ideas which achieve accuracies in the
$20$ to $50$ percent range.  If you work a bit harder you can get up
over $50$ percent.  But to get much higher accuracies it helps to use
established machine learning algorithms.  Let's try using one of the
best known algorithms, the <em>support vector
  machine</em>
or <em>SVM</em>.  If you're not
familiar with SVMs, not to worry, we're not going to need to
understand the details of how SVMs work.  Instead, we'll use a Python
library called
<a href="http://scikit-learn.org/stable/">scikit-learn</a>,
which provides a simple Python interface to a fast C-based library for
SVMs known as
<a href="http://www.csie.ntu.edu.tw/&#126;cjlin/libsvm/">LIBSVM</a>.</p><p>If we run scikit-learn's SVM classifier using the default settings,
then it gets 9,435 of 10,000 test images correct.  (The code is
available
<a href="https://github.com/mnielsen/neural-networks-and-deep-learning/blob/master/src/mnist_svm.py">here</a>.)
That's a big improvement over our naive approach of classifying an
image based on how dark it is.  Indeed, it means that the SVM is
performing roughly as well as our neural networks, just a little
worse.  In later chapters we'll introduce new techniques that enable
us to improve our neural networks so that they perform much better
than the SVM.</p><p>That's not the end of the story, however.  The 9,435 of 10,000 result
is for scikit-learn's default settings for SVMs.  SVMs have a number
of tunable parameters, and it's possible to search for parameters
which improve this out-of-the-box performance.  I won't explicitly do
this search, but instead refer you to
<a href="http://peekaboo-vision.blogspot.de/2010/09/mnist-for-ever.html">this
  blog post</a> by <a href="http://peekaboo-vision.blogspot.ca/">Andreas
  Mueller</a> if you'd like to know more.  Mueller shows that with some
work optimizing the SVM's parameters it's possible to get the
performance up above 98.5 percent accuracy.  In other words, a
well-tuned SVM only makes an error on about one digit in 70.  That's
pretty good!  Can neural networks do better?</p><p>In fact, they can.  At present, well-designed neural networks
outperform every other technique for solving MNIST, including SVMs.
The current (2013) record is classifying 9,979 of 10,000 images
correctly.  This was done by <a href="http://www.cs.nyu.edu/&#126;wanli/">Li
  Wan</a>, <a href="http://www.matthewzeiler.com/">Matthew Zeiler</a>, Sixin
Zhang, <a href="http://yann.lecun.com/">Yann LeCun</a>, and
<a href="http://cs.nyu.edu/&#126;fergus/pmwiki/pmwiki.php">Rob Fergus</a>.
We'll see most of the techniques they used later in the book.  At that
level the performance is close to human-equivalent, and is arguably
better, since quite a few of the MNIST images are difficult even for
humans to recognize with confidence, for example:</p><p><center><img src="images/mnist_really_bad_images.png" width="560px"></center></p><p>I trust you'll agree that those are tough to classify!  With images
like these in the MNIST data set it's remarkable that neural networks
can accurately classify all but 21 of the 10,000 test images.
Usually, when programming we believe that solving a complicated
problem like recognizing the MNIST digits requires a sophisticated
algorithm.  But even the neural networks in the Wan <em>et al</em> paper
just mentioned involve quite simple algorithms, variations on the
algorithm we've seen in this chapter.  All the complexity is learned,
automatically, from the training data. In some sense, the moral of
both our results and those in more sophisticated papers, is that for
some problems:
<center>
  sophisticated algorithm $\leq$ simple learning algorithm + good
  training data.
</center></p><p><h3><a name="toward_deep_learning"></a><a href="#toward_deep_learning">Toward deep learning</a></h3></p><p>While our neural network gives impressive performance, that
performance is somewhat mysterious.  The weights and biases in the
network were discovered automatically.  And that means we don't
immediately have an explanation of how the network does what it does.
Can we find some way to understand the principles by which our network
is classifying handwritten digits?  And, given such principles, can we
do better?</p><p>To put these questions more starkly, suppose that a few decades hence
neural networks lead to artificial intelligence (AI).  Will we
understand how such intelligent networks work?  Perhaps the networks
will be opaque to us, with weights and biases we don't understand,
because they've been learned automatically.  In the early days of AI
research people hoped that the effort to build an AI would also help
us understand the principles behind intelligence and, maybe, the
functioning of the human brain.  But perhaps the outcome will be that
we end up understanding neither the brain nor how artificial
intelligence works!</p><p>To address these questions, let's think back to the interpretation of
artificial neurons that I gave at the start of the chapter, as a means
of weighing evidence.  Suppose we want to determine whether an image
shows a human face or not:</p><p> </p><p>  <span class="marginnote">Credits: 1. <a
  href="http://commons.wikimedia.org/wiki/User:ST">Ester Inbar</a>. 2.
  Unknown. 3. NASA, ESA, G. Illingworth, D. Magee, and P. Oesch
  (University of California, Santa Cruz), R. Bouwens (Leiden
  University), and the HUDF09 Team.  Click on the images for more
  details.</span></p><p>  <a
  href="http://commons.wikimedia.org/wiki/File:Kangaroo_ST_03.JPG"><img
  src="images/Kangaroo.JPG" height="190px"/></a> <a
  href="http://commons.wikimedia.org/wiki/File:Albert_Einstein_at_the_age_of_three_(1882).jpg"><img
  src="images/Einstein_crop.jpg" height="190px"/></a> <a
  href="http://commons.wikimedia.org/wiki/File:The_Hubble_eXtreme_Deep_Field.jpg"><img
  src="images/hubble.jpg" height="190px"/></a> </p><p>We could attack this problem the same way we attacked handwriting
recognition - by using the pixels in the image as input to a neural
network, with the output from the network a single neuron indicating
either "Yes, it's a face" or "No, it's not a face".</p><p>Let's suppose we do this, but that we're not using a learning
algorithm.  Instead, we're going to try to design a network by hand,
choosing appropriate weights and biases.  How might we go about it?
Forgetting neural networks entirely for the moment, a heuristic we
could use is to decompose the problem into sub-problems: does the
image have an eye in the top left?  Does it have an eye in the top
right?  Does it have a nose in the middle?  Does it have a mouth in
the bottom middle?  Is there hair on top?  And so on.</p><p>If the answers to several of these questions are "yes", or even just
"probably yes", then we'd conclude that the image is likely to be a
face.  Conversely, if the answers to most of the questions are "no",
then the image probably isn't a face.</p><p>Of course, this is just a rough heuristic, and it suffers from many
deficiencies.  Maybe the person is bald, so they have no hair.  Maybe
we can only see part of the face, or the face is at an angle, so some
of the facial features are obscured.  Still, the heuristic suggests
that if we can solve the sub-problems using neural networks, then
perhaps we can build a neural network for face-detection, by combining
the networks for the sub-problems.  Here's a possible architecture,
with rectangles denoting the sub-networks.  Note that this isn't
intended as a realistic approach to solving the face-detection
problem; rather, it's to help us build intuition about how networks
function.  Here's the architecture:</p><p><center>
<img src="images/tikz14.png"/>
</center></p><p>It's also plausible that the sub-networks can be decomposed.  Suppose
we're considering the question: "Is there an eye in the top left?"
This can be decomposed into questions such as: "Is there an
eyebrow?"; "Are there eyelashes?"; "Is there an iris?"; and so
on.  Of course, these questions should really include positional
information, as well - "Is the eyebrow in the top left, and above
the iris?", that kind of thing - but let's keep it simple.  The
network to answer the question "Is there an eye in the top left?"
can now be decomposed:</p><p><center>
<img src="images/tikz15.png"/>
</center></p><p>Those questions too can be broken down, further and further through
multiple layers.  Ultimately, we'll be working with sub-networks that
answer questions so simple they can easily be answered at the level of
single pixels.  Those questions might, for example, be about the
presence or absence of very simple shapes at particular points in the
image.  Such questions can be answered by single neurons connected to
the raw pixels in the image.</p><p>The end result is a network which breaks down a very complicated
question - does this image show a face or not - into very simple
questions answerable at the level of single pixels.  It does this
through a series of many layers, with early layers answering very
simple and specific questions about the input image, and later layers
building up a hierarchy of ever more complex and abstract concepts.
Networks with this kind of many-layer structure - two or more hidden
layers - are called <em>deep neural networks</em>.</p><p></p><p></p><p>
Of course, I haven't said how to do this recursive decomposition into
sub-networks.  It certainly isn't practical to hand-design the weights
and biases in the network.  Instead, we'd like to use learning
algorithms so that the network can automatically learn the weights and
biases - and thus, the hierarchy of concepts - from training data.
Researchers in the 1980s and 1990s tried using stochastic gradient
descent and backpropagation to train deep networks.  Unfortunately,
except for a few special architectures, they didn't have much luck.
The networks would learn, but very slowly, and in practice often too
slowly to be useful.</p><p>Since 2006, a set of techniques has been developed that enable
learning in deep neural nets.  These deep learning techniques are
based on stochastic gradient descent and backpropagation, but also
introduce new ideas.  These techniques have enabled much deeper (and
larger) networks to be trained - people now routinely train networks
with 5 to 10 hidden layers.  And, it turns out that these perform far
better on many problems than shallow neural networks, i.e., networks
with just a single hidden layer.  The reason, of course, is the
ability of deep nets to build up a complex hierarchy of concepts.
It's a bit like the way conventional programming languages use modular
design and ideas about abstraction to enable the creation of complex
computer programs.  Comparing a deep network to a shallow network is a
bit like comparing a programming language with the ability to make
function calls to a stripped down language with no ability to make
such calls.  Abstraction takes a different form in neural networks
than it does in conventional programming, but it's just as important.</p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p>
</div>






<div class="footer"> <span class="left_footer"> In academic work,
please cite this book as: Michael A. Nielsen, "Neural Networks and
Deep Learning", Determination Press, 2015

<br/>
<br/>

This work is licensed under a <a rel="license"
href="http://creativecommons.org/licenses/by-nc/3.0/deed.en_GB"
style="color: #eee;">Creative Commons Attribution-NonCommercial 3.0
Unported License</a>.  This means you're free to copy, share, and
build on this book, but not to sell it.  If you're interested in
commercial use, please <a
href="mailto:mn@michaelnielsen.org">contact me</a>.
</span>
<span class="right_footer">
Last update: Thu Aug 13 11:49:43 2015
<br/>
<br/>
<br/>
<a rel="license" href="http://creativecommons.org/licenses/by-nc/3.0/deed.en_GB"><img alt="Creative Commons Licence" style="border-width:0" src="https://i.creativecommons.org/l/by-nc/3.0/88x31.png" /></a>
</span>
</div>

</body>
</html>
