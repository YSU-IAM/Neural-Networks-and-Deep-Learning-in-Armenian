<!DOCTYPE html>
<html lang="en">
<!-- Produced from a LaTeX source file.  Note that the production is done -->
<!-- by a very rough-and-ready (and buggy) script, so the HTML and other  -->
<!-- code is quite ugly!  Later versions should be better.                -->
    <meta charset="utf-8">
    <meta name="citation_title" content="Neural Networks and Deep Learning">
    <meta name="citation_author" content="Nielsen, Michael A.">
    <meta name="citation_publication_date" content="2015">
    <meta name="citation_fulltext_html_url" content="http://neuralnetworksanddeeplearning.com">
    <meta name="citation_publisher" content="Determination Press">
    <link rel="icon" href="nnadl_favicon.ICO" />
    <title>Նեյրոնային ցանցեր և խորը ուսուցում: Մայքլ Նիլսենի գրքի թարգմանությունը հայերեն</title>
    <script src="assets/jquery.min.js"></script>
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {inlineMath: [['$','$']]},
        "HTML-CSS":
          {scale: 92},
        TeX: { equationNumbers: { autoNumber: "AMS" }}});
    </script>
    <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>


    <link href="assets/style.css" rel="stylesheet">
    <link href="assets/pygments.css" rel="stylesheet">
    <link rel="stylesheet" href="http://code.jquery.com/ui/1.11.2/themes/smoothness/jquery-ui.css">

<style>
/* Adapted from */
/* https://groups.google.com/d/msg/mathjax-users/jqQxrmeG48o/oAaivLgLN90J, */
/* by David Cervone */

@font-face {
    font-family: 'MJX_Math';
    src: url('http://cdn.mathjax.org/mathjax/latest/fonts/HTML-CSS/TeX/eot/MathJax_Math-Italic.eot'); /* IE9 Compat Modes */
    src: url('http://cdn.mathjax.org/mathjax/latest/fonts/HTML-CSS/TeX/eot/MathJax_Math-Italic.eot?iefix') format('eot'),
    url('http://cdn.mathjax.org/mathjax/latest/fonts/HTML-CSS/TeX/woff/MathJax_Math-Italic.woff')  format('woff'),
    url('http://cdn.mathjax.org/mathjax/latest/fonts/HTML-CSS/TeX/otf/MathJax_Math-Italic.otf')  format('opentype'),
    url('http://cdn.mathjax.org/mathjax/latest/fonts/HTML-CSS/TeX/svg/MathJax_Math-Italic.svg#MathJax_Math-Italic') format('svg');
}

@font-face {
    font-family: 'MJX_Main';
    src: url('http://cdn.mathjax.org/mathjax/latest/fonts/HTML-CSS/TeX/eot/MathJax_Main-Regular.eot'); /* IE9 Compat Modes */
    src: url('http://cdn.mathjax.org/mathjax/latest/fonts/HTML-CSS/TeX/eot/MathJax_Main-Regular.eot?iefix') format('eot'),
    url('http://cdn.mathjax.org/mathjax/latest/fonts/HTML-CSS/TeX/woff/MathJax_Main-Regular.woff')  format('woff'),
    url('http://cdn.mathjax.org/mathjax/latest/fonts/HTML-CSS/TeX/otf/MathJax_Main-Regular.otf')  format('opentype'),
    url('http://cdn.mathjax.org/mathjax/latest/fonts/HTML-CSS/TeX/svg/MathJax_Main-Regular.svg#MathJax_Main-Regular') format('svg');
}
</style>
</head>
<body><div class="nonumber_header"><h2><a href="index.html">Նեյրոնային ցանցեր և խորը ուսուցում</a></h2></div><div class="section"><div id="toc">
<p class="toc_title"><a href="index.html">Նեյրոնային ցանցեր և խորը ուսուցում</a></p><p class="toc_not_mainchapter"><a href="about.html">Ինչի՞ մասին է գիրքը</a></p><p class="toc_not_mainchapter"><a href="exercises_and_problems.html">Խնդիրների և վարժությունների մասին</a></p><p class='toc_mainchapter'><a id="toc_using_neural_nets_to_recognize_handwritten_digits_reveal" class="toc_reveal" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';"><img id="toc_img_using_neural_nets_to_recognize_handwritten_digits" src="images/arrow.png" width="15px"></a><a href="chap1.html">Ձեռագիր թվերի ճանաչում օգտագործելով նեյրոնային ցանծեր</a><div id="toc_using_neural_nets_to_recognize_handwritten_digits" style="display: none;"><p class="toc_section"><ul><a href="chap1.html#perceptrons"><li>Պերսեպտրոններ</li></a><a href="chap1.html#sigmoid_neurons"><li>Սիգմոիդ նեյրոններ</li></a><a href="chap1.html#the_architecture_of_neural_networks"><li>Նեյրոնային ցանցերի կառուցվածքը</li></a><a href="chap1.html#a_simple_network_to_classify_handwritten_digits"><li>Պարզ ցանց ձեռագիր թվերի դասակարգման համար</li></a><a href="chap1.html#learning_with_gradient_descent"><li>Սովորում գրադիենտային նվազման միջոցով</li></a><a href="chap1.html#implementing_our_network_to_classify_digits"><li>Թվերի դասակարգման համար նախատեսված ցանցի իրականացումը</li></a><a href="chap1.html#toward_deep_learning"><li>Խորը ուսուցմանն ընդառաջ</li></a></ul></p></div>
<script>
$('#toc_using_neural_nets_to_recognize_handwritten_digits_reveal').click(function() {
   var src = $('#toc_img_using_neural_nets_to_recognize_handwritten_digits').attr('src');
   if(src == 'images/arrow.png') {
     $("#toc_img_using_neural_nets_to_recognize_handwritten_digits").attr('src', 'images/arrow_down.png');
   } else {
     $("#toc_img_using_neural_nets_to_recognize_handwritten_digits").attr('src', 'images/arrow.png');
   };
   $('#toc_using_neural_nets_to_recognize_handwritten_digits').toggle('fast', function() {});
});</script><p class='toc_mainchapter'><a id="toc_how_the_backpropagation_algorithm_works_reveal" class="toc_reveal" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';"><img id="toc_img_how_the_backpropagation_algorithm_works" src="images/arrow.png" width="15px"></a><a href="chap2.html">How the backpropagation algorithm works</a><div id="toc_how_the_backpropagation_algorithm_works" style="display: none;"><p class="toc_section"><ul><a href="chap2.html#warm_up_a_fast_matrix-based_approach_to_computing_the_output
_from_a_neural_network"><li>Warm up: a fast matrix-based approach to computing the output
  from a neural network</li></a><a href="chap2.html#the_two_assumptions_we_need_about_the_cost_function"><li>The two assumptions we need about the cost function</li></a><a href="chap2.html#the_hadamard_product_$s_\odot_t$"><li>The Hadamard product, $s \odot t$</li></a><a href="chap2.html#the_four_fundamental_equations_behind_backpropagation"><li>The four fundamental equations behind backpropagation</li></a><a href="chap2.html#proof_of_the_four_fundamental_equations_(optional)"><li>Proof of the four fundamental equations (optional)</li></a><a href="chap2.html#the_backpropagation_algorithm"><li>The backpropagation algorithm</li></a><a href="chap2.html#the_code_for_backpropagation"><li>The code for backpropagation</li></a><a href="chap2.html#in_what_sense_is_backpropagation_a_fast_algorithm"><li>In what sense is backpropagation a fast algorithm?</li></a><a href="chap2.html#backpropagation_the_big_picture"><li>Backpropagation: the big picture</li></a></ul></p></div>
<script>
$('#toc_how_the_backpropagation_algorithm_works_reveal').click(function() {
   var src = $('#toc_img_how_the_backpropagation_algorithm_works').attr('src');
   if(src == 'images/arrow.png') {
     $("#toc_img_how_the_backpropagation_algorithm_works").attr('src', 'images/arrow_down.png');
   } else {
     $("#toc_img_how_the_backpropagation_algorithm_works").attr('src', 'images/arrow.png');
   };
   $('#toc_how_the_backpropagation_algorithm_works').toggle('fast', function() {});
});</script><p class='toc_mainchapter'><a id="toc_improving_the_way_neural_networks_learn_reveal" class="toc_reveal" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';"><img id="toc_img_improving_the_way_neural_networks_learn" src="images/arrow.png" width="15px"></a><a href="chap3.html">Improving the way neural networks learn</a><div id="toc_improving_the_way_neural_networks_learn" style="display: none;"><p class="toc_section"><ul><a href="chap3.html#the_cross-entropy_cost_function"><li>The cross-entropy cost function</li></a><a href="chap3.html#overfitting_and_regularization"><li>Overfitting and regularization</li></a><a href="chap3.html#weight_initialization"><li>Weight initialization</li></a><a href="chap3.html#handwriting_recognition_revisited_the_code"><li>Handwriting recognition revisited: the code</li></a><a href="chap3.html#how_to_choose_a_neural_network's_hyper-parameters"><li>How to choose a neural network's hyper-parameters?</li></a><a href="chap3.html#other_techniques"><li>Other techniques</li></a></ul></p></div>
<script>
$('#toc_improving_the_way_neural_networks_learn_reveal').click(function() {
   var src = $('#toc_img_improving_the_way_neural_networks_learn').attr('src');
   if(src == 'images/arrow.png') {
     $("#toc_img_improving_the_way_neural_networks_learn").attr('src', 'images/arrow_down.png');
   } else {
     $("#toc_img_improving_the_way_neural_networks_learn").attr('src', 'images/arrow.png');
   };
   $('#toc_improving_the_way_neural_networks_learn').toggle('fast', function() {});
});</script><p class='toc_mainchapter'><a id="toc_a_visual_proof_that_neural_nets_can_compute_any_function_reveal" class="toc_reveal" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';"><img id="toc_img_a_visual_proof_that_neural_nets_can_compute_any_function" src="images/arrow.png" width="15px"></a><a href="chap4.html">A visual proof that neural nets can compute any function</a><div id="toc_a_visual_proof_that_neural_nets_can_compute_any_function" style="display: none;"><p class="toc_section"><ul><a href="chap4.html#two_caveats"><li>Two caveats</li></a><a href="chap4.html#universality_with_one_input_and_one_output"><li>Universality with one input and one output</li></a><a href="chap4.html#many_input_variables"><li>Many input variables</li></a><a href="chap4.html#extension_beyond_sigmoid_neurons"><li>Extension beyond sigmoid neurons</li></a><a href="chap4.html#fixing_up_the_step_functions"><li>Fixing up the step functions</li></a><a href="chap4.html#conclusion"><li>Conclusion</li></a></ul></p></div>
<script>
$('#toc_a_visual_proof_that_neural_nets_can_compute_any_function_reveal').click(function() {
   var src = $('#toc_img_a_visual_proof_that_neural_nets_can_compute_any_function').attr('src');
   if(src == 'images/arrow.png') {
     $("#toc_img_a_visual_proof_that_neural_nets_can_compute_any_function").attr('src', 'images/arrow_down.png');
   } else {
     $("#toc_img_a_visual_proof_that_neural_nets_can_compute_any_function").attr('src', 'images/arrow.png');
   };
   $('#toc_a_visual_proof_that_neural_nets_can_compute_any_function').toggle('fast', function() {});
});</script><p class='toc_mainchapter'><a id="toc_why_are_deep_neural_networks_hard_to_train_reveal" class="toc_reveal" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';"><img id="toc_img_why_are_deep_neural_networks_hard_to_train" src="images/arrow.png" width="15px"></a><a href="chap5.html">Why are deep neural networks hard to train?</a><div id="toc_why_are_deep_neural_networks_hard_to_train" style="display: none;"><p class="toc_section"><ul><a href="chap5.html#the_vanishing_gradient_problem"><li>The vanishing gradient problem</li></a><a href="chap5.html#what's_causing_the_vanishing_gradient_problem_unstable_gradients_in_deep_neural_nets"><li>What's causing the vanishing gradient problem?  Unstable gradients in deep neural nets</li></a><a href="chap5.html#unstable_gradients_in_more_complex_networks"><li>Unstable gradients in more complex networks</li></a><a href="chap5.html#other_obstacles_to_deep_learning"><li>Other obstacles to deep learning</li></a></ul></p></div>
<script>
$('#toc_why_are_deep_neural_networks_hard_to_train_reveal').click(function() {
   var src = $('#toc_img_why_are_deep_neural_networks_hard_to_train').attr('src');
   if(src == 'images/arrow.png') {
     $("#toc_img_why_are_deep_neural_networks_hard_to_train").attr('src', 'images/arrow_down.png');
   } else {
     $("#toc_img_why_are_deep_neural_networks_hard_to_train").attr('src', 'images/arrow.png');
   };
   $('#toc_why_are_deep_neural_networks_hard_to_train').toggle('fast', function() {});
});</script><p class='toc_mainchapter'><a id="toc_deep_learning_reveal" class="toc_reveal" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';"><img id="toc_img_deep_learning" src="images/arrow.png" width="15px"></a><a href="chap6.html">Deep learning</a><div id="toc_deep_learning" style="display: none;"><p class="toc_section"><ul><a href="chap6.html#introducing_convolutional_networks"><li>Introducing convolutional networks</li></a><a href="chap6.html#convolutional_neural_networks_in_practice"><li>Convolutional neural networks in practice</li></a><a href="chap6.html#the_code_for_our_convolutional_networks"><li>The code for our convolutional networks</li></a><a href="chap6.html#recent_progress_in_image_recognition"><li>Recent progress in image recognition</li></a><a href="chap6.html#other_approaches_to_deep_neural_nets"><li>Other approaches to deep neural nets</li></a><a href="chap6.html#on_the_future_of_neural_networks"><li>On the future of neural networks</li></a></ul></p></div>
<script>
$('#toc_deep_learning_reveal').click(function() {
   var src = $('#toc_img_deep_learning').attr('src');
   if(src == 'images/arrow.png') {
     $("#toc_img_deep_learning").attr('src', 'images/arrow_down.png');
   } else {
     $("#toc_img_deep_learning").attr('src', 'images/arrow.png');
   };
   $('#toc_deep_learning').toggle('fast', function() {});
});</script><p class="toc_not_mainchapter"><a href="sai.html">Appendix: Is there a <em>simple</em> algorithm for intelligence?</a></p><p class="toc_not_mainchapter"><a href="acknowledgements.html">Acknowledgements</a></p><p class="toc_not_mainchapter"><a href="faq.html">Frequently Asked Questions</a></p>
</div>


<p>
  Նեյրոնային ցանցերը մինչև օրս ստեղծված ամենահրաշալի ծրագրավորման մեթոդոլոգիաներից է:
  Ծրագրավորման ընդունված մոտեցումն է թելադրել համակարգչին լուծման քայլերը` բաժանելով մեծ խնդիրը բազմաթիվ փոքր,
  բայց հստակ սահմանված ենթախնդիրների, որոնք համակարգիչը կարող է լուծել: Դրան հակառակ` նեյրոնային ցանցերում
  մենք չենք թելադրում համակարգչին ինչպես լուծել խնդիրը: Փոխարենը, այն սովորում է դիտարկվող տվյալներից`
  ինքնուրույն հասկանալով լուծումը:
</p>

<p>
  Տվյալներից ավտոմատ կերպով սովորելը խոստումնալից է հնչում: Սակայն մինչև 2006 թ.
  բացի մի քանի հատուկ խնդրից, մենք չգիտեինք ինչպես սովորեցնել ցանցին որպեսզի այն
  առաջ անցներ տրադիցիոնալ մոտեցումներից: Այն ինչ փոխվեց 2006-ին դա այսպես կոչված
  խորը ցանցերում սովորելու տեխնիկաների հայտնագործումն էր: Այդ տեխնիկաներն այժմ հայտնի
  են որպես խորը ուսուցում: Դրանք ժամանակի ընթացքում ավելի են լավացվել և այսօր խորը ուսուցումն
  ու խորը նեյրոնային ցանցերը տպավորիչ արդյունքներ են ցուցաբերում այնպիսի խնդիրների վրա, ինչպիսիք են
  համակարգչային տեսողությունը(computer vision), խոսքի ճանաչումը(speech recognition) և խոսակցական լեզվի մշակումը(natural
  language processing): Այդ լուծումները հսկայական ծավալներով գործարկվում են այնպիսի ընկերությունների կողմից, ինչպիսիք են
  Գուգլը, Մայքրոսոֆթը և Ֆեյսբուքը:
</p>

<p>
  Այս գրքի նպատակն է օգնել ընթերցողին յուրացնել նեյրոնային ցանցերի հիմքային
  գաղափարները, ներառյալ խորը ուսուցման ժամանակակից տեխնիկաները: Գրքի վրա
  աշխատելով, ընթերցողը կգրի կոդ, որը օգտագործում է նեյրոնային ցանցեր և խորը ուսուցում
  բարդ օրինաչափությունների ճանաչման(pattern recognition) լուծման համար: Ընթերցողը
  կունենա նաև հիմք իրեն հետաքրքրող խնդիրներին լուծումներ առաջարկելու համար` օգտագործելով
  նեյրոնային ցանցեր և խորը ուսուցում:
</p>

<p>
  <h3>
    <a name="a_principle-oriented_approach"></a>
    <a href="#a_principle-oriented_approach">Սկզբունքային մոտեցում</a>
  </h3>
</p>

<p>
  Գրքի հիմքում ընկած համոզմունքներից մեկն այն է, որ լավ է որակյալ հասկանալ նեյրոնային ցանցերի
  և խորը ուսուցման հիմքային սկզբունքները քան պարզապես տեղյակ լինել բազմաթիվ գաղափարների մասին:
  Հիմքային գաղափարների լավ ըմբռնելու դեպքում ընթերցողն ավելի արագ կարող է հասկանալ նոր նյութերը:
</p>

<p>
  Դա նշանակում է որ գիրքը նախատեսված չէ սովորեցնելու, թե ինչպես օգտագործել
  նեյրոնային ցանցերի ինչ-որ գրադարան: Եթե ձեր ցանկությունն է սովորել գրադարաններից մեկը, ապա
  այս գիրքը նպատակահարմար չէ դա իրականացնելու համար: Սակայն կարևոր է գիտակցել, որ
  գուցե դա կօգնի արագ խնդիրը լուծել, սակայն հասկանալու համար թե իրոք
  ինչ է տեղի ունենում նեյրոնային ցանցերում բավական չէ սովորել որևէ
  հայտնի գրադարան: Դուք կարիք ունեք ձեռք բերելու հիմնավոր գիտելիք թե ինչպես են աշխատում նեյրոնային ցանցերը:
  Տեխնոլոգիաները գալիս են և գնում են, սակայն գիտելիքը մնում է:
</p>

<p>
  <h3>
    <a name="a_hands-on_approach"></a>
    <a href="#a_hands-on_approach">Պրակտիկ մոտեցում</a>
  </h3>
</p>

<p>
  Մենք սովորելու ենք նեյրոնային ցանցերի և խորը ուսուցման հիմքային սկզբունքները
  լուծելով հստակ խնդիր, այն է` սովորեցնել համակարգչին ճանաչել ձեռագիր թվանշանները:
  Այս խնդիրը բավականին դժվար է լուծել` օգտագործելով ծրագրավորման տրադիցիոնալ մոտեցումները:
  Այնուամենայնիվ, մենք կտեսնենք, որ այն կարելի է լուծել, օգտագործելով պարզ նեյրոնային ցանց
  մի քանի տասնյակ տող կոդով` առանց գրադարան օգտագործելու: Ավելին, մենք կլավացնենք ծրագիրը
  մի քանի իտերացիաների ընթացքում, օգտագործելով նեյրոնային և խորը ուսուցման ցանցերի հիմքային գաղափարները:
</p>

<p>
  Այսպիսի մոտեցումը նշանակում է որ դուք պետք է ունենաք ծրագրավորման փորձ գիրքը կարդալ
  կարողանալու համար: Սակայն պարտադիր չէ լինել պրոֆեսիոնալ ծրագրավորող: Կոդը գրված է Python
  ծրագրավորման լեզվով (վերսիա 2.7), ինչը հեշտ կլինի հասկանալ անգամ եթե դուք Python-ով
  չեք ծրագրավորում: Գրքում միասին կկառուցենք փոքրիկ նեյրոնային ցանցերի գրադարան, որը դուք
  կարող եք օգտագործել փորձեր կատարելու և գիտելիքները խորացնելու համար: Ամբողջ կոդը կարելի է ներբեռնել
  <a href="https://github.com/mnielsen/neural-networks-and-deep-learning">այստեղից</a>:
</p>

<p>
  Հարկ եմ համարում նաև նշել, որ գիրքը կարդալու համար մաթեմատիկական գիտելիքի
  մակարդակը կարող է համեստ լինել: Գրքում տեղ գտած մաթեմատիկայի բաժինները
  իրենցից ներկայացնում են տարրական հանրահաշիվ և ֆունկցիաների գրաֆիկներ, ինչը
  սպասվում է, որ բոլորը կհասկանան: Որոշ տեղերում ավելի բարդ մաթեմատիկա է օգտագործվում,
  սակայն գրքի կառուցվածքը թույլ է տալիս շարունակել կարդալ` բաց թողնելով այդ հատվածները:
  Գլուխը, որում օգտագործում է համեմատաբար ծանր մաթեմատիկա, դա  <a href="chap2.html">2րդ գլուխն</a> է,
  որը պահանջում է գիտելիք մեկից ավել փոփոխականների ֆունկցիաների մաթեմատիկական անալիզ և գծային հանրահաշիվ:
  Եթե դրանք ծանոթ չեն, ապա <a href="chap2.html">2րդ գլուխը</a> սկսվում է նրանով թե ինչպես
  վարվել մաթէմատիկայի բաժինների հետ: Եթե դուք կհամարեք դա շատ ծանր առաջ շարժվելու համար, ապա
  խորհուրդ է տրվում բաց թողնել այդ գլուխը մինչև <a href="chap2.html#the_backpropagation_algorithm">ամփոփում</a>:
</p>

<p></p><p></p><p></p><p></p><p></p><p></p><p>
</div>



<div class="footer"> <span class="left_footer"> In academic work,
please cite this book as: Michael A. Nielsen, "Neural Networks and
Deep Learning", Determination Press, 2015

<br/>
<br/>

This work is licensed under a <a rel="license"
href="http://creativecommons.org/licenses/by-nc/3.0/deed.en_GB"
style="color: #eee;">Creative Commons Attribution-NonCommercial 3.0
Unported License</a>.  This means you're free to copy, share, and
build on this book, but not to sell it.  If you're interested in
commercial use, please <a
href="mailto:mn@michaelnielsen.org">contact me</a>.
</span>
<span class="right_footer">
Last update: Thu Aug 13 11:49:43 2015
<br/>
<br/>
<br/>
<a rel="license" href="http://creativecommons.org/licenses/by-nc/3.0/deed.en_GB"><img alt="Creative Commons Licence" style="border-width:0" src="http://i.creativecommons.org/l/by-nc/3.0/88x31.png" /></a>
</span>
</div>

</body>
</html>

